{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lab/anaconda3/envs/NLU/lib/python3.7/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import loralib as lora\n",
    "import numpy as np\n",
    "#import matplotlib.pyplot as plt\n",
    "import time\n",
    "import os\n",
    "import sys\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import random\n",
    "import math\n",
    "import copy\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from datasets import load_dataset, load_metric\n",
    "import copy\n",
    "import transformers\n",
    "from transformers import (\n",
    "    AutoConfig,\n",
    "    AutoModelForSequenceClassification,\n",
    "    AutoTokenizer,\n",
    "    DataCollatorWithPadding,\n",
    "    EvalPrediction,\n",
    "    HfArgumentParser,\n",
    "    PretrainedConfig,\n",
    "    Trainer,\n",
    "    TrainingArguments,\n",
    "    default_data_collator,\n",
    "    set_seed,\n",
    "    EarlyStoppingCallback,\n",
    ")\n",
    "from transformers.trainer_utils import get_last_checkpoint, is_main_process\n",
    "from transformers.utils import check_min_version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def seed_everything(seed: int = 0):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    os.environ[\"PYTHONHASHSEED\"] = str(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)  # type: ignore\n",
    "    torch.backends.cudnn.deterministic = True  # type: ignore\n",
    "    torch.backends.cudnn.benchmark = True  # type: ignore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed_everything(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w_q_encoder_loraA_weights = []\n",
    "w_q_encoder_loraB_weights = []\n",
    "w_v_encoder_loraA_weights = []\n",
    "w_v_encoder_loraB_weights = []\n",
    "len_of_layers = 12  # len(SVD_model.roberta.encoder.layer)\n",
    "with torch.no_grad():\n",
    "    for i in range(len_of_layers):\n",
    "        encoder_q_original_weight = SVD_model.roberta.encoder.layer[i].attention.self.query.weight.data.T\n",
    "        encoder_v_original_weight = SVD_model.roberta.encoder.layer[i].attention.self.value.weight.data.T\n",
    "        encoder_q_u, encoder_q_s, encoder_q_v = torch.linalg.svd(encoder_q_original_weight)\n",
    "        encoder_v_u, encoder_v_s, encoder_v_v = torch.linalg.svd(encoder_v_original_weight)\n",
    "        approx_rank = rank\n",
    "        # w_q_encoder\n",
    "        # torch.Size([768, rank])\n",
    "        w_q_encoder_loraA_weights.append(\n",
    "            encoder_q_u[:, :approx_rank] @ torch.diag(encoder_q_s[:approx_rank]).sqrt()\n",
    "        )\n",
    "        # torch.Size([rank, 768])\n",
    "        w_q_encoder_loraB_weights.append(\n",
    "            torch.diag(encoder_q_s[:approx_rank]).sqrt() @ encoder_q_v[:approx_rank, :]\n",
    "        )\n",
    "        # w_v_encoder\n",
    "        w_v_encoder_loraA_weights.append(\n",
    "            encoder_v_u[:, :approx_rank] @ torch.diag(encoder_v_s[:approx_rank]).sqrt()\n",
    "        )\n",
    "        w_v_encoder_loraB_weights.append(\n",
    "            torch.diag(encoder_v_s[:approx_rank]).sqrt() @ encoder_v_v[:approx_rank, :]\n",
    "        )\n",
    "og_weight = SVD_model.roberta.encoder.layer[0].attention.self.query.weight.data.T\n",
    "# insert_lora(SVD_model, 768, approx_rank, lora_alpha)\n",
    "with torch.no_grad():\n",
    "    for i in range(len_of_layers):\n",
    "        SVD_model.roberta.encoder.layer[i].attention.self.query.lora_A.copy_(\n",
    "            w_q_encoder_loraA_weights[i].transpose(0, 1)\n",
    "        )\n",
    "        SVD_model.roberta.encoder.layer[i].attention.self.query.lora_B.copy_(\n",
    "            w_q_encoder_loraB_weights[i].transpose(0, 1)\n",
    "        )\n",
    "        SVD_model.roberta.encoder.layer[i].attention.self.value.lora_A.copy_(\n",
    "            w_v_encoder_loraA_weights[i].transpose(0, 1)\n",
    "        )\n",
    "        SVD_model.roberta.encoder.layer[i].attention.self.value.lora_B.copy_(\n",
    "            w_v_encoder_loraB_weights[i].transpose(0, 1)\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.0732, -0.0019, -0.0901,  ...,  0.1035,  0.0895, -0.1039],\n",
      "        [-0.0503,  0.2062,  0.0739,  ...,  0.0655,  0.0638,  0.1283],\n",
      "        [ 0.0873,  0.0705, -0.0510,  ..., -0.0434, -0.0083,  0.1095],\n",
      "        ...,\n",
      "        [-0.1872,  0.0175, -0.0310,  ..., -0.0509,  0.1026, -0.1170],\n",
      "        [-0.2543,  0.0437,  0.0641,  ...,  0.0709, -0.1043,  0.0117],\n",
      "        [-0.0517, -0.0858,  0.1024,  ..., -0.1888,  0.0034, -0.0538]]) \n",
      " tensor([[ 0.0732, -0.0019, -0.0901,  ...,  0.1035,  0.0895, -0.1039],\n",
      "        [-0.0503,  0.2062,  0.0739,  ...,  0.0655,  0.0638,  0.1283],\n",
      "        [ 0.0873,  0.0705, -0.0510,  ..., -0.0434, -0.0083,  0.1095],\n",
      "        ...,\n",
      "        [-0.1872,  0.0175, -0.0310,  ..., -0.0509,  0.1026, -0.1170],\n",
      "        [-0.2543,  0.0437,  0.0641,  ...,  0.0709, -0.1043,  0.0117],\n",
      "        [-0.0517, -0.0858,  0.1024,  ..., -0.1888,  0.0034, -0.0538]])\n"
     ]
    }
   ],
   "source": [
    "og_weight = model.roberta.encoder.layer[0].attention.self.query.weight.data\n",
    "u,s,vt = torch.linalg.svd(og_weight)\n",
    "print(og_weight,'\\n',u@torch.diag(s)@vt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10.196619</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>9.957478</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8.467140</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7.959620</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7.876126</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>763</th>\n",
       "      <td>0.008453</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>764</th>\n",
       "      <td>0.007697</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>765</th>\n",
       "      <td>0.005820</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>766</th>\n",
       "      <td>0.005240</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>767</th>\n",
       "      <td>0.001830</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>768 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             0\n",
       "0    10.196619\n",
       "1     9.957478\n",
       "2     8.467140\n",
       "3     7.959620\n",
       "4     7.876126\n",
       "..         ...\n",
       "763   0.008453\n",
       "764   0.007697\n",
       "765   0.005820\n",
       "766   0.005240\n",
       "767   0.001830\n",
       "\n",
       "[768 rows x 1 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_s = pd.DataFrame(s.numpy())\n",
    "df_s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      10.196619\n",
       "1       9.957478\n",
       "2       8.467140\n",
       "3       7.959620\n",
       "4       7.876126\n",
       "         ...    \n",
       "763     0.008453\n",
       "764     0.007697\n",
       "765     0.005820\n",
       "766     0.005240\n",
       "767     0.001830\n",
       "Name: 0, Length: 768, dtype: float32"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_s[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAikAAAGdCAYAAADXIOPgAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/NK7nSAAAACXBIWXMAAA9hAAAPYQGoP6dpAAA8TUlEQVR4nO3deXxU9b3/8ffMJJN931cIi4Rd1hhwl4pI3WvVS1vU1lbFrba20P7UWmuxtddirVerrUpvXaq94gougKIoi+z7HiCQnZBMEsg28/39ERiJgIJMcmZ5PR+PeVTOOcn5fB2Zefe7HZsxxggAAMDP2K0uAAAA4FgIKQAAwC8RUgAAgF8ipAAAAL9ESAEAAH6JkAIAAPwSIQUAAPglQgoAAPBLYVYX8GUej0dlZWWKi4uTzWazuhwAAHACjDFqaGhQdna27Hbf9IH4XUgpKytTXl6e1WUAAIBvoLS0VLm5uT75XX4XUuLi4iR1NDI+Pt7iagAAwIlwuVzKy8vzfo/7gt+FlMNDPPHx8YQUAAACjC+najBxFgAA+CVCCgAA8EuEFAAA4Jf8bk4KAACByu12q62tzeoyukx4eLgcDke33Y+QAgCADzQ2NmrPnj0yxlhdSpex2WzKzc1VbGxst9yPkAIAwClyu93as2ePoqOjlZaWFpSbkRpjVF1drT179qhv377d0qNCSAEA4BS1tbXJGKO0tDRFRUVZXU6XSUtL086dO9XW1tYtIYWJswAA+Egw9qAcqbvbR0gBAAB+iZACAAD8EiEFAAD4JUIKAAAh7oknnlDPnj0VGRmpoqIiLV261OqSJIVQSKl0NWv67I2aPmej1aUAAOA3/v3vf+vuu+/W/fffrxUrVmjo0KEaP368qqqqrC4tdJYgN7a0628f71BcRJimTehvdTkAgCBmjNHBNrcl944Kd5zUKpxHH31UN910k2644QZJ0lNPPaV33nlHzz77rKZOndpVZZ6QkAkpSdFOSVJDS7va3B6FO0KmEwkA0M0Otrk14L73LLn3ht+OV7TzxL7eW1tbtXz5ck2bNs17zG63a9y4cVq0aFFXlXjCQuabOiEqXIeDZd2B4H2uAgAAJ6qmpkZut1sZGRmdjmdkZKiiosKiqr5w0j0pH3/8sR555BEtX75c5eXlmjVrli6//HLveWOM7r//fj3zzDOqq6vT2LFj9eSTT6pv376+rPukOew2xUeGq/5gm+oOtCotLsLSegAAwSsq3KENvx1v2b2DxUn3pDQ1NWno0KF64oknjnn+j3/8o/7yl7/oqaee0pIlSxQTE6Px48erubn5lIs9VUnR4ZKk/fSkAAC6kM1mU7QzzJLXycxHSU1NlcPhUGVlZafjlZWVyszM9PW/lpN20iFlwoQJ+t3vfqcrrrjiqHPGGM2YMUP/7//9P1122WUaMmSI/vnPf6qsrEyvv/66L+o9JYmH5qXsP9BqcSUAAFjP6XRqxIgRmjdvnveYx+PRvHnzVFxcbGFlHXw6J6WkpEQVFRUaN26c91hCQoKKioqOOwGnpaVFLper06urHO5JqSOkAAAgSbr77rv1zDPPaObMmdq4caNuueUWNTU1eVf7WMmnq3sOT7I5mQk406dP1wMPPODLMo4ryduTwnAPAACSdM0116i6ulr33XefKioqdPrpp+vdd9896rvcCpav7pk2bZrq6+u9r9LS0i67V3xUR0+K6yAhBQCAw2677Tbt2rVLLS0tWrJkiYqKiqwuSZKPQ8rhSTYnMwEnIiJC8fHxnV5dxWHvmEzk9pguuwcAAPANn4aUgoICZWZmdpqA43K5tGTJEr+YgENIAQAgcJz0nJTGxkZt27bN++eSkhKtWrVKycnJys/P11133aXf/e536tu3rwoKCnTvvfcqOzu7014qVvGGFENIAQDA3510SFm2bJnOO+8875/vvvtuSdLkyZP1/PPP6xe/+IWampr04x//WHV1dTrzzDP17rvvKjIy0ndVf0OOQ2vHPfSkAADg9046pJx77rkyX9ETYbPZ9Nvf/la//e1vT6mwrmCnJwUA0IW+6vsxGHR3+yxf3dOdDvekuD0WFwIACCoOR8dW9K2twb0P1+H2HW5vVwuZpyBL0uEHHzPcAwDwpbCwMEVHR6u6ulrh4eGy24OvD8Dj8ai6ulrR0dEKC+ue+BBSIYXhHgBAV7DZbMrKylJJSYl27dpldTldxm63Kz8//6SeD3QqQiqkMHEWANBVnE6n+vbtG9RDPk6ns1t7iUIrpNCTAgDoQna73S9WswaL4Bs0+wp2G5u5AQAQKEIqpBzuSfHQkwIAgN8LqZBiZ1t8AAACRkiFFPZJAQAgcIRWSDm8TwrDPQAA+L0QCykdzWW4BwAA/xdiIaXjf+lJAQDA/4VUSGEJMgAAgSOkQsrhJcjthBQAAPxeaIUUtsUHACBghFRI4QGDAAAEjpAKKfSkAAAQOEIrpNCTAgBAwAipkPLFtvgWFwIAAL5WSIUUhnsAAAgcIRVSDm04y3APAAABIKRCCj0pAAAEjtAKKUycBQAgYIRmSKEnBQAAvxeSIYXhHgAA/F9IhRTvAwYZ7gEAwO+FVEhxsE8KAAABIyRDioeeFAAA/F5IhRTvcA9zUgAA8HshFVKYOAsAQOAIrZDCxFkAAAJGSIUU77b49KQAAOD3QiqksJkbAACBI7RCCsM9AAAEjJAKKfZDPSnGSIagAgCAXwupkHK4J0ViyAcAAH8XUiHlcE+KxJAPAAD+LqRCStgRIcXD1vgAAPi1kAopDnpSAAAIGCEVUuzMSQEAIGCEVEhxdBruIaQAAODPQiqkHJFRGO4BAMDPhVRIsdls3qBCTwoAAP4tpEKKJIUdeoBPOyEFAAC/FnIhJSKso8kt7axBBgDAn4VeSAl3SJKa29wWVwIAAL5KyIWUyPCOJhNSAADwbyEYUjp6Ug4SUgAA8GshGFIOzUlpY04KAAD+LPRCShhzUgAACAShF1IOT5xtJ6QAAODPQjCkHJ44y3APAAD+LORCCkuQAQAIDCEXUr6Yk0JPCgAA/iz0Qgr7pAAAEBB8HlLcbrfuvfdeFRQUKCoqSr1799aDDz4o4ydPHWbiLAAAgSHM17/wD3/4g5588knNnDlTAwcO1LJly3TDDTcoISFBd9xxh69vd9LYJwUAgMDg85Dy2Wef6bLLLtPEiRMlST179tRLL72kpUuX+vpW3wj7pAAAEBh8PtwzZswYzZs3T1u2bJEkrV69WgsXLtSECROOeX1LS4tcLlenV1eKZHUPAAABwec9KVOnTpXL5VJhYaEcDofcbrceeughTZo06ZjXT58+XQ888ICvyzgu9kkBACAw+Lwn5ZVXXtELL7ygF198UStWrNDMmTP1pz/9STNnzjzm9dOmTVN9fb33VVpa6uuSOkmMdkqSyusPdul9AADAqfF5T8o999yjqVOn6tprr5UkDR48WLt27dL06dM1efLko66PiIhQRESEr8s4riG5CZKkjeUNaml3K+LQHBUAAOBffN6TcuDAAdntnX+tw+GQx+Mfwyv5ydFKig5Xq9ujjeUNVpcDAACOw+ch5ZJLLtFDDz2kd955Rzt37tSsWbP06KOP6oorrvD1rb4Rm82mvulxkqTS2gMWVwMAAI7H58M9jz/+uO69917deuutqqqqUnZ2tn7yk5/ovvvu8/WtvrG0uI7hpeqGFosrAQAAx+PzkBIXF6cZM2ZoxowZvv7VPnM4pNQ0ElIAAPBXIffsHklKje1Y4UNPCgAA/iskQ4p3uIeeFAAA/FZIhxSGewAA8F8hGVLS4yIlSXv3s6EbAAD+KiRDSu+0WNls0v4DbfSmAADgp0IypEQ5HcpPjpYkbalkQzcAAPxRSIYUSd4N3bZVNVpcCQAAOJaQDSm5SVGSpCoXwz0AAPijkA0pSYeehryvqdXiSgAAwLGEbEhJjgmXJO0npAAA4JdCOKR07JVSe4CQAgCAPwrZkJJ0qCellp4UAAD8UsiGlOSYjjkpDPcAAOCfCCkHWuXxGIurAQAAXxa6ISXaKWeYXR4j7dzXZHU5AADgS0I2pIQ57Do9N1GStGzXfmuLAQAARwnZkCJJI3omSZJWEFIAAPA7IR1S+mV0bI3PcA8AAP4npEPK4a3x9+w/aHElAADgy0I8pHQ8Cbm8vlntbo/F1QAAgCOFdEhJj4uQ02GX22NUXt9sdTkAAOAIIR1S7Hab8pI7hny2VTdaXA0AADhSSIcUSRqalyhJWrm7ztI6AABAZyEfUobndyxDXrmbZcgAAPiTkA8pQ3ITJEkbyxssrgQAABwp5ENK77RYSVJNYwsPGwQAwI+EfEiJiQhTTiKTZwEA8DchH1IkqU96R2/KtipCCgAA/oKQInmXIZfVsfMsAAD+gpAiKSvhcEhhQzcAAPwFIUXyzkmhJwUAAP9BSJGUlRApSSqrJ6QAAOAvCCmSsg/1pJTXNcvjMRZXAwAAJEKKpI6elHCHTa1uj8pdzEsBAMAfEFIkhTnsykuOliSVVDdZXA0AAJAIKV4FKTGSpJJ9hBQAAPwBIeWQgtSOkLKDXWcBAPALhJRDTsuMkyRt4kGDAAD4BULKIQOy4iVJG8pdMoYVPgAAWI2QckjfjFiF2W2qP9imsnpW+AAAYDVCyiERYY4j9kthUzcAAKxGSDlCaqxTklTT2GJxJQAAgJByhLS4CElSdQMhBQAAqxFSjkBIAQDAfxBSjpAW2/GgwWqGewAAsBwh5QipcR1zUqpchBQAAKxGSDlCr9RYSdLSnbU62Oq2uBoAAEIbIeUIRQXJykuOUkNzuz7aXGV1OQAAhDRCyhHsdpvOKEiRJG2t4hk+AABYiZDyJb3SOoZ8tvOgQQAALEVI+ZJeaYefhtxkcSUAAIQ2QsqXnJbR8TTkzZUNamppt7gaAABCFyHlS3qmRKtHSrRa2z36kMmzAABYhpDyJTabTRcUZkiSPi+ptbgaAABCFyHlGAozO4Z8dtQwLwUAAKt0SUjZu3evvve97yklJUVRUVEaPHiwli1b1hW36hK90zsmz25nGTIAAJYJ8/Uv3L9/v8aOHavzzjtPc+bMUVpamrZu3aqkpCRf36rL9D60DLmsvlnl9QeVlRBlcUUAAIQen4eUP/zhD8rLy9Nzzz3nPVZQUODr23SpxGinhuQmaM2eev3pvS367+8OtbokAABCjs+He958802NHDlSV199tdLT0zVs2DA988wzx72+paVFLper08sfTJvQX5L0wYYKtbs9FlcDAEDo8XlI2bFjh5588kn17dtX7733nm655Rbdcccdmjlz5jGvnz59uhISEryvvLw8X5f0jYwuSFZidLhcze360/tbrC4HAICQYzPGGF/+QqfTqZEjR+qzzz7zHrvjjjv0+eefa9GiRUdd39LSopaWFu+fXS6X8vLyVF9fr/j4eF+WdtL+/MEWPTZvq5Kiw7XyvgstrQUAAH/mcrmUkJDg0+9vn/ekZGVlacCAAZ2O9e/fX7t37z7m9REREYqPj+/08hc/OqtjLs3+A21qZPdZAAC6lc9DytixY7V58+ZOx7Zs2aIePXr4+lZdLi4yXEnR4ZKk0toDFlcDAEBo8XlI+elPf6rFixfr97//vbZt26YXX3xRTz/9tKZMmeLrW3WL/ORoSdJuQgoAAN3K5yFl1KhRmjVrll566SUNGjRIDz74oGbMmKFJkyb5+lbdIj+lY2O3t9eUy8fTdwAAwFfw+cTZU9UVE29OxdKSWl33zGK5PUYPXj5I3z8j8IatAADoagExcTbYjC5I1j3j+0mSXl567Mm/AADA9wgpJ+A7I3Jls0nry1yqqG+2uhwAAEICIeUEpMZGaFheoiRp3qZKa4sBACBEEFJO0AX9MyRJf/+kRA3NbRZXAwBA8COknKDLTs9WjNOhkpomPbVgu9XlAAAQ9AgpJyg3KVoPXzVEUkdvyord+y2uCACA4EZIOQkXD87SGb2S1dLu0SPvbv76HwAAAN8YIeUkOOw2/enqobLbpEU79mlDmcvqkgAACFqElJOUmxStiwdnSZL+9D69KQAAdBVCyjfwswv7yWG3af6mKi0tqbW6HAAAghIh5RsoSI3RNaPyJEm/+M9qNngDAKALEFK+oTsv6KvE6HDt3HdAD76zwepyAAAIOoSUbygjPlLP3zBakjR7bbme/ng7T0kGAMCHCCmn4PS8RF0/pqeMkX4/e5PeWVtudUkAAAQNQsopuu/bA3TlsBxJ0jMf76A3BQAAHyGknCK73aZfT+yviDC7Vu+p1+IdrPYBAMAXCCk+kBIboatH5kqSJj+7VB9urrK4IgAAAh8hxUd+fmE/xUeGqdXt0ePztlpdDgAAAY+Q4iOJ0U69dfuZkqQVu+v0zhom0QIAcCoIKT7UIyVG4wdmSJKmvLhC015bw0RaAAC+IUKKjz1+3XDddl4f2WzSS0tL9ebqMqtLAgAgIBFSfMwZZtfPx/fTHef3lSS9sGS3xRUBABCYCCld5LuHnu2ztKRWz39awrAPAAAniZDSRXISo3T1iI5lyb95a4MeemejxRUBABBYCCld6I/fGaJpEwpls0l/X1ii/1200+qSAAAIGISULmSz2fSTc3rr7nGnSZLufWM9QQUAgBNESOkGt53fRz8+u5ekjqDyydZqiysCAMD/EVK6gc1m07QJhbpudMdk2nteXaOVu/dbXBUAAP6NkNJNbDabpk7or5zEKFW4mnXlk59pxtwtaml3W10aAAB+iZDSjRKiwvWvHxVpXP90GSPNmLtV3//HUrW5PVaXBgCA3yGkdLOC1Bj9ffIozbjmdEU7HVpaUqvpszdZXRYAAH6HkGKRy4fl6NHvni5JevbTEt38v8vV3MbQDwAAhxFSLHTRoEzdfn4fSdK76yv057lbLK4IAAD/QUix2M8u7KffXT5IkvS3BTt018srtb+p1eKqAACwHiHFD3zvjB6aXNxDkvT6qjJ9688L9MGGSourAgDAWoQUP/HAZYP02q1j1Dc9VjWNrbrpn8s09f/WqKK+2erSAACwBCHFjwzPT9Jbt5+pm84qkCS9/HmpvvXnBdpc0WBxZQAAdD9Cip+JDHfo1xMH6MWbitQnPVYNze26/aUVqj/QZnVpAAB0K0KKnxrTO1Wv/KRYqbFObalsVPHD8zRj7hY1trRbXRoAAN2CkOLHkmOcevb6UcpLjtKBVrdmzN2qSx9fqPVl9VaXBgBAlyOk+LkhuYla8PPzNP3KwYpxOrSjpkk3zVymJnpUAABBjpASAOx2m64bna+3bj9TcZFhKqtv1kWPfax/f75bxhirywMAoEsQUgJIr7RYzbxxtFJjI1Rae1C//L+1evjdTWrnAYUAgCBESAkww/OTNPvOM3XZ6dmSOnapnfT3JTrYynN/AADBhZASgNLjIvXYtcP0l+uGyRlm15KSWp35h/naUOayujQAAHyGkBLALh2arUe/O1QxTof2NbXqu39bpP9dtFNuD/NUAACBj5AS4L49JFufTbtARQXJamxp171vrNeV//Op1u1lmTIAILARUoJAQlS4XrzpDP32soGKiwjT6j31uvSvCzXttbUqqztodXkAAHwjhJQg4bDb9IPinpr3s3N0ydBseYz00tLd+tajC/TPRTvV2s4KIABAYLEZP9tow+VyKSEhQfX19YqPj7e6nID1+c5aTZ+9USt210mSigqS9Y/rRyk2IszawgAAQakrvr/pSQlSo3om69Wbx+j+SwYoNiJMS0pqdcUTn+rddeVWlwYAwAkhpAQxh92mG8YW6MWbipQS49TWqkbd/K8VuuJ/PlWVq9nq8gAA+EqElBAwJDdRc+8+RzeM7SlJWrm7Ttc+vVgrdu+3tjAAAL4CISVEJMU4df8lA/X27WcqNdapHTVN+u5Ti/TUgu1qaWe3WgCA/yGkhJhBOQl65SfFOqtvqto9Rg/P2aRrn16svSxVBgD4mS4PKQ8//LBsNpvuuuuurr4VTlCvtFjNvGG0HvnOECVEhWvl7jqN//PHmvnZTp6qDADwG10aUj7//HP97W9/05AhQ7ryNvgG7Habrh6Zp9enjFX/rHg1trTr/jfX63fvbFRTS7vV5QEA0HUhpbGxUZMmTdIzzzyjpKSkrroNTlFBaoxevblYVw3PlST9Y2GJzv3TR2yrDwCwXJeFlClTpmjixIkaN27cV17X0tIil8vV6YXuFRsRpj9dPUT/M2m48pKjVN3QomufXqxHP9iiPfsPWF0eACBEdUlIefnll7VixQpNnz79a6+dPn26EhISvK+8vLyuKAlfw2az6eLBWXr79rM04NDwz1/mbdVZf/xQv/jPalU3tFhdIgAgxPg8pJSWlurOO+/UCy+8oMjIyK+9ftq0aaqvr/e+SktLfV0STkJCVLjeuv1MPfFfwzWqZ5KMkV5ZtkeX/nWhZq3cw8RaAEC38fmze15//XVdccUVcjgc3mNut1s2m012u10tLS2dzn0Zz+7xL59tr9GdL6/y9qQMzknQw1cN1sDsBIsrAwD4k674/vZ5SGloaNCuXbs6HbvhhhtUWFioX/7ylxo0aNBX/jwhxf/UHWjVvxbv0hMfbtfBNrfsNumC/hm6/5IByk2Ktro8AIAf6Irvb58/EjcuLu6oIBITE6OUlJSvDSjwT4nRTt12fl99d1SefvGfNfpoc7U+2FCp+ZuqdOWwHD14+SBFhh+/dwwAgG+CHWdxwtLjIvX8DaP17l1n6YxeyXJ7jF5dvkfffnyhlu+qtbo8AECQ8flwz6liuCdwLNxao7v+vUo1jS2y2aTvn9FDd1zQV6mxEVaXBgDoZgExJ+VUEVICS92BVv1+9ka9smyPJCkq3KErhufo7m+dRlgBgBDSFd/fDPfglCRGO/XH7wzViz8q0uCcBB1sc+vFJbt18WOf6PWVe+X2+FUGBgAEEHpS4DMej9EHGyv1yHubta2qUZLUPytej183TH3SYy2uDgDQlRjuQUA42OrWs5+W6G8LtsvV3C6bTZowKFN3jTtNp2XEWV0eAKALEFIQUCpdzfr5q6v1ydYa77FvD8nSD88s0LB8HjoJAMGEkIKAtL6sXn/+YKvmbqyUJDnsNl07Kk/n9UvX+YXpstttFlcIADhVhBQEtHV76zVj7hbN3VjlPTa6IFm/u3wQw0AAEOAIKQh4xhh9tn2fXllWqvfXV+pgm1tSx5yVBy8fxLJlAAhQhBQEldLaA/rNm+s1f3OVjJGSosP1/eKe+q/R+cpM+PonaAMA/AchBUFp3d56/fzV1dpU0SBJinE69OOze+t7Z+QrhZ4VAAgIhBQErTa3R2+tLtM/F+3SqtI6SR0TbK8ZladbzumtvGSetgwA/oyQgqDn8Ri9s7Zcz3yyQ2v21EuSIsPtunZUvn4+vp9iI3z+4G4AgA8QUhBSPtteoxlzt2ppSccTlgsz43TTWb106enZCnfwRAcA8CeEFIQcY4ze31Cp215coTZ3x3+qaXERuumsAt10Vi/ZbOyxAgD+gJCCkLWhzKW315TplWV7VNPYIkk6q2+qfnlRoQZmxxNWAMBihBSEvNZ2j/538S49PGejt2dlWH6i/vvqoeqVxkMMAcAqhBTgkF37mvTIe5s1e225PEay2aRLhmRrynl91C+T3WsBoLsRUoAv2Vt3UFP/b433IYbhDpt+UNxTPzmnl9Lj2BAOALoLIQU4jiU79mn6nE3ePVYiw+36zSUDdeHATCXHOK0tDgBCACEF+Aoej9G76ys0fc5GldYelCRFOx2adnF/XX56tuIiwy2uEACCFyEFOAEt7W49Nner3lpT5g0rEWF23XhmgSYOztKgnASLKwSA4ENIAU6Cx2P057lb9MqyUlW6WrzHv3dGvu4ZX6iEKHpWAMBXCCnAN+DxGP1n+R69v6FSczdWSpLiIsJ07eg83XFBX4aBAMAHCCnAKfq/5Xv0yHubVeFqltQxZ+XK4TmaXNxTfdJj2RQOAL4hQgrgA81tbr29plxPLdiubVWN3uM9U6L1x+8M1eiCZAurA4DAREgBfMgYo0Xb9+nJBdu1aPs+tXs6/ipcOTxH3xmRq9E9kxXGgwwB4IQQUoAuUnegVQ+9s1GvLt/jPZYZH6kfn91LV43IZZItAHwNQgrQxRZt36dZK/fo3XUVcjW3S5JiI8L0vTN66MaxPZUezy62AHAshBSgmzS1tOupBds1Z12Fd96K3SadfVqavjMiVxcOyJQzjKEgADiMkAJ0M2OM5m6s0lMLtmv5rv3e46mxEfrx2QX64Zm95LCzIggACCmAhXZUN+r/VuzRK8v2qLqhY3O4/lnxunFsT10xLIdJtgBCGiEF8ANtbo/+s3yPHnx7gw60uiVJfdJj9euJ/XVev3SLqwMAaxBSAD9S6WrWayv26umPt2v/gTZJ0sDseI3rn6FvDcjQwOx4NocDEDIIKYAfcjW36S9zt+q5z3bK7fnir9M5p6XpJ+f00ogeSYoIc1hYIQB0PUIK4Mf2NbZo/qYqzd1YqQ83VavV7ZEkpcdFaOKQLF1+eo4G5yTIzkRbAEGIkAIEiB3Vjfrr/G36eGu1ahpbvcd7pcXoquG5+n5xD8XzYEMAQYSQAgSYlna3PtxUpddXlmnuxkrv1vupsU7ddFYv/fDMAlYFAQgKhBQggO1rbNHsteX6+8IS7dp3QFLHRNtfXFSo4l4pbA4HIKARUoAg0Nru0ayVe/T72ZtUf7BjVVBGfIRuGFugSUX5imMYCEAAIqQAQaS6oUUPz9mkuRsrvWElPjJMPyjuqeuK8pWTGGVxhQBw4ggpQBBqbffojVV79dSC7dpe3eQ9nhrr1LeHZOsn5/RSVgKBBYB/I6QAQczjMXp/Q4WeXbhTy3fv9+65Eu6w6ftn9NR3RuRqQDZ/JwD4J0IKECIamtu0bOd+Pblgu5aW1HqPD8yO19UjcnXZ6TlKinFaWCEAdEZIAUKMMUZvri7TnLUVmrepUm3ujr+uToddd47rq5+c3YslzAD8AiEFCGH7m1r1xqq9emXZHm0od0mS4iLC9K0BGZowOEvnF6bLwW62ACxCSAEgSfqfj7bpmY93eB9sKElD8xL1gzN66Jx+aUqNjbCwOgChiJACwMvtMVq2s1b/Xlaq99dXqrGlXZJks0lXDc/V9WN6alBOgsVVAggVhBQAx7Rn/wG9vLRUH26u0voyl/f4kNwEFfdO0Q/HFig9PtLCCgEEO0IKgK+1aPs+Pf9ZieZvqvJOtA132NQnPU63nttbEwdn8SRmAD5HSAFwwvbWHdTi7fv04tLdWr5rv/d4r9QYTZ1QqHP6pSkizGFhhQCCCSEFwEkzxmh37QE98eE2vbW6XAfb3JKkaKdDY3qn6LzCdF0xLEfRzjCLKwUQyAgpAE5JQ3Ob/vv9LXpnbbmqG1q8x9PiIvSTs3vp2tH5io0grAA4eYQUAD7h8RhtKHdpwZZqvbhkt/bWHZQkJUWH6+ZzeuuaUXlKjGZHWwAnjpACwOf2NbZo5mc79daacpXUdDzg0GG36YxeybpoYKYuPT1HCVHhFlcJwN8FREiZPn26XnvtNW3atElRUVEaM2aM/vCHP6hfv34n9POEFMAa7W6PZq3cq38sLNGmigbv8RinQ+f0S9PPL+ynXmmxFlYIwJ8FREi56KKLdO2112rUqFFqb2/Xr371K61bt04bNmxQTEzM1/48IQWw3q59TXpvfYVeXbZHW6saJXVsEndev3RdPSJXw/KTlJnAvisAvhAQIeXLqqurlZ6ergULFujss8/+2usJKYD/8HiMFpfs098W7NCCLdXe43abdP2YAn17aJaG5ibyzCAAXfL93eXT+Ovr6yVJycnJXX0rAD5mt9s0pneqxvRO1Y7qRr2wZLfmb6pSSU2Tnv20RM9+WqLshEhdenqOvl/cQzmJUVaXDCCIdGlPisfj0aWXXqq6ujotXLjwmNe0tLSopeWLpZAul0t5eXn0pAB+yhijN1aV6Z215Vq8Y58amjueGeQMs6u4V4ouHZqtK4blsKstEGICbrjnlltu0Zw5c7Rw4ULl5uYe85rf/OY3euCBB446TkgB/F9zm1vvb6jUC4t3aUlJrfd4WlyELhyQoYsGZeqMXikKd9gtrBJAdwiokHLbbbfpjTfe0Mcff6yCgoLjXkdPChD4jDFau7de76+v1MzPdqrh0BOZJSkrIVLjB2bqe2f0UJ90VgcBwSogQooxRrfffrtmzZqljz76SH379j2pn2fiLBDYWts9+mx7jd5bX6n311doX1OrJCk2IkyXD8vWdaPzNTA7weIqAfhaQISUW2+9VS+++KLeeOONTnujJCQkKCrq6yfVEVKA4HF4OOiJ+du0ubJj7xWbTRqck6DT8xI1PD9JFw7M4LlBQBAIiJBisx17stxzzz2n66+//mt/npACBJ/mNrfmbqzUnLUVemdteadzuUlR+q+ifF08KEs9U79+LyUA/ikgQsqpIqQAwa2s7qCW79qvVaV1mr22XOX1zd5zRQXJun5MT13QP0POMCbbAoGEkAIgqLia2/T8pzu1tKRWn22vkefQp1F6XIQmFfXQNaPy2NkWCBCEFABBq7z+oJ77dKdeX7lXVQ0dK/7sNumsvmm644I+Gp6fdNzhZADWI6QACHqt7R7NWVeuFxbv1tKdX+y9kpccpXNPS9fZp6WpuHeKYiOYbAv4E0IKgJCys6ZJj8/fpnfWlqm5zeM9Hu6w6YxeKfrhmQUa2yeVzeIAP0BIARCSmlra9dn2ffp4S7U+2lKl0tqD3nPxkWE6vzBd4wdm6qzT0uhhASxCSAEQ8owxKqlp0szPduqdteWqaWz1nrPbpAsHZOrmc3vr9LxE64oEQhAhBQCO4PYYrdi9X++vr9D7Gyq1a98B77kRPZI0rn+GJo/pwWZxQDcgpADAV9hS2aCnP96hN1btVZu746Mt2unQeYXpmjg4S+f2SyOwAF2EkAIAJ6C8/qBmrdyrl5eWanftF70rUeEOnVeYpjP7pGlIboIG5fAMIcBXCCkAcBKMMVqzp16z15Vr9tryThNuJelbAzI0qSifFUKADxBSAOAbMsZo3V6X5qwr17oylz7dViP3oS1uE6PDdfHgLN16bm/lJkVbXCkQmAgpAOAjWyob9L+LdmnOus4rhAbnJHgn3Y4uSOYZQsAJIqQAgI+5PUaLd+zTEx9u06Id+3TkJ2JWQqRuPqe3rhqRy/4rwNcgpABAF6pyNWtxSa0Wbq3WW6vLdbDNLUmy2aTeabE697Q0TRicqWF5SbLbeY4QcCRCCgB0E1dzm/61eJdeWrr7qAm3GfERumhgpi4alKXRBclyEFgAQgoAWKG6oUXLd9Xq3XUVmruxSo0t7d5zqbFOfWtApi4alKmhuQlKjHZaWClgHUIKAFispd2tT7fVaPbaCn2woVL1B9u85+w26dKh2bp4cJbG9EllHgtCCiEFAPxIm9ujxTv2afbaCs3bWKmqhhbvuXCHTeeclqaighSd0y9Np2XEWVgp0PUIKQDgx1bs3q83V5Vp3qbKo+axXDggQ+MHZur8wnQlxTAkhOBDSAGAAGCM0ebKBs1ZW6E1e+r04eZq7zm7TRpdkKzzC9N11fBcpcRGWFgp4DuEFAAIQOvL6vXeuo4nNW+qaOh0bmhugn5xUaGKe6WwrBkBjZACAAFuW1Wj3ltfobfXlGtjuct7PMbp0EWDsjQkN0Fj+6Sod1qsbDZCCwIHIQUAgkhVQ7Men7dN//68VK1uT6dz+cnROr8wXecXpquoV7IiwhwWVQmcGEIKAAShNrdHC7fW6OOt1dpW1aglO2o7hZZop0Nn9knV1SPzdH5hOpvHwS8RUgAgBDS1tOvTbTWav6lK8zdVdVraHBsRpuE9kjRxcKYuGpilhOhwCysFvkBIAYAQ4/EYbSh3adbKvfr356WddruVpJE9kvRfRfkq6pWinMQoi6oECCkAENLcHqPNFQ36aEuV/rNsj3bUNHU6n5MYpaKCZJ1XmK5z+qUpPpJeFnQfQgoAwKvS1aznPt2pRdtrtK7MJbfni4/zMLtNowuSdUH/DJ3bL015SdFyhtktrBbBjpACADimppZ2rdi9Xwu31mjuxkptr+7cyxLtdOiigZm6bFiOigqSFRnOaiH4FiEFAHBCdtY0ad6mKs3bWKmlJbVqP6KXJS4iTKfnJ+q8fun6r6J8Agt8gpACADhpHo/RytI6vbFqr95dV9FptZAkFfdK0cVDsnR+YbqyEyLZRA7fCCEFAHBKPB6jVXvqtGp3nZ7+eIcqXM2dzqfFRejK4Tm6ZEi2BmbHE1hwwggpAACfcXuMSmoaNXdjlWavLdf6L02+zYyP1HmF6RrXP13FvVMU7QyzsFr4O0IKAKDLHGx165215Xpj1V4t27lfB9vc3nMOu01902N1ydBsXTk8R5nxDAuhM0IKAKBbNLe5tXjHPs3fVKV5G6u0t+5gp/M5iVE6q2+qzitM15l9UhUTQS9LqCOkAAAsUVHfrE+2VuuZT3Zoa1WjjvzmcDrsGtMnReP6Z2hAdrwGZMWzYigEEVIAAJY70NqupSW1+mhzteZvqtLu2gOdzjvD7BrZI0mXD8vRxMFZ9LKECEIKAMCvGGO0rapR72+o1Gfba7S5okE1ja3e806HXYNy4nXRoEydX5iuXqmxsvMU56BESAEA+DVjjHbUNOnddRV6dVmpdu7r3MuSmxSlwsx4TRySqcuG5hBYggghBQAQMIwx2l17QB9uqtKsVWXaVO5SS7vHez4y3N4RWAZnqbh3igZkxRNaAhghBQAQsFzNbVpdWqfFO/bp2YU7Oy1xlqSIMLtGFyTrquG5uqB/uuJ4inNAIaQAAIJCm9uj3bUH9Nm2Gr2/ofKofVminQ6N7JmsM3ol69zT0tUrLYYVQ36OkAIACErtbo927mvSrJV7NXtthUpqOj/F2emwa3iPRJ3VN03jB2aqT3qsRZXieAgpAICg5/EYba5s0OId+/TR5mqt2LVfDS3tna5Ji4tQ3/RYXTw4S1cNz1WUk14WqxFSAAAhaUOZSytL9+uDDZX6dFuN2txffHXFOB0aNyBDY3un6vz+6UqNjbCw0tBFSAEAhLymlnZtrWrUsp21mrlop0prv9iy3+mwa0SPJJ3ZN1Vn9knVoJwEOVgx1C0IKQAAHMEYo5WldXp/faU+2Vqt9WWuTucTosI1pneKeqTEaGhugs7tl87QUBchpAAAcByHN5L7dFuNPtlao8Xb9x01lyUq3KGiXskalpek8wvT1T8rTmEOu0UVBxdCCgAAJ6jd7dHqPfVaWlKrsrqD+nBzlfbs7/w0Z6fDrv7Z8bpkSJZG9kzWoOx4Qss3REgBAOAbMsZoQ7lLS0tqtWRHrT7ZWq2m1s4byiVGh+usvmkqzIzT6IJkDcpOYHjoBBFSAADwEY/HaM/+g1qwpUrvb6jUmj31qj/Y1ukaZ5hdxb1SdF6/NA3OTdDA7AQ2lTsOQgoAAF2k3e3Rsl37tWxnrdaXubR8135VNbR0uiY+MkwDsuM1umeyeqfH6vxCtu8/jJACAEA3McZo7d56fbptn5aU7NO6vfWqaWztdI3NJhWkxKh/drwGZMXr9LxEjeqZLGdY6M1rIaQAAGCRdrdHa/bWa0OZS2v21GnZzv3a8aXt+yXJYbdpQFa8zj4tVf0y4zWmd0pIbDBHSAEAwI9UN7RoY7lLG8pdWl/m0qLt+1TT2HLUdckxTmXGR6pHSrQKUmPUKy1WvdJi1Ds1VgnRwTFcFFAh5YknntAjjzyiiooKDR06VI8//rhGjx79tT9HSAEABCqPx6is/qAWbq3RqtI6rd5Tr43lrq/8mZQY56Hgcii8HPrn/OSYgBo2CpiQ8u9//1s/+MEP9NRTT6moqEgzZszQq6++qs2bNys9Pf0rf5aQAgAIJnUHWlVe36zy+oMqqTmgHdWNKqlp0o7qJlW4mo/7czabFB8Zroz4COUlRSsvOVo9UqI1ICte2YlRSouL8KuVRgETUoqKijRq1Cj99a9/lSR5PB7l5eXp9ttv19SpU7/yZwkpAIBQ0dTS3hFYapq0o7pRO6qbDgWYxqP2cDmWhKhwZcZHKj0+QskxTiXHONUvI045SR0hJjU2QsnRTtm74flFXfH9HeaT33KE1tZWLV++XNOmTfMes9vtGjdunBYtWuTr2wEAELBiIsI0KCdBg3ISOh03xmhfU6tqm1pVUd+s0v0HtHvfAW2vbtLGcpeqG1vU2u5R/cE21R9s0+bKhuPew2G3KSXGqdTYCKXFRSgzPlI9U2N0y7m9u7p5p8znIaWmpkZut1sZGRmdjmdkZGjTpk1HXd/S0qKWli8mGblcXz12BwBAsLPZbEqN7egJOS0j7qjzxhi5mttV6WpWRX2zKl3Nqj/Ypor6Zm2ubFCVq0XVjS2qbWqV22NU1dDSsedLecfP9wrVkHKypk+frgceeMDqMgAACBg2m00JUeFKiAo/Zog5rM3tUW1Tq6obWryv8vpmRQfIVv8+DympqalyOByqrKzsdLyyslKZmZlHXT9t2jTdfffd3j+7XC7l5eX5uiwAAEJOuMOujPhIZcRHWl3KN+LztU1Op1MjRozQvHnzvMc8Ho/mzZun4uLio66PiIhQfHx8pxcAAECXDPfcfffdmjx5skaOHKnRo0drxowZampq0g033NAVtwMAAEGoS0LKNddco+rqat13332qqKjQ6aefrnffffeoybQAAADHw7b4AADglHXF93fg7LcLAABCCiEFAAD4JUIKAADwS4QUAADglwgpAADALxFSAACAXyKkAAAAv0RIAQAAfomQAgAA/FKXbIt/Kg5vgOtyuSyuBAAAnKjD39u+3Mje70JKQ0ODJCkvL8/iSgAAwMlqaGhQQkKCT36X3z27x+PxqKysTHFxcbLZbD793S6XS3l5eSotLQ365wKFSltDpZ0SbQ1WtDX4hEo7pc5tjYuLU0NDg7Kzs2W3+2Y2id/1pNjtduXm5nbpPeLj44P+P5zDQqWtodJOibYGK9oafEKlndIXbfVVD8phTJwFAAB+iZACAAD8UkiFlIiICN1///2KiIiwupQuFyptDZV2SrQ1WNHW4BMq7ZS6vq1+N3EWAABACrGeFAAAEDgIKQAAwC8RUgAAgF8ipAAAAL8UMiHliSeeUM+ePRUZGamioiItXbrU6pJO2scff6xLLrlE2dnZstlsev311zudN8bovvvuU1ZWlqKiojRu3Dht3bq10zW1tbWaNGmS4uPjlZiYqB/+8IdqbGzsxlZ8venTp2vUqFGKi4tTenq6Lr/8cm3evLnTNc3NzZoyZYpSUlIUGxurq666SpWVlZ2u2b17tyZOnKjo6Gilp6frnnvuUXt7e3c25Ws9+eSTGjJkiHcjpOLiYs2ZM8d7PljaeSwPP/ywbDab7rrrLu+xYGnvb37zG9lstk6vwsJC7/lgaack7d27V9/73veUkpKiqKgoDR48WMuWLfOeD5bPpZ49ex71ntpsNk2ZMkVScL2nbrdb9957rwoKChQVFaXevXvrwQcf7PRMnm57X00IePnll43T6TTPPvusWb9+vbnppptMYmKiqaystLq0kzJ79mzz61//2rz22mtGkpk1a1an8w8//LBJSEgwr7/+ulm9erW59NJLTUFBgTl48KD3mosuusgMHTrULF682HzyySemT58+5rrrruvmlny18ePHm+eee86sW7fOrFq1ylx88cUmPz/fNDY2eq+5+eabTV5enpk3b55ZtmyZOeOMM8yYMWO859vb282gQYPMuHHjzMqVK83s2bNNamqqmTZtmhVNOq4333zTvPPOO2bLli1m8+bN5le/+pUJDw8369atM8YETzu/bOnSpaZnz55myJAh5s477/QeD5b23n///WbgwIGmvLzc+6qurvaeD5Z21tbWmh49epjrr7/eLFmyxOzYscO89957Ztu2bd5rguVzqaqqqtP7+cEHHxhJ5sMPPzTGBM97aowxDz30kElJSTFvv/22KSkpMa+++qqJjY01jz32mPea7npfQyKkjB492kyZMsX7Z7fbbbKzs8306dMtrOrUfDmkeDwek5mZaR555BHvsbq6OhMREWFeeuklY4wxGzZsMJLM559/7r1mzpw5xmazmb1793Zb7SerqqrKSDILFiwwxnS0Kzw83Lz66qveazZu3GgkmUWLFhljOgKd3W43FRUV3muefPJJEx8fb1paWrq3AScpKSnJ/P3vfw/adjY0NJi+ffuaDz74wJxzzjnekBJM7b3//vvN0KFDj3kumNr5y1/+0px55pnHPR/Mn0t33nmn6d27t/F4PEH1nhpjzMSJE82NN97Y6diVV15pJk2aZIzp3vc16Id7WltbtXz5co0bN857zG63a9y4cVq0aJGFlflWSUmJKioqOrUzISFBRUVF3nYuWrRIiYmJGjlypPeacePGyW63a8mSJd1e84mqr6+XJCUnJ0uSli9frra2tk5tLSwsVH5+fqe2Dh48WBkZGd5rxo8fL5fLpfXr13dj9SfO7Xbr5ZdfVlNTk4qLi4O2nVOmTNHEiRM7tUsKvvd169atys7OVq9evTRp0iTt3r1bUnC1880339TIkSN19dVXKz09XcOGDdMzzzzjPR+sn0utra3617/+pRtvvFE2my2o3lNJGjNmjObNm6ctW7ZIklavXq2FCxdqwoQJkrr3ffW7Bwz6Wk1Njdxud6f/MCQpIyNDmzZtsqgq36uoqJCkY7bz8LmKigqlp6d3Oh8WFqbk5GTvNf7G4/Horrvu0tixYzVo0CBJHe1wOp1KTEzsdO2X23qsfxeHz/mTtWvXqri4WM3NzYqNjdWsWbM0YMAArVq1KqjaKUkvv/yyVqxYoc8///yoc8H0vhYVFen5559Xv379VF5ergceeEBnnXWW1q1bF1Tt3LFjh5588kndfffd+tWvfqXPP/9cd9xxh5xOpyZPnhy0n0uvv/666urqdP3110sKrv92JWnq1KlyuVwqLCyUw+GQ2+3WQw89pEmTJknq3u+boA8pCGxTpkzRunXrtHDhQqtL6TL9+vXTqlWrVF9fr//85z+aPHmyFixYYHVZPldaWqo777xTH3zwgSIjI60up0sd/n+ckjRkyBAVFRWpR48eeuWVVxQVFWVhZb7l8Xg0cuRI/f73v5ckDRs2TOvWrdNTTz2lyZMnW1xd1/nHP/6hCRMmKDs72+pSusQrr7yiF154QS+++KIGDhyoVatW6a677lJ2dna3v69BP9yTmpoqh8Nx1CzryspKZWZmWlSV7x1uy1e1MzMzU1VVVZ3Ot7e3q7a21i//Xdx22216++239eGHHyo3N9d7PDMzU62traqrq+t0/Zfbeqx/F4fP+ROn06k+ffpoxIgRmj59uoYOHarHHnss6Nq5fPlyVVVVafjw4QoLC1NYWJgWLFigv/zlLwoLC1NGRkZQtfdIiYmJOu2007Rt27agel+zsrI0YMCATsf69+/vHdoKxs+lXbt2ae7cufrRj37kPRZM76kk3XPPPZo6daquvfZaDR48WN///vf105/+VNOnT5fUve9r0IcUp9OpESNGaN68ed5jHo9H8+bNU3FxsYWV+VZBQYEyMzM7tdPlcmnJkiXedhYXF6uurk7Lly/3XjN//nx5PB4VFRV1e83HY4zRbbfdplmzZmn+/PkqKCjodH7EiBEKDw/v1NbNmzdr9+7dndq6du3aTn9JPvjgA8XHxx/1oepvPB6PWlpagq6dF1xwgdauXatVq1Z5XyNHjtSkSZO8/xxM7T1SY2Ojtm/frqysrKB6X8eOHXvU9gBbtmxRjx49JAXX59Jhzz33nNLT0zVx4kTvsWB6TyXpwIEDsts7xwOHwyGPxyOpm9/XU5gAHDBefvllExERYZ5//nmzYcMG8+Mf/9gkJiZ2mmUdCBoaGszKlSvNypUrjSTz6KOPmpUrV5pdu3YZYzqWhCUmJpo33njDrFmzxlx22WXHXBI2bNgws2TJErNw4ULTt29fv1vqd8stt5iEhATz0UcfdVryd+DAAe81N998s8nPzzfz5883y5YtM8XFxaa4uNh7/vByvwsvvNCsWrXKvPvuuyYtLc3vlvtNnTrVLFiwwJSUlJg1a9aYqVOnGpvNZt5//31jTPC083iOXN1jTPC092c/+5n56KOPTElJifn000/NuHHjTGpqqqmqqjLGBE87ly5dasLCwsxDDz1ktm7dal544QUTHR1t/vWvf3mvCZbPJWM6Vobm5+ebX/7yl0edC5b31BhjJk+ebHJycrxLkF977TWTmppqfvGLX3iv6a73NSRCijHGPP744yY/P984nU4zevRos3jxYqtLOmkffvihkXTUa/LkycaYjmVh9957r8nIyDARERHmggsuMJs3b+70O/bt22euu+46Exsba+Lj480NN9xgGhoaLGjN8R2rjZLMc889573m4MGD5tZbbzVJSUkmOjraXHHFFaa8vLzT79m5c6eZMGGCiYqKMqmpqeZnP/uZaWtr6+bWfLUbb7zR9OjRwzidTpOWlmYuuOACb0AxJnjaeTxfDinB0t5rrrnGZGVlGafTaXJycsw111zTae+QYGmnMca89dZbZtCgQSYiIsIUFhaap59+utP5YPlcMsaY9957z0g6qn5jgus9dblc5s477zT5+fkmMjLS9OrVy/z617/utFS6u95XmzFHbCEHAADgJ4J+TgoAAAhMhBQAAOCXCCkAAMAvEVIAAIBfIqQAAAC/REgBAAB+iZACAAD8EiEFAAD4JUIKAADwS4QUAADglwgpAADALxFSAACAX/r/L8TLC45uj6IAAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_s.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>768.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>2.209294</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.757067</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.001830</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.746821</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>1.869588</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>3.358775</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>10.196619</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                0\n",
       "count  768.000000\n",
       "mean     2.209294\n",
       "std      1.757067\n",
       "min      0.001830\n",
       "25%      0.746821\n",
       "50%      1.869588\n",
       "75%      3.358775\n",
       "max     10.196619"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_s.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'Singular Values')"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "approx_rank = 768\n",
    "plt.bar(range(approx_rank), s[:approx_rank])\n",
    "plt.xlabel('Singular Value Index')\n",
    "plt.ylabel('Singular Value')\n",
    "plt.title('Singular Values')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Int64Index([1, 2, 3, 5, 6, 7, 9, 11, 12, 13, 15, 17, 19, 23], dtype='int64')\n"
     ]
    }
   ],
   "source": [
    "# 값의 차분 계산\n",
    "df_s['difference'] = df_s[0].diff()\n",
    "\n",
    "# 값이 급격하게 변하는 구간 확인\n",
    "threshold = 0.1# 원하는 임계값 설정. 이 값을 기준으로 변화량을 판단.\n",
    "large_diff_indices = df_s[df_s['difference'].abs() > threshold].index\n",
    "\n",
    "print(large_diff_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_s['difference'][:128].abs().plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(27.7128), tensor(78.2083), tensor(27.7128))"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.norm(u),torch.norm(torch.diag(s)),torch.norm(vt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>127.888741</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>74.773071</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>71.333099</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>67.454742</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>66.180603</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            0\n",
       "0  127.888741\n",
       "1   74.773071\n",
       "2   71.333099\n",
       "3   67.454742\n",
       "4   66.180603"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_s_sum = pd.DataFrame(s.numpy())\n",
    "df_s_sum.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(95.9664) tensor(667.1432) tensor(95.8177)\n"
     ]
    }
   ],
   "source": [
    "for i in range(1,12):\n",
    "    og_weight = model.roberta.encoder.layer[i].attention.self.query.weight.data\n",
    "    u_temp,s_temp,vt_temp = torch.linalg.svd(og_weight)\n",
    "    u+=u_temp\n",
    "    s+=s_temp\n",
    "    vt+=vt_temp\n",
    "print(torch.norm(u),torch.norm(torch.diag(s)),torch.norm(vt))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at textattack/roberta-base-SST-2 were not used when initializing RobertaForSequenceClassification: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "- This IS expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RobertaForSequenceClassification(\n",
       "  (roberta): RobertaModel(\n",
       "    (embeddings): RobertaEmbeddings(\n",
       "      (word_embeddings): Embedding(50265, 768, padding_idx=1)\n",
       "      (position_embeddings): Embedding(514, 768, padding_idx=1)\n",
       "      (token_type_embeddings): Embedding(1, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): RobertaEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0): RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (1): RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (2): RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (3): RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (4): RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (5): RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (6): RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (7): RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (8): RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (9): RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (10): RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (11): RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (classifier): RobertaClassificationHead(\n",
       "    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "    (out_proj): Linear(in_features=768, out_features=2, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = AutoModelForSequenceClassification.from_pretrained(\n",
    "        'textattack/roberta-base-SST-2'\n",
    "    )\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_model= copy.deepcopy(AutoModelForSequenceClassification.from_pretrained(\n",
    "        'textattack/roberta-base-SST-2'\n",
    "    ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def insert_lora(model, dim, rank, lora_alpha):\n",
    "    len_of_layers = 12  # len(model.roberta.encoder)\n",
    "    for i in range(len_of_layers):\n",
    "        model.roberta.encoder.layer[i].attention.self.query = copy.deepcopy(\n",
    "            lora.Linear(dim, dim, r=rank, lora_alpha=lora_alpha, merge_weights=False)\n",
    "        )\n",
    "        model.roberta.encoder.layer[i].attention.self.value = copy.deepcopy(\n",
    "            lora.Linear(dim, dim, r=rank, lora_alpha=lora_alpha, merge_weights=False)\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([768, 768])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(model.roberta.encoder.layer[0].attention.self.value.weight.data).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_q_original_weight = model.roberta.encoder.layer[0].attention.self.query.weight.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dW_init_by_SVD(model, SVD_model, rank):\n",
    "    w_q_encoder_loraA_weights = []\n",
    "    w_q_encoder_loraB_weights = []\n",
    "\n",
    "    w_v_encoder_loraA_weights = []\n",
    "    w_v_encoder_loraB_weights = []\n",
    "\n",
    "    len_of_layers = 12  # len(SVD_model.roberta.encoder.layer)\n",
    "    with torch.no_grad():\n",
    "        for i in range(len_of_layers):\n",
    "            encoder_q_original_weight = SVD_model.roberta.encoder.layer[i].attention.self.query.weight.data\n",
    "            encoder_v_original_weight = SVD_model.roberta.encoder.layer[i].attention.self.value.weight.data\n",
    "\n",
    "            encoder_q_u, encoder_q_s, encoder_q_v = torch.linalg.svd(encoder_q_original_weight)\n",
    "            encoder_v_u, encoder_v_s, encoder_v_v = torch.linalg.svd(encoder_v_original_weight)\n",
    "\n",
    "            approx_rank = rank\n",
    "\n",
    "            # w_q_encoder\n",
    "            # torch.Size([768, rank])\n",
    "            w_q_encoder_loraA_weights.append(\n",
    "                encoder_q_u[:, :approx_rank] @ torch.diag(encoder_q_s[:approx_rank]).sqrt()\n",
    "            )\n",
    "            # torch.Size([rank, 768])\n",
    "            w_q_encoder_loraB_weights.append(\n",
    "                torch.diag(encoder_q_s[:approx_rank]).sqrt() @ encoder_q_v[:approx_rank, :]\n",
    "            )\n",
    "            # w_v_encoder\n",
    "            w_v_encoder_loraA_weights.append(\n",
    "                encoder_v_u[:, :approx_rank] @ torch.diag(encoder_v_s[:approx_rank]).sqrt()\n",
    "            )\n",
    "            w_v_encoder_loraB_weights.append(\n",
    "                torch.diag(encoder_v_s[:approx_rank]).sqrt() @ encoder_v_v[:approx_rank, :]\n",
    "            )\n",
    "    og_weight = SVD_model.roberta.encoder.layer[0].attention.self.query.weight.data\n",
    "    # insert_lora(SVD_model, 768, approx_rank, lora_alpha)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for i in range(len_of_layers):\n",
    "            model.roberta.encoder.layer[i].attention.self.query.lora_A.copy_(\n",
    "                w_q_encoder_loraA_weights[i].transpose(0, 1)\n",
    "            )\n",
    "            model.roberta.encoder.layer[i].attention.self.query.lora_B.copy_(\n",
    "                w_q_encoder_loraB_weights[i].transpose(0, 1)\n",
    "            )\n",
    "\n",
    "            model.roberta.encoder.layer[i].attention.self.value.lora_A.copy_(\n",
    "                w_v_encoder_loraA_weights[i].transpose(0, 1)\n",
    "            )\n",
    "            model.roberta.encoder.layer[i].attention.self.value.lora_B.copy_(\n",
    "                w_v_encoder_loraB_weights[i].transpose(0, 1)\n",
    "            )\n",
    "    print(f\"OG weight Norm : {torch.linalg.norm(og_weight)}\")\n",
    "    approx_weight = (\n",
    "        model.roberta.encoder.layer[0].attention.self.query.lora_A.T\n",
    "        @ model.roberta.encoder.layer[0].attention.self.query.lora_B.T\n",
    "    )\n",
    "    print(f\"recon error between OG and rank_{approx_rank} SVD weight : {recon_error(og_weight,approx_weight)} \")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def W_init_by_loraAB(model, lora_model):\n",
    "    \"\"\"\n",
    "    model의 W weight를 lora_model의 Lora Layer의 weight로 초기화\n",
    "    \"\"\"\n",
    "    len_of_layers = 12\n",
    "    loraA_q_encoder_weight_list = []\n",
    "    loraB_q_encoder_weight_list = []\n",
    "\n",
    "    loraA_v_encoder_weight_list = []\n",
    "    loraB_v_encoder_weight_list = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for i in range(len_of_layers):\n",
    "            loraA_q_encoder_new_weight = lora_model.roberta.encoder.layer[i].attention.self.query.lora_A\n",
    "            loraA_q_encoder_weight_list.append(loraA_q_encoder_new_weight)\n",
    "            loraB_q_encoder_new_weight = lora_model.roberta.encoder.layer[i].attention.self.query.lora_B\n",
    "            loraB_q_encoder_weight_list.append(loraB_q_encoder_new_weight)\n",
    "\n",
    "            loraA_v_encoder_new_weight = lora_model.roberta.encoder.layer[i].attention.self.value.lora_A\n",
    "            loraA_v_encoder_weight_list.append(loraA_v_encoder_new_weight)\n",
    "            loraB_v_encoder_new_weight = lora_model.roberta.encoder.layer[i].attention.self.value.lora_B\n",
    "            loraB_v_encoder_weight_list.append(loraB_v_encoder_new_weight)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for i in range(len_of_layers):\n",
    "            model.roberta.encoder.layer[i].attention.self.query.weight.copy_(\n",
    "                (loraA_q_encoder_weight_list[i].T @ loraB_q_encoder_weight_list[i].T).T\n",
    "            )\n",
    "\n",
    "            model.roberta.encoder.layer[i].attention.self.value.weight.copy_(\n",
    "                (loraA_v_encoder_weight_list[i].T @ loraB_v_encoder_weight_list[i].T).T\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.0732, -0.0019, -0.0901,  ...,  0.1035,  0.0895, -0.1039],\n",
       "        [-0.0503,  0.2062,  0.0739,  ...,  0.0655,  0.0638,  0.1283],\n",
       "        [ 0.0873,  0.0705, -0.0510,  ..., -0.0434, -0.0083,  0.1095],\n",
       "        ...,\n",
       "        [-0.1872,  0.0175, -0.0310,  ..., -0.0509,  0.1026, -0.1170],\n",
       "        [-0.2543,  0.0437,  0.0641,  ...,  0.0709, -0.1043,  0.0117],\n",
       "        [-0.0517, -0.0858,  0.1024,  ..., -0.1888,  0.0034, -0.0538]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.roberta.encoder.layer[0].attention.self.query.weight.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(6.5303, grad_fn=<CopyBackwards>) tensor(0., grad_fn=<CopyBackwards>)\n",
      "tensor(6.5065, grad_fn=<CopyBackwards>) tensor(0., grad_fn=<CopyBackwards>)\n",
      "tensor(6.5388, grad_fn=<CopyBackwards>) tensor(0., grad_fn=<CopyBackwards>)\n",
      "tensor(6.5455, grad_fn=<CopyBackwards>) tensor(0., grad_fn=<CopyBackwards>)\n",
      "tensor(6.5329, grad_fn=<CopyBackwards>) tensor(0., grad_fn=<CopyBackwards>)\n",
      "tensor(6.5359, grad_fn=<CopyBackwards>) tensor(0., grad_fn=<CopyBackwards>)\n",
      "tensor(6.5215, grad_fn=<CopyBackwards>) tensor(0., grad_fn=<CopyBackwards>)\n",
      "tensor(6.5400, grad_fn=<CopyBackwards>) tensor(0., grad_fn=<CopyBackwards>)\n",
      "tensor(6.5258, grad_fn=<CopyBackwards>) tensor(0., grad_fn=<CopyBackwards>)\n",
      "tensor(6.5298, grad_fn=<CopyBackwards>) tensor(0., grad_fn=<CopyBackwards>)\n",
      "tensor(6.5322, grad_fn=<CopyBackwards>) tensor(0., grad_fn=<CopyBackwards>)\n",
      "tensor(6.5349, grad_fn=<CopyBackwards>) tensor(0., grad_fn=<CopyBackwards>)\n",
      "Parameter containing:\n",
      "tensor([[-0.0015,  0.0225,  0.0280,  ..., -0.0284, -0.0101,  0.0257],\n",
      "        [-0.0154, -0.0053,  0.0193,  ..., -0.0130, -0.0153,  0.0278],\n",
      "        [-0.0181,  0.0082,  0.0032,  ..., -0.0080,  0.0014,  0.0004],\n",
      "        ...,\n",
      "        [ 0.0102,  0.0158,  0.0357,  ...,  0.0264, -0.0264, -0.0181],\n",
      "        [-0.0002,  0.0185,  0.0289,  ..., -0.0263, -0.0175, -0.0354],\n",
      "        [ 0.0055,  0.0208,  0.0156,  ..., -0.0243,  0.0203,  0.0143]],\n",
      "       requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "insert_lora(model, 768, 128, 128)\n",
    "for i in range(12):\n",
    "    print(torch.norm(model.roberta.encoder.layer[i].attention.self.query.lora_A),torch.norm(model.roberta.encoder.layer[i].attention.self.query.lora_B))\n",
    "print(model.roberta.encoder.layer[0].attention.self.query.lora_A)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter containing:\n",
      "tensor([[-1.9966e-02, -2.0107e-02,  1.0792e-02,  ..., -1.8989e-02,\n",
      "          3.4663e-02, -1.8569e-02],\n",
      "        [ 2.4267e-02, -2.2216e-02, -3.4597e-03,  ..., -6.8253e-05,\n",
      "         -1.4426e-02,  3.3981e-02],\n",
      "        [ 1.2890e-02, -4.0622e-03,  1.5104e-02,  ...,  8.1993e-03,\n",
      "          1.2184e-02, -2.1274e-02],\n",
      "        ...,\n",
      "        [ 1.7017e-02, -6.0550e-03, -3.2701e-02,  ..., -1.6243e-02,\n",
      "         -5.2863e-03,  3.4739e-02],\n",
      "        [-3.4334e-02,  1.9611e-02, -6.6544e-03,  ..., -3.2922e-02,\n",
      "          1.4811e-02,  3.4774e-02],\n",
      "        [-2.8915e-02, -2.9844e-02,  2.8870e-02,  ...,  4.2270e-04,\n",
      "          2.9687e-03, -5.4101e-03]], requires_grad=True) Parameter containing:\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[-1.9966e-02, -2.0107e-02,  1.0792e-02,  ..., -1.8989e-02,\n",
      "          3.4663e-02, -1.8569e-02],\n",
      "        [ 2.4267e-02, -2.2216e-02, -3.4597e-03,  ..., -6.8253e-05,\n",
      "         -1.4426e-02,  3.3981e-02],\n",
      "        [ 1.2890e-02, -4.0622e-03,  1.5104e-02,  ...,  8.1993e-03,\n",
      "          1.2184e-02, -2.1274e-02],\n",
      "        ...,\n",
      "        [ 1.7017e-02, -6.0550e-03, -3.2701e-02,  ..., -1.6243e-02,\n",
      "         -5.2863e-03,  3.4739e-02],\n",
      "        [-3.4334e-02,  1.9611e-02, -6.6544e-03,  ..., -3.2922e-02,\n",
      "          1.4811e-02,  3.4774e-02],\n",
      "        [-2.8915e-02, -2.9844e-02,  2.8870e-02,  ...,  4.2270e-04,\n",
      "          2.9687e-03, -5.4101e-03]], requires_grad=True) Parameter containing:\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[-1.9966e-02, -2.0107e-02,  1.0792e-02,  ..., -1.8989e-02,\n",
      "          3.4663e-02, -1.8569e-02],\n",
      "        [ 2.4267e-02, -2.2216e-02, -3.4597e-03,  ..., -6.8253e-05,\n",
      "         -1.4426e-02,  3.3981e-02],\n",
      "        [ 1.2890e-02, -4.0622e-03,  1.5104e-02,  ...,  8.1993e-03,\n",
      "          1.2184e-02, -2.1274e-02],\n",
      "        ...,\n",
      "        [ 1.7017e-02, -6.0550e-03, -3.2701e-02,  ..., -1.6243e-02,\n",
      "         -5.2863e-03,  3.4739e-02],\n",
      "        [-3.4334e-02,  1.9611e-02, -6.6544e-03,  ..., -3.2922e-02,\n",
      "          1.4811e-02,  3.4774e-02],\n",
      "        [-2.8915e-02, -2.9844e-02,  2.8870e-02,  ...,  4.2270e-04,\n",
      "          2.9687e-03, -5.4101e-03]], requires_grad=True) Parameter containing:\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[-1.9966e-02, -2.0107e-02,  1.0792e-02,  ..., -1.8989e-02,\n",
      "          3.4663e-02, -1.8569e-02],\n",
      "        [ 2.4267e-02, -2.2216e-02, -3.4597e-03,  ..., -6.8253e-05,\n",
      "         -1.4426e-02,  3.3981e-02],\n",
      "        [ 1.2890e-02, -4.0622e-03,  1.5104e-02,  ...,  8.1993e-03,\n",
      "          1.2184e-02, -2.1274e-02],\n",
      "        ...,\n",
      "        [ 1.7017e-02, -6.0550e-03, -3.2701e-02,  ..., -1.6243e-02,\n",
      "         -5.2863e-03,  3.4739e-02],\n",
      "        [-3.4334e-02,  1.9611e-02, -6.6544e-03,  ..., -3.2922e-02,\n",
      "          1.4811e-02,  3.4774e-02],\n",
      "        [-2.8915e-02, -2.9844e-02,  2.8870e-02,  ...,  4.2270e-04,\n",
      "          2.9687e-03, -5.4101e-03]], requires_grad=True) Parameter containing:\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[-1.9966e-02, -2.0107e-02,  1.0792e-02,  ..., -1.8989e-02,\n",
      "          3.4663e-02, -1.8569e-02],\n",
      "        [ 2.4267e-02, -2.2216e-02, -3.4597e-03,  ..., -6.8253e-05,\n",
      "         -1.4426e-02,  3.3981e-02],\n",
      "        [ 1.2890e-02, -4.0622e-03,  1.5104e-02,  ...,  8.1993e-03,\n",
      "          1.2184e-02, -2.1274e-02],\n",
      "        ...,\n",
      "        [ 1.7017e-02, -6.0550e-03, -3.2701e-02,  ..., -1.6243e-02,\n",
      "         -5.2863e-03,  3.4739e-02],\n",
      "        [-3.4334e-02,  1.9611e-02, -6.6544e-03,  ..., -3.2922e-02,\n",
      "          1.4811e-02,  3.4774e-02],\n",
      "        [-2.8915e-02, -2.9844e-02,  2.8870e-02,  ...,  4.2270e-04,\n",
      "          2.9687e-03, -5.4101e-03]], requires_grad=True) Parameter containing:\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[-1.9966e-02, -2.0107e-02,  1.0792e-02,  ..., -1.8989e-02,\n",
      "          3.4663e-02, -1.8569e-02],\n",
      "        [ 2.4267e-02, -2.2216e-02, -3.4597e-03,  ..., -6.8253e-05,\n",
      "         -1.4426e-02,  3.3981e-02],\n",
      "        [ 1.2890e-02, -4.0622e-03,  1.5104e-02,  ...,  8.1993e-03,\n",
      "          1.2184e-02, -2.1274e-02],\n",
      "        ...,\n",
      "        [ 1.7017e-02, -6.0550e-03, -3.2701e-02,  ..., -1.6243e-02,\n",
      "         -5.2863e-03,  3.4739e-02],\n",
      "        [-3.4334e-02,  1.9611e-02, -6.6544e-03,  ..., -3.2922e-02,\n",
      "          1.4811e-02,  3.4774e-02],\n",
      "        [-2.8915e-02, -2.9844e-02,  2.8870e-02,  ...,  4.2270e-04,\n",
      "          2.9687e-03, -5.4101e-03]], requires_grad=True) Parameter containing:\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[-1.9966e-02, -2.0107e-02,  1.0792e-02,  ..., -1.8989e-02,\n",
      "          3.4663e-02, -1.8569e-02],\n",
      "        [ 2.4267e-02, -2.2216e-02, -3.4597e-03,  ..., -6.8253e-05,\n",
      "         -1.4426e-02,  3.3981e-02],\n",
      "        [ 1.2890e-02, -4.0622e-03,  1.5104e-02,  ...,  8.1993e-03,\n",
      "          1.2184e-02, -2.1274e-02],\n",
      "        ...,\n",
      "        [ 1.7017e-02, -6.0550e-03, -3.2701e-02,  ..., -1.6243e-02,\n",
      "         -5.2863e-03,  3.4739e-02],\n",
      "        [-3.4334e-02,  1.9611e-02, -6.6544e-03,  ..., -3.2922e-02,\n",
      "          1.4811e-02,  3.4774e-02],\n",
      "        [-2.8915e-02, -2.9844e-02,  2.8870e-02,  ...,  4.2270e-04,\n",
      "          2.9687e-03, -5.4101e-03]], requires_grad=True) Parameter containing:\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[-1.9966e-02, -2.0107e-02,  1.0792e-02,  ..., -1.8989e-02,\n",
      "          3.4663e-02, -1.8569e-02],\n",
      "        [ 2.4267e-02, -2.2216e-02, -3.4597e-03,  ..., -6.8253e-05,\n",
      "         -1.4426e-02,  3.3981e-02],\n",
      "        [ 1.2890e-02, -4.0622e-03,  1.5104e-02,  ...,  8.1993e-03,\n",
      "          1.2184e-02, -2.1274e-02],\n",
      "        ...,\n",
      "        [ 1.7017e-02, -6.0550e-03, -3.2701e-02,  ..., -1.6243e-02,\n",
      "         -5.2863e-03,  3.4739e-02],\n",
      "        [-3.4334e-02,  1.9611e-02, -6.6544e-03,  ..., -3.2922e-02,\n",
      "          1.4811e-02,  3.4774e-02],\n",
      "        [-2.8915e-02, -2.9844e-02,  2.8870e-02,  ...,  4.2270e-04,\n",
      "          2.9687e-03, -5.4101e-03]], requires_grad=True) Parameter containing:\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[-1.9966e-02, -2.0107e-02,  1.0792e-02,  ..., -1.8989e-02,\n",
      "          3.4663e-02, -1.8569e-02],\n",
      "        [ 2.4267e-02, -2.2216e-02, -3.4597e-03,  ..., -6.8253e-05,\n",
      "         -1.4426e-02,  3.3981e-02],\n",
      "        [ 1.2890e-02, -4.0622e-03,  1.5104e-02,  ...,  8.1993e-03,\n",
      "          1.2184e-02, -2.1274e-02],\n",
      "        ...,\n",
      "        [ 1.7017e-02, -6.0550e-03, -3.2701e-02,  ..., -1.6243e-02,\n",
      "         -5.2863e-03,  3.4739e-02],\n",
      "        [-3.4334e-02,  1.9611e-02, -6.6544e-03,  ..., -3.2922e-02,\n",
      "          1.4811e-02,  3.4774e-02],\n",
      "        [-2.8915e-02, -2.9844e-02,  2.8870e-02,  ...,  4.2270e-04,\n",
      "          2.9687e-03, -5.4101e-03]], requires_grad=True) Parameter containing:\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[-1.9966e-02, -2.0107e-02,  1.0792e-02,  ..., -1.8989e-02,\n",
      "          3.4663e-02, -1.8569e-02],\n",
      "        [ 2.4267e-02, -2.2216e-02, -3.4597e-03,  ..., -6.8253e-05,\n",
      "         -1.4426e-02,  3.3981e-02],\n",
      "        [ 1.2890e-02, -4.0622e-03,  1.5104e-02,  ...,  8.1993e-03,\n",
      "          1.2184e-02, -2.1274e-02],\n",
      "        ...,\n",
      "        [ 1.7017e-02, -6.0550e-03, -3.2701e-02,  ..., -1.6243e-02,\n",
      "         -5.2863e-03,  3.4739e-02],\n",
      "        [-3.4334e-02,  1.9611e-02, -6.6544e-03,  ..., -3.2922e-02,\n",
      "          1.4811e-02,  3.4774e-02],\n",
      "        [-2.8915e-02, -2.9844e-02,  2.8870e-02,  ...,  4.2270e-04,\n",
      "          2.9687e-03, -5.4101e-03]], requires_grad=True) Parameter containing:\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[-1.9966e-02, -2.0107e-02,  1.0792e-02,  ..., -1.8989e-02,\n",
      "          3.4663e-02, -1.8569e-02],\n",
      "        [ 2.4267e-02, -2.2216e-02, -3.4597e-03,  ..., -6.8253e-05,\n",
      "         -1.4426e-02,  3.3981e-02],\n",
      "        [ 1.2890e-02, -4.0622e-03,  1.5104e-02,  ...,  8.1993e-03,\n",
      "          1.2184e-02, -2.1274e-02],\n",
      "        ...,\n",
      "        [ 1.7017e-02, -6.0550e-03, -3.2701e-02,  ..., -1.6243e-02,\n",
      "         -5.2863e-03,  3.4739e-02],\n",
      "        [-3.4334e-02,  1.9611e-02, -6.6544e-03,  ..., -3.2922e-02,\n",
      "          1.4811e-02,  3.4774e-02],\n",
      "        [-2.8915e-02, -2.9844e-02,  2.8870e-02,  ...,  4.2270e-04,\n",
      "          2.9687e-03, -5.4101e-03]], requires_grad=True) Parameter containing:\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[-1.9966e-02, -2.0107e-02,  1.0792e-02,  ..., -1.8989e-02,\n",
      "          3.4663e-02, -1.8569e-02],\n",
      "        [ 2.4267e-02, -2.2216e-02, -3.4597e-03,  ..., -6.8253e-05,\n",
      "         -1.4426e-02,  3.3981e-02],\n",
      "        [ 1.2890e-02, -4.0622e-03,  1.5104e-02,  ...,  8.1993e-03,\n",
      "          1.2184e-02, -2.1274e-02],\n",
      "        ...,\n",
      "        [ 1.7017e-02, -6.0550e-03, -3.2701e-02,  ..., -1.6243e-02,\n",
      "         -5.2863e-03,  3.4739e-02],\n",
      "        [-3.4334e-02,  1.9611e-02, -6.6544e-03,  ..., -3.2922e-02,\n",
      "          1.4811e-02,  3.4774e-02],\n",
      "        [-2.8915e-02, -2.9844e-02,  2.8870e-02,  ...,  4.2270e-04,\n",
      "          2.9687e-03, -5.4101e-03]], requires_grad=True) Parameter containing:\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "for i in range(12):\n",
    "    print((model.roberta.encoder.layer[0].attention.self.query.lora_A),(model.roberta.encoder.layer[0].attention.self.query.lora_B))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AFTER INSERT LORA\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[-0.0260,  0.0036,  0.0135,  ..., -0.0217, -0.0324,  0.0208],\n",
       "        [ 0.0183,  0.0114, -0.0100,  ...,  0.0274, -0.0075,  0.0359],\n",
       "        [-0.0166,  0.0352,  0.0215,  ..., -0.0181,  0.0247, -0.0143],\n",
       "        ...,\n",
       "        [-0.0098, -0.0138, -0.0200,  ...,  0.0151,  0.0234, -0.0087],\n",
       "        [-0.0258, -0.0131, -0.0245,  ...,  0.0161, -0.0046,  0.0163],\n",
       "        [-0.0265, -0.0130,  0.0059,  ...,  0.0115, -0.0178, -0.0350]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"AFTER INSERT LORA\")\n",
    "model.roberta.encoder.layer[0].attention.self.query.weight.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(10.9219, grad_fn=<CopyBackwards>),\n",
       " tensor(10.8647, grad_fn=<CopyBackwards>))"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lora_state_dict = torch.load('/home/lab/bumjun/lora-training/LoRA/examples/NLU/sst2/lora/2023-09-11_16:37:03lorackpt.bin')\n",
    "model.load_state_dict(lora_state_dict, strict=False)\n",
    "torch.norm(model.roberta.encoder.layer[0].attention.self.query.lora_A),torch.norm(model.roberta.encoder.layer[0].attention.self.query.lora_B)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(9.2688, grad_fn=<CopyBackwards>)\n",
      "tensor(9.2465, grad_fn=<CopyBackwards>)\n",
      "tensor(9.2708, grad_fn=<CopyBackwards>)\n",
      "tensor(9.2347, grad_fn=<CopyBackwards>)\n",
      "tensor(9.2479, grad_fn=<CopyBackwards>)\n",
      "tensor(9.2505, grad_fn=<CopyBackwards>)\n",
      "tensor(9.2038, grad_fn=<CopyBackwards>)\n",
      "tensor(9.2329, grad_fn=<CopyBackwards>)\n",
      "tensor(9.2156, grad_fn=<CopyBackwards>)\n",
      "tensor(9.2522, grad_fn=<CopyBackwards>)\n",
      "tensor(9.2205, grad_fn=<CopyBackwards>)\n",
      "tensor(9.2672, grad_fn=<CopyBackwards>)\n"
     ]
    }
   ],
   "source": [
    "insert_lora(new_model, 768, 128, 128)\n",
    "#lora_state_dict = torch.load('/home/lab/bumjun/lora-training/LoRA/examples/NLU/sst2/lora/lorackpt_.bin')\n",
    "#new_model.load_state_dict(lora_state_dict, strict=False)\n",
    "for i in range(12):\n",
    "    print(torch.norm(new_model.roberta.encoder.layer[i].attention.self.query.lora_A-model.roberta.encoder.layer[i].attention.self.query.lora_A))#,torch.norm(new_model.roberta.encoder.layer[i].attention.self.query.lora_B-model.roberta.encoder.layer[i].attention.self.query.lora_B))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at textattack/roberta-base-SST-2 were not used when initializing RobertaForSequenceClassification: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "- This IS expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(6.5407, grad_fn=<CopyBackwards>) tensor(0., grad_fn=<CopyBackwards>)\n",
      "tensor(6.5271, grad_fn=<CopyBackwards>) tensor(0., grad_fn=<CopyBackwards>)\n",
      "tensor(6.5261, grad_fn=<CopyBackwards>) tensor(0., grad_fn=<CopyBackwards>)\n",
      "tensor(6.5379, grad_fn=<CopyBackwards>) tensor(0., grad_fn=<CopyBackwards>)\n",
      "tensor(6.5217, grad_fn=<CopyBackwards>) tensor(0., grad_fn=<CopyBackwards>)\n",
      "tensor(6.5411, grad_fn=<CopyBackwards>) tensor(0., grad_fn=<CopyBackwards>)\n",
      "tensor(6.5292, grad_fn=<CopyBackwards>) tensor(0., grad_fn=<CopyBackwards>)\n",
      "tensor(6.5453, grad_fn=<CopyBackwards>) tensor(0., grad_fn=<CopyBackwards>)\n",
      "tensor(6.5406, grad_fn=<CopyBackwards>) tensor(0., grad_fn=<CopyBackwards>)\n",
      "tensor(6.5278, grad_fn=<CopyBackwards>) tensor(0., grad_fn=<CopyBackwards>)\n",
      "tensor(6.5377, grad_fn=<CopyBackwards>) tensor(0., grad_fn=<CopyBackwards>)\n",
      "tensor(6.5237, grad_fn=<CopyBackwards>) tensor(0., grad_fn=<CopyBackwards>)\n",
      "Parameter containing:\n",
      "tensor([[-0.0266, -0.0122,  0.0111,  ..., -0.0165,  0.0338,  0.0026],\n",
      "        [-0.0057,  0.0161,  0.0318,  ..., -0.0113,  0.0178,  0.0268],\n",
      "        [ 0.0332,  0.0243,  0.0062,  ...,  0.0112, -0.0070, -0.0324],\n",
      "        ...,\n",
      "        [ 0.0215, -0.0003,  0.0116,  ..., -0.0040, -0.0059, -0.0250],\n",
      "        [-0.0192, -0.0217, -0.0040,  ...,  0.0154,  0.0089,  0.0131],\n",
      "        [-0.0279,  0.0343, -0.0229,  ...,  0.0033,  0.0092, -0.0304]],\n",
      "       requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "model = copy.deepcopy(AutoModelForSequenceClassification.from_pretrained(\n",
    "        'textattack/roberta-base-SST-2'\n",
    "    ))\n",
    "insert_lora(model, 768, 128, 128)\n",
    "for i in range(12):\n",
    "    print(torch.norm(model.roberta.encoder.layer[i].attention.self.query.lora_A),torch.norm(model.roberta.encoder.layer[i].attention.self.query.lora_B))\n",
    "print(model.roberta.encoder.layer[0].attention.self.query.lora_A)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at textattack/roberta-base-SST-2 were not used when initializing RobertaForSequenceClassification: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "- This IS expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(6.5259, grad_fn=<CopyBackwards>) tensor(0., grad_fn=<CopyBackwards>)\n",
      "tensor(6.5205, grad_fn=<CopyBackwards>) tensor(0., grad_fn=<CopyBackwards>)\n",
      "tensor(6.5330, grad_fn=<CopyBackwards>) tensor(0., grad_fn=<CopyBackwards>)\n",
      "tensor(6.5258, grad_fn=<CopyBackwards>) tensor(0., grad_fn=<CopyBackwards>)\n",
      "tensor(6.5288, grad_fn=<CopyBackwards>) tensor(0., grad_fn=<CopyBackwards>)\n",
      "tensor(6.5455, grad_fn=<CopyBackwards>) tensor(0., grad_fn=<CopyBackwards>)\n",
      "tensor(6.5385, grad_fn=<CopyBackwards>) tensor(0., grad_fn=<CopyBackwards>)\n",
      "tensor(6.5391, grad_fn=<CopyBackwards>) tensor(0., grad_fn=<CopyBackwards>)\n",
      "tensor(6.5260, grad_fn=<CopyBackwards>) tensor(0., grad_fn=<CopyBackwards>)\n",
      "tensor(6.5238, grad_fn=<CopyBackwards>) tensor(0., grad_fn=<CopyBackwards>)\n",
      "tensor(6.5434, grad_fn=<CopyBackwards>) tensor(0., grad_fn=<CopyBackwards>)\n",
      "tensor(6.5411, grad_fn=<CopyBackwards>) tensor(0., grad_fn=<CopyBackwards>)\n"
     ]
    }
   ],
   "source": [
    "new_model= copy.deepcopy(AutoModelForSequenceClassification.from_pretrained(\n",
    "        'textattack/roberta-base-SST-2'\n",
    "    ))\n",
    "insert_lora(new_model, 768, 128, 128)\n",
    "for i in range(12):\n",
    "    print(torch.norm(new_model.roberta.encoder.layer[i].attention.self.query.lora_A),torch.norm(new_model.roberta.encoder.layer[i].attention.self.query.lora_B))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'roberta.encoder.layer.0.attention.self.query.lora_A': tensor([[ 0.1515, -0.1323, -0.1244,  ...,  0.0710,  0.1183, -0.0110],\n",
       "         [-0.1000,  0.0803,  0.2078,  ..., -0.1149,  0.0634, -0.0568],\n",
       "         [ 0.2582, -0.0209, -0.0885,  ...,  0.0078, -0.0894, -0.0078],\n",
       "         ...,\n",
       "         [-0.1884,  0.0715,  0.0927,  ...,  0.1912,  0.0300, -0.2001],\n",
       "         [-0.0154,  0.0779, -0.0565,  ..., -0.0350,  0.0982, -0.0041],\n",
       "         [ 0.0760, -0.0409,  0.1545,  ...,  0.0343,  0.0311, -0.0163]],\n",
       "        device='cuda:0'),\n",
       " 'roberta.encoder.layer.0.attention.self.query.lora_B': tensor([[-0.0154,  0.0150,  0.1466,  ..., -0.0155,  0.0818, -0.1649],\n",
       "         [ 0.0124, -0.0048, -0.0017,  ..., -0.0034,  0.0430,  0.0365],\n",
       "         [-0.0030,  0.0033, -0.1092,  ...,  0.0135,  0.0124,  0.1118],\n",
       "         ...,\n",
       "         [-0.0446,  0.0194,  0.2464,  ..., -0.1759,  0.2416,  0.1392],\n",
       "         [ 0.0507,  0.0158, -0.1048,  ...,  0.0168, -0.0128, -0.2386],\n",
       "         [ 0.0126,  0.0374, -0.0804,  ...,  0.0669,  0.1022, -0.1314]],\n",
       "        device='cuda:0'),\n",
       " 'roberta.encoder.layer.0.attention.self.value.lora_A': tensor([[-0.0029, -0.0103, -0.0356,  ...,  0.0766,  0.0195,  0.0140],\n",
       "         [ 0.0351, -0.0145,  0.0303,  ..., -0.0207,  0.0264,  0.0754],\n",
       "         [ 0.0826,  0.0614,  0.0364,  ..., -0.1054,  0.0732, -0.0046],\n",
       "         ...,\n",
       "         [-0.0591,  0.0449, -0.0521,  ...,  0.0429,  0.0299, -0.0105],\n",
       "         [ 0.0519,  0.0117, -0.0910,  ...,  0.0102,  0.0117,  0.0218],\n",
       "         [ 0.0845,  0.0190,  0.1347,  ..., -0.1848,  0.0630, -0.0270]],\n",
       "        device='cuda:0'),\n",
       " 'roberta.encoder.layer.0.attention.self.value.lora_B': tensor([[ 0.0128, -0.0350,  0.0361,  ..., -0.0298,  0.0259, -0.0127],\n",
       "         [ 0.0101,  0.0083,  0.0576,  ..., -0.0279,  0.0098, -0.0188],\n",
       "         [ 0.0065, -0.0018,  0.0332,  ...,  0.0238,  0.0371, -0.0247],\n",
       "         ...,\n",
       "         [ 0.0186,  0.0004, -0.0156,  ..., -0.0138, -0.0144, -0.0194],\n",
       "         [ 0.0004, -0.0059,  0.0034,  ...,  0.0285, -0.0095, -0.0072],\n",
       "         [ 0.0011,  0.0166, -0.0041,  ...,  0.0132,  0.0128,  0.0229]],\n",
       "        device='cuda:0'),\n",
       " 'roberta.encoder.layer.1.attention.self.query.lora_A': tensor([[ 0.1528,  0.1166,  0.1363,  ...,  0.1043,  0.1389,  0.1240],\n",
       "         [-0.1176,  0.1393,  0.1933,  ..., -0.1604,  0.0036, -0.0458],\n",
       "         [-0.0128,  0.0796,  0.0016,  ...,  0.0357, -0.0645, -0.0030],\n",
       "         ...,\n",
       "         [ 0.0347,  0.0212, -0.0486,  ...,  0.0616, -0.0479,  0.0569],\n",
       "         [-0.0555, -0.1247,  0.0156,  ..., -0.0120,  0.0194,  0.2553],\n",
       "         [ 0.0292, -0.0831,  0.0357,  ..., -0.0107,  0.0744, -0.0116]],\n",
       "        device='cuda:0'),\n",
       " 'roberta.encoder.layer.1.attention.self.query.lora_B': tensor([[ 0.0473,  0.0058,  0.0008,  ...,  0.1074,  0.0244, -0.0204],\n",
       "         [-0.0577, -0.0141,  0.0143,  ...,  0.0122,  0.0132,  0.0473],\n",
       "         [ 0.0008, -0.0013,  0.0134,  ..., -0.0387,  0.0086, -0.0501],\n",
       "         ...,\n",
       "         [ 0.2014, -0.0024, -0.0060,  ..., -0.0160,  0.0020,  0.0051],\n",
       "         [ 0.2867, -0.0107, -0.0191,  ..., -0.0481, -0.0230, -0.0484],\n",
       "         [-0.1394, -0.0175,  0.0054,  ...,  0.0733,  0.1115,  0.0448]],\n",
       "        device='cuda:0'),\n",
       " 'roberta.encoder.layer.1.attention.self.value.lora_A': tensor([[-0.0095,  0.0023, -0.0225,  ..., -0.0261,  0.0343, -0.0190],\n",
       "         [-0.0206, -0.0008, -0.0386,  ..., -0.0011, -0.0399, -0.0440],\n",
       "         [-0.0116, -0.0976,  0.0329,  ...,  0.0091, -0.0579, -0.0112],\n",
       "         ...,\n",
       "         [ 0.0027, -0.0045,  0.1123,  ..., -0.0597,  0.0113, -0.0278],\n",
       "         [ 0.0802,  0.0579, -0.0312,  ...,  0.0350, -0.0480, -0.0245],\n",
       "         [-0.1131,  0.0268, -0.0478,  ...,  0.0204, -0.0300,  0.0273]],\n",
       "        device='cuda:0'),\n",
       " 'roberta.encoder.layer.1.attention.self.value.lora_B': tensor([[ 0.0748,  0.0135,  0.0689,  ..., -0.1250,  0.2577, -0.0754],\n",
       "         [-0.0085,  0.0303,  0.0059,  ..., -0.0435,  0.0642,  0.0384],\n",
       "         [-0.0383, -0.0078, -0.0487,  ...,  0.0250, -0.0270, -0.0224],\n",
       "         ...,\n",
       "         [-0.0123, -0.0701, -0.0495,  ..., -0.2034, -0.1159, -0.0848],\n",
       "         [-0.0993, -0.0682,  0.0501,  ..., -0.0304,  0.1099,  0.0198],\n",
       "         [-0.0769,  0.0537,  0.0561,  ..., -0.1009, -0.0547,  0.0716]],\n",
       "        device='cuda:0'),\n",
       " 'roberta.encoder.layer.2.attention.self.query.lora_A': tensor([[ 0.1339,  0.0895,  0.1420,  ...,  0.1132,  0.1662,  0.0890],\n",
       "         [ 0.0280,  0.0316, -0.0017,  ..., -0.0196,  0.0324,  0.0419],\n",
       "         [ 0.0845, -0.0397,  0.0094,  ...,  0.0281,  0.0524, -0.3808],\n",
       "         ...,\n",
       "         [ 0.0582, -0.0085,  0.0296,  ..., -0.0317,  0.1046,  0.0407],\n",
       "         [-0.0267,  0.0281, -0.0291,  ...,  0.0543,  0.0202,  0.0025],\n",
       "         [ 0.0554,  0.0767, -0.1108,  ..., -0.1031,  0.1140, -0.0699]],\n",
       "        device='cuda:0'),\n",
       " 'roberta.encoder.layer.2.attention.self.query.lora_B': tensor([[ 0.0140, -0.1253,  0.1061,  ..., -0.0035,  0.0185, -0.0797],\n",
       "         [-0.0067, -0.0226,  0.0139,  ...,  0.0539, -0.1005, -0.0014],\n",
       "         [ 0.0951, -0.1897, -0.0202,  ..., -0.0345,  0.0221, -0.0022],\n",
       "         ...,\n",
       "         [ 0.0145,  0.1157,  0.0378,  ...,  0.1209, -0.0191,  0.0641],\n",
       "         [ 0.0068,  0.0726,  0.1114,  ...,  0.0490,  0.0244, -0.0278],\n",
       "         [ 0.0214, -0.0621, -0.0417,  ..., -0.0428, -0.0493, -0.0808]],\n",
       "        device='cuda:0'),\n",
       " 'roberta.encoder.layer.2.attention.self.value.lora_A': tensor([[ 0.0712,  0.0489,  0.0199,  ...,  0.0752,  0.0325,  0.0199],\n",
       "         [-0.0698,  0.0181, -0.0884,  ...,  0.0328, -0.0613, -0.0743],\n",
       "         [ 0.1175,  0.0025, -0.0144,  ...,  0.0106,  0.0622,  0.0575],\n",
       "         ...,\n",
       "         [-0.0728,  0.0101,  0.0103,  ..., -0.0830, -0.0529, -0.0612],\n",
       "         [-0.0351, -0.0198, -0.0764,  ...,  0.0179, -0.1201, -0.0108],\n",
       "         [ 0.0124, -0.0005,  0.0480,  ..., -0.0242,  0.0202, -0.0230]],\n",
       "        device='cuda:0'),\n",
       " 'roberta.encoder.layer.2.attention.self.value.lora_B': tensor([[ 0.0441,  0.1042, -0.1527,  ..., -0.0022,  0.0064, -0.0279],\n",
       "         [ 0.0750,  0.0263,  0.0382,  ..., -0.1180,  0.0782, -0.0159],\n",
       "         [ 0.1386, -0.1494, -0.2427,  ..., -0.0331,  0.0281,  0.0608],\n",
       "         ...,\n",
       "         [ 0.0023, -0.0018, -0.0222,  ..., -0.0525, -0.0187,  0.0406],\n",
       "         [-0.0727,  0.0030,  0.0230,  ...,  0.0206,  0.0544,  0.0487],\n",
       "         [-0.0265,  0.0396,  0.0158,  ...,  0.0474, -0.0193,  0.0630]],\n",
       "        device='cuda:0'),\n",
       " 'roberta.encoder.layer.3.attention.self.query.lora_A': tensor([[-1.1175e-01, -1.1019e-01, -1.2476e-01,  ..., -1.1651e-01,\n",
       "          -1.6497e-01, -1.1000e-01],\n",
       "         [ 9.5022e-03,  2.3494e-02, -1.8329e-01,  ...,  1.2030e-02,\n",
       "           1.8415e-03, -7.5449e-02],\n",
       "         [-4.9891e-03, -1.2564e-01, -5.1038e-05,  ..., -6.0735e-02,\n",
       "           1.8814e-02, -3.5968e-02],\n",
       "         ...,\n",
       "         [-3.4987e-02,  7.9837e-03,  2.4406e-02,  ...,  3.2749e-02,\n",
       "           8.0752e-02, -2.5442e-02],\n",
       "         [-8.7311e-02, -2.1682e-02,  5.4255e-02,  ..., -6.3132e-02,\n",
       "           1.0158e-01,  4.9498e-02],\n",
       "         [ 3.6252e-02,  8.9382e-02,  1.3231e-01,  ...,  5.0055e-03,\n",
       "           1.4967e-02,  3.1829e-02]], device='cuda:0'),\n",
       " 'roberta.encoder.layer.3.attention.self.query.lora_B': tensor([[-0.1135,  0.0061,  0.0263,  ...,  0.1282, -0.0127,  0.0141],\n",
       "         [ 0.0613, -0.0053,  0.0406,  ..., -0.0410, -0.0008,  0.0303],\n",
       "         [ 0.3817, -0.0404, -0.0846,  ..., -0.0494,  0.1093,  0.0865],\n",
       "         ...,\n",
       "         [-0.0501, -0.0593,  0.1190,  ..., -0.0502,  0.0494,  0.0989],\n",
       "         [ 0.0705, -0.1563, -0.0220,  ..., -0.0595,  0.0578, -0.0288],\n",
       "         [ 0.1445, -0.0394,  0.0670,  ..., -0.2046, -0.0687, -0.0217]],\n",
       "        device='cuda:0'),\n",
       " 'roberta.encoder.layer.3.attention.self.value.lora_A': tensor([[ 0.0623,  0.0777,  0.0428,  ...,  0.0949,  0.1030,  0.0572],\n",
       "         [ 0.0487, -0.0051,  0.0755,  ...,  0.0076, -0.0353,  0.0487],\n",
       "         [-0.0240,  0.0412,  0.0101,  ..., -0.0130,  0.0812, -0.0487],\n",
       "         ...,\n",
       "         [ 0.0093, -0.0208,  0.0621,  ..., -0.0326,  0.0409, -0.0346],\n",
       "         [-0.0754,  0.0345,  0.0475,  ...,  0.0732, -0.0029,  0.0045],\n",
       "         [-0.0537, -0.0289, -0.0090,  ..., -0.0140, -0.0125,  0.0461]],\n",
       "        device='cuda:0'),\n",
       " 'roberta.encoder.layer.3.attention.self.value.lora_B': tensor([[ 0.0064,  0.0726, -0.0315,  ...,  0.0401, -0.0317,  0.0253],\n",
       "         [-0.0301,  0.1509, -0.0243,  ..., -0.0479, -0.0439,  0.0494],\n",
       "         [ 0.0014, -0.0085, -0.0589,  ...,  0.1145,  0.0536,  0.0988],\n",
       "         ...,\n",
       "         [-0.0785, -0.0240,  0.1066,  ..., -0.0853,  0.0380,  0.0241],\n",
       "         [ 0.1366, -0.0335,  0.0072,  ...,  0.0080,  0.0240,  0.0406],\n",
       "         [ 0.0198, -0.0088,  0.0721,  ..., -0.0254,  0.0175, -0.0456]],\n",
       "        device='cuda:0'),\n",
       " 'roberta.encoder.layer.4.attention.self.query.lora_A': tensor([[ 0.1221,  0.1180,  0.1230,  ...,  0.1084,  0.1559,  0.1036],\n",
       "         [ 0.0082, -0.0053,  0.1402,  ..., -0.0359, -0.0364,  0.0669],\n",
       "         [-0.0406, -0.0255, -0.0118,  ..., -0.0283,  0.0628, -0.1138],\n",
       "         ...,\n",
       "         [ 0.0509,  0.1713, -0.0543,  ..., -0.0262, -0.0069, -0.0925],\n",
       "         [-0.0003, -0.0823,  0.0404,  ..., -0.0018,  0.0321,  0.0506],\n",
       "         [ 0.0205,  0.0220,  0.0521,  ...,  0.1265, -0.0681, -0.0387]],\n",
       "        device='cuda:0'),\n",
       " 'roberta.encoder.layer.4.attention.self.query.lora_B': tensor([[-0.0106,  0.0214, -0.0202,  ..., -0.1563,  0.0805, -0.0710],\n",
       "         [ 0.1496,  0.0003, -0.0501,  ...,  0.0078,  0.0218,  0.1181],\n",
       "         [-0.0767, -0.0921,  0.0384,  ..., -0.0022, -0.1030, -0.0344],\n",
       "         ...,\n",
       "         [-0.0431,  0.1219,  0.0669,  ...,  0.0062,  0.1755,  0.0140],\n",
       "         [ 0.0043, -0.0166, -0.0454,  ..., -0.0032,  0.0533,  0.1021],\n",
       "         [-0.0280,  0.0532,  0.0124,  ..., -0.0109,  0.0080, -0.1456]],\n",
       "        device='cuda:0'),\n",
       " 'roberta.encoder.layer.4.attention.self.value.lora_A': tensor([[-1.1236e-01, -6.8989e-02,  1.0583e-02,  ..., -7.3324e-02,\n",
       "          -1.0720e-01, -6.4005e-02],\n",
       "         [ 1.5916e-01,  8.2682e-03,  1.2870e-01,  ...,  4.6608e-02,\n",
       "           1.3018e-04, -3.8511e-02],\n",
       "         [-8.6573e-02, -8.6985e-04,  3.7398e-02,  ..., -6.3057e-02,\n",
       "          -8.6441e-02,  7.5497e-02],\n",
       "         ...,\n",
       "         [-9.1744e-03, -4.5310e-02, -2.8376e-02,  ..., -8.9672e-02,\n",
       "          -4.0314e-02,  6.5388e-02],\n",
       "         [ 6.0313e-02,  4.8526e-02,  4.4775e-02,  ...,  2.2491e-02,\n",
       "          -2.0898e-02,  6.2401e-02],\n",
       "         [-6.4296e-02, -1.2993e-02, -3.3310e-02,  ...,  1.2881e-02,\n",
       "          -3.6306e-02,  4.8413e-02]], device='cuda:0'),\n",
       " 'roberta.encoder.layer.4.attention.self.value.lora_B': tensor([[-0.0329,  0.0232, -0.0264,  ..., -0.0208,  0.0771, -0.0357],\n",
       "         [-0.0729, -0.0894,  0.0267,  ...,  0.1312,  0.0881,  0.1210],\n",
       "         [-0.0367, -0.0290, -0.0142,  ...,  0.1098, -0.0400, -0.0108],\n",
       "         ...,\n",
       "         [-0.0607,  0.0236,  0.0398,  ..., -0.0257, -0.0219, -0.0134],\n",
       "         [-0.1765,  0.1275,  0.0227,  ..., -0.0176,  0.0191, -0.0749],\n",
       "         [ 0.0345, -0.0096,  0.0006,  ...,  0.0368, -0.0606, -0.0565]],\n",
       "        device='cuda:0'),\n",
       " 'roberta.encoder.layer.5.attention.self.query.lora_A': tensor([[-1.1499e-01, -1.3863e-01, -1.0959e-01,  ..., -1.0845e-01,\n",
       "          -1.3788e-01, -1.6039e-01],\n",
       "         [-2.4303e-02, -3.1268e-03,  2.6201e-02,  ..., -5.3986e-02,\n",
       "          -2.2806e-02,  1.6960e-03],\n",
       "         [ 3.9030e-03, -9.8654e-02,  8.5918e-02,  ..., -9.4383e-02,\n",
       "          -4.9851e-03,  4.1067e-02],\n",
       "         ...,\n",
       "         [ 3.0400e-02, -6.1301e-03, -2.1957e-02,  ..., -8.8407e-02,\n",
       "           1.1932e-04, -4.3889e-02],\n",
       "         [-1.6766e-02,  9.6503e-03,  1.9370e-03,  ...,  2.0172e-02,\n",
       "          -3.2799e-02,  8.3483e-02],\n",
       "         [-7.4123e-03,  4.5318e-02,  6.3177e-02,  ..., -2.4273e-02,\n",
       "           1.3322e-01, -4.4636e-02]], device='cuda:0'),\n",
       " 'roberta.encoder.layer.5.attention.self.query.lora_B': tensor([[ 0.0083, -0.0401,  0.1042,  ..., -0.0545, -0.1236,  0.0310],\n",
       "         [ 0.0049, -0.0135,  0.0096,  ...,  0.0377, -0.0307,  0.0818],\n",
       "         [-0.0131,  0.0419,  0.0049,  ...,  0.0162,  0.0347, -0.0198],\n",
       "         ...,\n",
       "         [-0.0128,  0.0332, -0.0819,  ..., -0.0603, -0.0324, -0.0956],\n",
       "         [ 0.2544,  0.0307,  0.0458,  ...,  0.0551,  0.0054,  0.0757],\n",
       "         [-0.4354, -0.0152,  0.0210,  ..., -0.0733, -0.0452,  0.0821]],\n",
       "        device='cuda:0'),\n",
       " 'roberta.encoder.layer.5.attention.self.value.lora_A': tensor([[-0.0080,  0.0003, -0.0660,  ...,  0.0629,  0.0980,  0.0946],\n",
       "         [-0.1086, -0.0118, -0.1190,  ..., -0.0327,  0.0401,  0.0109],\n",
       "         [ 0.1453,  0.0199,  0.0823,  ...,  0.0067, -0.0633,  0.0933],\n",
       "         ...,\n",
       "         [ 0.1926,  0.0032,  0.0499,  ..., -0.0266, -0.0480,  0.0265],\n",
       "         [ 0.1440,  0.0605,  0.0862,  ...,  0.0360,  0.0538,  0.0896],\n",
       "         [-0.0275, -0.0251, -0.0150,  ...,  0.0228,  0.0451, -0.0448]],\n",
       "        device='cuda:0'),\n",
       " 'roberta.encoder.layer.5.attention.self.value.lora_B': tensor([[-0.1106, -0.0772,  0.0096,  ..., -0.1219,  0.1073, -0.0692],\n",
       "         [-0.0779, -0.0727,  0.0828,  ..., -0.1255,  0.0004,  0.1183],\n",
       "         [-0.0620, -0.1081, -0.0483,  ..., -0.0245,  0.0404, -0.0976],\n",
       "         ...,\n",
       "         [-0.0293,  0.0562,  0.0953,  ..., -0.1363,  0.0316,  0.0182],\n",
       "         [ 0.0692,  0.0928, -0.0544,  ...,  0.0068,  0.0154, -0.0214],\n",
       "         [ 0.0902,  0.1330, -0.1316,  ...,  0.0030,  0.0055, -0.0183]],\n",
       "        device='cuda:0'),\n",
       " 'roberta.encoder.layer.6.attention.self.query.lora_A': tensor([[-0.0602,  0.0057,  0.0666,  ..., -0.0110,  0.1108,  0.0968],\n",
       "         [ 0.0484,  0.0566,  0.0331,  ...,  0.0703, -0.0484, -0.0029],\n",
       "         [ 0.0003, -0.1087, -0.0074,  ..., -0.0989, -0.0336,  0.0607],\n",
       "         ...,\n",
       "         [ 0.1884,  0.1816, -0.0285,  ..., -0.0718,  0.0761, -0.0130],\n",
       "         [-0.0617, -0.0438,  0.0302,  ...,  0.0339, -0.0244,  0.0049],\n",
       "         [ 0.0493, -0.0161,  0.0894,  ...,  0.1182,  0.0660,  0.0456]],\n",
       "        device='cuda:0'),\n",
       " 'roberta.encoder.layer.6.attention.self.query.lora_B': tensor([[-4.2421e-02, -7.2382e-02,  1.2101e-02,  ..., -2.9171e-02,\n",
       "           6.3932e-02,  2.9543e-02],\n",
       "         [ 2.8453e-02, -7.2862e-02, -2.9936e-02,  ..., -8.7836e-02,\n",
       "           1.5584e-01,  1.0827e-01],\n",
       "         [-4.0817e-01,  1.4122e-01,  4.7489e-02,  ..., -4.2953e-02,\n",
       "           1.1645e-01, -9.6573e-02],\n",
       "         ...,\n",
       "         [ 2.6190e-01,  1.2453e-01,  2.4413e-04,  ...,  6.3656e-02,\n",
       "          -6.6829e-03, -8.0181e-02],\n",
       "         [-1.9350e-03, -4.4426e-02, -7.3140e-03,  ...,  2.3074e-02,\n",
       "          -1.3335e-03,  7.2998e-03],\n",
       "         [-1.7868e-01, -1.2769e-01, -1.7191e-02,  ...,  5.3669e-02,\n",
       "           9.2835e-02,  9.1430e-02]], device='cuda:0'),\n",
       " 'roberta.encoder.layer.6.attention.self.value.lora_A': tensor([[ 3.2095e-02,  3.4912e-02,  1.3743e-02,  ...,  6.4347e-02,\n",
       "           9.3349e-02,  1.0776e-01],\n",
       "         [-1.0026e-01,  4.3436e-02,  1.4441e-02,  ...,  3.2625e-02,\n",
       "          -4.9250e-03,  5.5772e-02],\n",
       "         [-6.2471e-02, -7.3738e-03,  1.0614e-02,  ...,  1.2135e-01,\n",
       "          -6.0953e-03,  1.8036e-04],\n",
       "         ...,\n",
       "         [-6.0752e-02,  7.7987e-03,  4.3457e-02,  ...,  2.4216e-02,\n",
       "           1.8622e-01,  2.2223e-02],\n",
       "         [-2.7784e-02, -2.0572e-02,  2.6232e-02,  ...,  3.2941e-02,\n",
       "          -1.0458e-02,  9.4640e-02],\n",
       "         [-9.3725e-02,  5.4178e-02,  4.2900e-02,  ..., -2.5348e-02,\n",
       "           2.7297e-02,  4.4020e-02]], device='cuda:0'),\n",
       " 'roberta.encoder.layer.6.attention.self.value.lora_B': tensor([[-0.0115, -0.0264,  0.0216,  ..., -0.0405,  0.0263, -0.0604],\n",
       "         [-0.0065, -0.0250, -0.0363,  ..., -0.0528, -0.0321,  0.0951],\n",
       "         [-0.0693, -0.0198,  0.0055,  ...,  0.0350, -0.0076,  0.0694],\n",
       "         ...,\n",
       "         [ 0.0656,  0.1063, -0.0044,  ..., -0.1846, -0.0671,  0.0523],\n",
       "         [-0.0187,  0.1193, -0.1848,  ..., -0.1109,  0.1758, -0.1861],\n",
       "         [-0.0612, -0.2007, -0.1794,  ...,  0.0414, -0.0711, -0.0822]],\n",
       "        device='cuda:0'),\n",
       " 'roberta.encoder.layer.7.attention.self.query.lora_A': tensor([[-0.0099, -0.0723, -0.1202,  ...,  0.0020, -0.0611, -0.1198],\n",
       "         [ 0.0069, -0.0139,  0.0221,  ..., -0.0856,  0.0173, -0.0234],\n",
       "         [ 0.0115, -0.1138, -0.0031,  ...,  0.1565,  0.0176,  0.0187],\n",
       "         ...,\n",
       "         [ 0.0550, -0.0633,  0.1109,  ...,  0.1145,  0.1114, -0.0326],\n",
       "         [ 0.0301, -0.1155, -0.1139,  ..., -0.0339,  0.0901,  0.1103],\n",
       "         [ 0.0329, -0.0916,  0.0358,  ...,  0.0015,  0.0262,  0.0247]],\n",
       "        device='cuda:0'),\n",
       " 'roberta.encoder.layer.7.attention.self.query.lora_B': tensor([[ 0.0055, -0.0327,  0.0862,  ...,  0.0340, -0.0701,  0.0390],\n",
       "         [ 0.0753,  0.0537,  0.0713,  ...,  0.0117, -0.0317, -0.0261],\n",
       "         [-0.0244,  0.0019,  0.0578,  ..., -0.1044, -0.0047,  0.0171],\n",
       "         ...,\n",
       "         [-0.1682,  0.0368, -0.0072,  ..., -0.1497, -0.0082,  0.0155],\n",
       "         [ 0.0131,  0.0326, -0.1524,  ..., -0.0754, -0.0135, -0.0172],\n",
       "         [ 0.0314,  0.1265,  0.0826,  ..., -0.0187,  0.0138, -0.0579]],\n",
       "        device='cuda:0'),\n",
       " 'roberta.encoder.layer.7.attention.self.value.lora_A': tensor([[-0.0589,  0.0746, -0.0122,  ...,  0.0696,  0.0421,  0.0738],\n",
       "         [-0.0642,  0.0066, -0.0709,  ..., -0.0410, -0.0463, -0.0383],\n",
       "         [-0.1286, -0.0307,  0.0259,  ...,  0.0422,  0.0625, -0.0056],\n",
       "         ...,\n",
       "         [-0.1211, -0.0200, -0.0104,  ..., -0.0311,  0.1152, -0.0150],\n",
       "         [-0.0124, -0.0181,  0.1030,  ..., -0.0063,  0.1607,  0.1101],\n",
       "         [ 0.0945,  0.0332,  0.0378,  ...,  0.0100,  0.0497,  0.0346]],\n",
       "        device='cuda:0'),\n",
       " 'roberta.encoder.layer.7.attention.self.value.lora_B': tensor([[ 0.0389, -0.0208,  0.0146,  ...,  0.0559, -0.0386,  0.0029],\n",
       "         [ 0.2013,  0.0262,  0.0136,  ..., -0.0472,  0.0504,  0.0823],\n",
       "         [-0.0305, -0.0254, -0.0148,  ...,  0.0079, -0.0181, -0.0174],\n",
       "         ...,\n",
       "         [-0.0313,  0.0772, -0.0400,  ..., -0.0441, -0.0327, -0.0107],\n",
       "         [-0.0834, -0.0113,  0.0197,  ..., -0.0094, -0.0215,  0.0041],\n",
       "         [-0.0198,  0.0148, -0.0182,  ...,  0.0002, -0.0271, -0.0211]],\n",
       "        device='cuda:0'),\n",
       " 'roberta.encoder.layer.8.attention.self.query.lora_A': tensor([[-0.0645, -0.0897, -0.1016,  ..., -0.0765, -0.1245, -0.1228],\n",
       "         [-0.0414, -0.0722, -0.0291,  ...,  0.0075,  0.0477, -0.0097],\n",
       "         [-0.0051, -0.0197,  0.0477,  ...,  0.0608,  0.0825, -0.1168],\n",
       "         ...,\n",
       "         [-0.0495,  0.0142, -0.0172,  ...,  0.0112,  0.1451,  0.0040],\n",
       "         [-0.0166, -0.0164, -0.0792,  ...,  0.0966,  0.1313,  0.0254],\n",
       "         [ 0.0904, -0.0087, -0.0929,  ...,  0.0063,  0.0537, -0.0231]],\n",
       "        device='cuda:0'),\n",
       " 'roberta.encoder.layer.8.attention.self.query.lora_B': tensor([[ 0.0359, -0.0782, -0.0054,  ...,  0.0972, -0.1001,  0.0430],\n",
       "         [ 0.0009, -0.2371, -0.0658,  ..., -0.0988, -0.1408, -0.0148],\n",
       "         [ 0.0505, -0.1975, -0.0964,  ...,  0.1341, -0.0397,  0.0145],\n",
       "         ...,\n",
       "         [ 0.0215, -0.1713, -0.0252,  ...,  0.0100,  0.0359,  0.0199],\n",
       "         [-0.0024,  0.0461,  0.0606,  ..., -0.1536, -0.0876, -0.0616],\n",
       "         [-0.0030, -0.1501,  0.1605,  ..., -0.0718,  0.0348,  0.0206]],\n",
       "        device='cuda:0'),\n",
       " 'roberta.encoder.layer.8.attention.self.value.lora_A': tensor([[ 0.0902,  0.1087,  0.0313,  ...,  0.0625,  0.0354,  0.1345],\n",
       "         [-0.0386,  0.0705,  0.0389,  ...,  0.0652, -0.0013, -0.0457],\n",
       "         [ 0.0571,  0.0070, -0.0324,  ...,  0.0660,  0.0455,  0.0616],\n",
       "         ...,\n",
       "         [ 0.0651, -0.0351, -0.0323,  ...,  0.0050, -0.0640,  0.0605],\n",
       "         [ 0.0989, -0.0842, -0.0492,  ...,  0.0506, -0.0513,  0.0224],\n",
       "         [ 0.1129, -0.0496,  0.0079,  ...,  0.0212, -0.0182, -0.0441]],\n",
       "        device='cuda:0'),\n",
       " 'roberta.encoder.layer.8.attention.self.value.lora_B': tensor([[ 0.0241, -0.0077,  0.0301,  ...,  0.0053, -0.0151, -0.0017],\n",
       "         [ 0.0981, -0.0983,  0.0132,  ...,  0.0344,  0.0468,  0.0372],\n",
       "         [ 0.0910, -0.0170,  0.0826,  ...,  0.0572,  0.0314,  0.0259],\n",
       "         ...,\n",
       "         [ 0.0721, -0.0640,  0.0286,  ..., -0.0353, -0.1199, -0.0081],\n",
       "         [ 0.1025, -0.0622,  0.0659,  ..., -0.0701, -0.0123, -0.0578],\n",
       "         [ 0.1169,  0.0090, -0.0753,  ..., -0.0278, -0.0453, -0.0156]],\n",
       "        device='cuda:0'),\n",
       " 'roberta.encoder.layer.9.attention.self.query.lora_A': tensor([[-9.0624e-02, -1.0606e-01, -8.7359e-02,  ..., -8.3822e-02,\n",
       "          -1.6079e-01, -1.3377e-01],\n",
       "         [-1.4827e-02,  8.3512e-02, -2.2328e-02,  ..., -4.3596e-03,\n",
       "          -1.8808e-02,  2.0659e-02],\n",
       "         [-1.7089e-02,  3.1637e-02, -6.0915e-03,  ..., -7.4801e-02,\n",
       "           4.1340e-02,  9.9723e-03],\n",
       "         ...,\n",
       "         [ 2.6471e-03,  1.0246e-04,  4.6432e-02,  ...,  4.6287e-02,\n",
       "          -5.9479e-02, -7.8757e-02],\n",
       "         [ 4.1732e-02, -6.4008e-02,  1.2481e-01,  ...,  2.0077e-01,\n",
       "          -3.1942e-02, -2.3782e-02],\n",
       "         [-5.7241e-02, -1.1634e-02, -4.8001e-02,  ..., -5.5253e-02,\n",
       "           5.2158e-02, -2.1344e-02]], device='cuda:0'),\n",
       " 'roberta.encoder.layer.9.attention.self.query.lora_B': tensor([[-0.0213,  0.1079, -0.1868,  ...,  0.0024, -0.0790,  0.0588],\n",
       "         [ 0.0676,  0.0553, -0.0593,  ..., -0.0913, -0.0429, -0.1361],\n",
       "         [-0.0161,  0.0211,  0.1559,  ..., -0.1647,  0.1539, -0.0891],\n",
       "         ...,\n",
       "         [ 0.0252, -0.0354,  0.0562,  ...,  0.0151, -0.0266, -0.0149],\n",
       "         [-0.0012,  0.0162, -0.0526,  ...,  0.0339, -0.0658,  0.0928],\n",
       "         [-0.0494, -0.0758, -0.1735,  ...,  0.0405, -0.0254, -0.1304]],\n",
       "        device='cuda:0'),\n",
       " 'roberta.encoder.layer.9.attention.self.value.lora_A': tensor([[ 0.1044,  0.0961,  0.0673,  ...,  0.0663,  0.0941,  0.1108],\n",
       "         [-0.0245,  0.0368,  0.0526,  ...,  0.0698,  0.0281, -0.0043],\n",
       "         [-0.0400, -0.0278, -0.0625,  ..., -0.0183,  0.0036, -0.0085],\n",
       "         ...,\n",
       "         [ 0.0895,  0.0117,  0.0481,  ..., -0.0377, -0.0315,  0.0178],\n",
       "         [ 0.0527, -0.0256,  0.0039,  ..., -0.0400, -0.1054, -0.0545],\n",
       "         [ 0.0983,  0.0073,  0.0327,  ..., -0.1056, -0.0195,  0.0540]],\n",
       "        device='cuda:0'),\n",
       " 'roberta.encoder.layer.9.attention.self.value.lora_B': tensor([[-0.0503, -0.0208,  0.0821,  ..., -0.0310,  0.0193,  0.0899],\n",
       "         [-0.0022,  0.0133,  0.0417,  ...,  0.0133,  0.0099, -0.0977],\n",
       "         [ 0.0869,  0.0229, -0.0073,  ..., -0.0106,  0.0536,  0.0304],\n",
       "         ...,\n",
       "         [ 0.0318, -0.0154,  0.0624,  ..., -0.0019,  0.0403, -0.0398],\n",
       "         [ 0.0163,  0.0500, -0.0148,  ..., -0.1167, -0.0303,  0.1281],\n",
       "         [-0.0292, -0.0034, -0.0426,  ...,  0.0117, -0.0860, -0.0262]],\n",
       "        device='cuda:0'),\n",
       " 'roberta.encoder.layer.10.attention.self.query.lora_A': tensor([[-0.1019, -0.0550, -0.0742,  ..., -0.1335, -0.1456, -0.1098],\n",
       "         [ 0.0779,  0.0701, -0.1155,  ..., -0.1070, -0.0444,  0.0335],\n",
       "         [ 0.0354,  0.0923,  0.1228,  ...,  0.1021, -0.0068, -0.0522],\n",
       "         ...,\n",
       "         [-0.0476, -0.0344, -0.0235,  ..., -0.0035,  0.0215,  0.0089],\n",
       "         [ 0.0443,  0.1199, -0.0735,  ..., -0.0567, -0.0088, -0.0045],\n",
       "         [ 0.0116,  0.0151,  0.0324,  ..., -0.0496, -0.0884, -0.0534]],\n",
       "        device='cuda:0'),\n",
       " 'roberta.encoder.layer.10.attention.self.query.lora_B': tensor([[-2.8925e-02,  2.0276e-02, -4.1964e-02,  ..., -1.4818e-02,\n",
       "           9.2620e-02, -1.0796e-02],\n",
       "         [-3.4989e-02, -5.0085e-03, -7.8325e-02,  ...,  3.5337e-03,\n",
       "          -4.8848e-02, -3.4305e-02],\n",
       "         [-6.7844e-02,  1.6604e-02, -9.1194e-02,  ..., -4.6652e-02,\n",
       "          -7.7015e-03,  6.9947e-02],\n",
       "         ...,\n",
       "         [-1.6156e-02, -3.0070e-02, -1.5265e-02,  ..., -3.1805e-02,\n",
       "          -5.1578e-04, -2.1156e-01],\n",
       "         [ 5.8077e-01, -1.3347e-03, -6.6731e-03,  ...,  5.9685e-02,\n",
       "           4.3441e-02,  5.8485e-02],\n",
       "         [-3.5625e-02, -6.8675e-02, -8.1958e-03,  ..., -4.5485e-02,\n",
       "          -2.2329e-02, -2.8996e-02]], device='cuda:0'),\n",
       " 'roberta.encoder.layer.10.attention.self.value.lora_A': tensor([[-0.0822, -0.1016, -0.1146,  ..., -0.0665, -0.0883, -0.0976],\n",
       "         [ 0.1011,  0.0211,  0.0107,  ..., -0.1116, -0.0472,  0.0212],\n",
       "         [ 0.0169,  0.0086,  0.0470,  ..., -0.0805, -0.0294,  0.0910],\n",
       "         ...,\n",
       "         [-0.0729,  0.0279, -0.0523,  ...,  0.0349,  0.0142, -0.0118],\n",
       "         [ 0.0952,  0.1158, -0.0430,  ...,  0.0848,  0.0270,  0.1037],\n",
       "         [ 0.0216,  0.0192, -0.0088,  ..., -0.0299,  0.0610,  0.0420]],\n",
       "        device='cuda:0'),\n",
       " 'roberta.encoder.layer.10.attention.self.value.lora_B': tensor([[ 0.1418, -0.0047, -0.0346,  ..., -0.0586, -0.0067, -0.0396],\n",
       "         [ 0.0789, -0.0630, -0.0799,  ...,  0.0332, -0.0524,  0.0158],\n",
       "         [ 0.0991,  0.0174, -0.0228,  ..., -0.0093, -0.0369,  0.0318],\n",
       "         ...,\n",
       "         [-0.1498, -0.0182,  0.0073,  ..., -0.0252,  0.0208,  0.0011],\n",
       "         [ 0.1985, -0.0393,  0.0213,  ..., -0.0118,  0.0215, -0.0419],\n",
       "         [ 0.0102, -0.0106,  0.0186,  ..., -0.0843, -0.0262, -0.0419]],\n",
       "        device='cuda:0'),\n",
       " 'roberta.encoder.layer.11.attention.self.query.lora_A': tensor([[ 0.1409,  0.0751,  0.1159,  ...,  0.1399,  0.1006,  0.1055],\n",
       "         [-0.0111,  0.1002,  0.0726,  ...,  0.0581,  0.0448, -0.0763],\n",
       "         [ 0.0004,  0.0109, -0.0489,  ..., -0.0265,  0.0265,  0.0636],\n",
       "         ...,\n",
       "         [ 0.1251,  0.1109,  0.0441,  ..., -0.0870,  0.0224,  0.0038],\n",
       "         [ 0.0306, -0.0159, -0.0699,  ...,  0.0357,  0.0696,  0.0346],\n",
       "         [ 0.0123, -0.0536,  0.0076,  ..., -0.0971, -0.0480, -0.0271]],\n",
       "        device='cuda:0'),\n",
       " 'roberta.encoder.layer.11.attention.self.query.lora_B': tensor([[ 0.1279,  0.0729,  0.1548,  ..., -0.0212, -0.0143,  0.1222],\n",
       "         [-0.0568,  0.0027,  0.0258,  ..., -0.0388, -0.0660,  0.0315],\n",
       "         [ 0.0530,  0.0365, -0.0683,  ...,  0.0052,  0.0244, -0.0599],\n",
       "         ...,\n",
       "         [ 0.0388, -0.0338, -0.0539,  ..., -0.0618, -0.0701, -0.0442],\n",
       "         [-0.0586,  0.0162, -0.0997,  ...,  0.0958,  0.0005, -0.0447],\n",
       "         [ 0.0566, -0.1319,  0.0032,  ..., -0.0002, -0.0322, -0.0515]],\n",
       "        device='cuda:0'),\n",
       " 'roberta.encoder.layer.11.attention.self.value.lora_A': tensor([[ 0.0995,  0.0874,  0.0975,  ...,  0.0789,  0.0832,  0.1005],\n",
       "         [ 0.0491, -0.0104, -0.0025,  ..., -0.0447, -0.0225,  0.0200],\n",
       "         [ 0.0415,  0.1198, -0.0406,  ..., -0.0414,  0.0900, -0.0646],\n",
       "         ...,\n",
       "         [-0.0587,  0.0673, -0.0232,  ...,  0.0879, -0.0095,  0.0497],\n",
       "         [ 0.0392, -0.0460, -0.0762,  ...,  0.0079, -0.0895,  0.0088],\n",
       "         [ 0.0653, -0.0288, -0.0595,  ..., -0.0322,  0.0142, -0.0567]],\n",
       "        device='cuda:0'),\n",
       " 'roberta.encoder.layer.11.attention.self.value.lora_B': tensor([[-0.0267,  0.0044, -0.0161,  ...,  0.0603, -0.0438,  0.0721],\n",
       "         [-0.0552,  0.0277,  0.0998,  ...,  0.0077,  0.0593, -0.0512],\n",
       "         [ 0.0109,  0.0188, -0.0198,  ..., -0.0025, -0.0176,  0.0278],\n",
       "         ...,\n",
       "         [-0.0530, -0.0553, -0.0107,  ...,  0.0383,  0.0071,  0.0264],\n",
       "         [ 0.1623,  0.0302, -0.0199,  ...,  0.0188, -0.0149, -0.0412],\n",
       "         [-0.0986,  0.0791, -0.0210,  ...,  0.0262,  0.0196,  0.0435]],\n",
       "        device='cuda:0'),\n",
       " 'classifier.dense.weight': tensor([[ 0.0180, -0.0191,  0.0013,  ..., -0.0028,  0.0019, -0.0336],\n",
       "         [-0.0042, -0.0020, -0.0157,  ..., -0.0257, -0.0287,  0.0334],\n",
       "         [ 0.0282,  0.0170,  0.0279,  ...,  0.0129,  0.0298, -0.0062],\n",
       "         ...,\n",
       "         [-0.0312, -0.0173, -0.0045,  ..., -0.0131, -0.0321, -0.0155],\n",
       "         [-0.0172,  0.0119,  0.0007,  ..., -0.0316, -0.0109,  0.0295],\n",
       "         [-0.0346, -0.0143, -0.0066,  ...,  0.0299,  0.0078, -0.0063]],\n",
       "        device='cuda:0'),\n",
       " 'classifier.dense.bias': tensor([ 1.6475e-02,  2.4421e-02, -3.0963e-02,  6.4479e-03, -2.9927e-02,\n",
       "         -2.2009e-02,  2.0980e-02, -3.1832e-02,  1.3313e-02,  1.1476e-02,\n",
       "         -1.2870e-02,  2.4720e-02, -1.5941e-03, -6.8895e-04, -1.8180e-02,\n",
       "         -2.3117e-02,  3.1449e-02,  2.5672e-02, -2.4677e-02,  7.2431e-03,\n",
       "         -2.4518e-03,  1.6568e-02, -3.0677e-02, -1.8684e-02, -2.5919e-02,\n",
       "         -1.1137e-02, -3.1962e-02, -8.6650e-03,  1.5229e-02,  2.4852e-02,\n",
       "         -3.5887e-02,  2.0487e-02, -2.0209e-03,  3.3589e-02,  1.1486e-02,\n",
       "         -4.5463e-03, -7.6366e-03,  2.0951e-03, -3.3638e-02, -3.0706e-02,\n",
       "         -1.1442e-02,  3.3797e-02,  1.8798e-02, -2.0369e-02, -2.8688e-02,\n",
       "         -1.6446e-02,  2.1340e-03, -1.7605e-02, -1.4474e-02,  2.5455e-02,\n",
       "         -4.5251e-04,  9.7753e-03,  1.6292e-02, -5.9972e-03, -2.9811e-02,\n",
       "         -9.6597e-03,  2.9264e-02, -2.7918e-02, -3.2579e-02, -3.0528e-02,\n",
       "         -2.9086e-02,  1.1019e-02,  1.8792e-02, -7.2932e-04, -9.3212e-03,\n",
       "         -3.1183e-02,  2.2677e-03, -2.3925e-02,  1.1505e-02, -3.2669e-02,\n",
       "          1.3505e-02, -2.2213e-02, -2.3640e-02,  3.0212e-02, -2.3892e-02,\n",
       "         -2.0756e-02, -2.2790e-04,  2.7609e-02,  3.4228e-02, -2.6705e-02,\n",
       "         -3.1171e-03,  1.5872e-02, -2.3548e-02, -2.1464e-02,  2.6810e-02,\n",
       "          2.0173e-02, -8.4683e-03, -2.4477e-03,  3.4083e-02,  1.9705e-02,\n",
       "          1.3569e-02,  1.8423e-02,  1.0593e-02, -6.4118e-03, -9.5151e-03,\n",
       "          1.3563e-03, -1.3607e-02, -2.7220e-02,  3.0440e-02,  3.4089e-02,\n",
       "         -1.5456e-02,  6.1755e-03,  1.8728e-02,  9.1035e-03,  1.5333e-02,\n",
       "          2.5156e-02, -2.7742e-02, -3.0664e-03, -1.0091e-02,  1.7312e-02,\n",
       "         -1.6581e-02, -3.1991e-02, -1.2538e-02,  2.2366e-02,  1.4975e-02,\n",
       "         -3.0899e-02, -1.9656e-02,  3.1119e-02,  3.2532e-03, -1.6409e-02,\n",
       "         -1.3297e-02,  1.5338e-02,  9.6948e-04, -3.3777e-02,  1.4913e-02,\n",
       "          1.5340e-02, -1.3029e-02,  6.6855e-03,  7.9315e-03, -3.4992e-02,\n",
       "          1.5250e-02,  2.8133e-02, -3.1385e-02,  2.3811e-02,  1.9983e-02,\n",
       "          2.3419e-02,  2.9882e-02,  1.0577e-03, -1.1657e-02, -2.4127e-02,\n",
       "          1.8292e-02, -1.7352e-02, -1.9111e-02,  3.2324e-02,  4.7367e-03,\n",
       "         -4.3892e-03,  2.9539e-02,  2.6742e-02,  2.0267e-02,  1.1858e-02,\n",
       "          2.5815e-02,  1.6071e-02, -2.6374e-02, -2.9726e-02,  7.3824e-03,\n",
       "         -1.0083e-02, -1.9166e-02,  2.6893e-02,  9.7438e-03,  9.4431e-03,\n",
       "         -3.0410e-02,  2.4585e-03,  3.0516e-02,  2.3375e-02, -1.0966e-02,\n",
       "         -3.4495e-03, -3.1460e-02, -6.3098e-03,  2.0491e-02, -1.9962e-02,\n",
       "          8.8330e-03,  1.2680e-02, -1.4261e-02, -4.8918e-03, -5.4891e-03,\n",
       "          3.1527e-02, -1.5018e-02, -1.9244e-02,  7.0263e-04, -1.6445e-02,\n",
       "          3.1912e-02,  1.1854e-02,  2.7413e-02, -2.9154e-02,  2.8805e-02,\n",
       "          3.1309e-02,  1.2984e-02,  2.0330e-02, -7.8475e-03, -2.4631e-03,\n",
       "         -9.6998e-03,  1.5997e-02, -1.9705e-02,  1.5609e-02, -2.3638e-02,\n",
       "          6.4857e-03, -1.7453e-02,  2.7154e-03, -2.8588e-02,  9.5789e-03,\n",
       "          2.2709e-02,  8.0878e-05,  3.2715e-02, -3.5955e-02,  1.2946e-02,\n",
       "          6.2962e-03,  3.4257e-02,  1.8860e-02,  3.5457e-02,  3.2379e-02,\n",
       "          8.4240e-03, -1.8737e-03,  2.5129e-02,  6.7445e-03, -5.1705e-03,\n",
       "          3.4532e-02,  1.0856e-03, -5.5089e-04,  2.8197e-02,  3.1648e-02,\n",
       "          1.5642e-02, -1.1721e-02,  3.4215e-02,  3.2168e-02, -3.0089e-02,\n",
       "         -1.3905e-02, -3.0568e-02,  1.0545e-02, -5.2915e-03,  2.7630e-02,\n",
       "          3.2586e-02, -1.8375e-02,  2.3575e-02, -3.2753e-02,  2.3048e-02,\n",
       "         -3.4372e-02,  9.1141e-03, -2.9788e-02,  1.9143e-02,  8.4445e-03,\n",
       "         -2.6434e-02,  2.9232e-02, -1.0169e-02,  3.4995e-02, -6.8743e-03,\n",
       "          2.6271e-02,  4.0102e-03,  3.3903e-02, -2.1913e-02,  3.2179e-02,\n",
       "          2.2513e-02,  3.1484e-02, -8.5296e-03, -2.0336e-02,  3.0785e-02,\n",
       "          2.4635e-02, -1.2377e-03,  1.1182e-02, -1.0914e-02,  3.1301e-02,\n",
       "          3.4804e-02, -1.9053e-02,  2.1966e-02, -3.0700e-02,  3.2261e-02,\n",
       "         -3.7758e-04, -2.8762e-02,  2.1746e-03,  2.9582e-02, -7.0811e-03,\n",
       "         -8.8892e-03,  2.9879e-02, -1.9227e-03, -2.1325e-02, -1.5766e-02,\n",
       "          2.7480e-04, -2.5843e-02, -2.4079e-02,  2.2901e-02, -1.2670e-02,\n",
       "          2.7463e-02, -2.6357e-04,  5.1419e-03, -1.3941e-03, -5.4837e-03,\n",
       "         -7.7822e-04,  1.6294e-02,  1.1703e-02, -1.8672e-02,  3.1045e-02,\n",
       "         -8.6542e-03,  1.5825e-02,  9.5663e-05, -1.6730e-02, -1.4074e-02,\n",
       "         -2.6917e-02, -1.3258e-02,  4.6434e-03, -1.2393e-02, -2.2182e-02,\n",
       "          3.3810e-02,  2.7997e-02,  1.3851e-02,  5.4966e-03, -3.3937e-02,\n",
       "          2.1646e-02,  2.4580e-02, -6.2955e-03, -1.3336e-02,  3.1912e-02,\n",
       "          3.4265e-02, -3.1452e-03, -2.2864e-02,  2.5268e-02,  1.7027e-03,\n",
       "          3.2351e-02, -3.2206e-02, -1.0961e-02,  3.3257e-02, -4.2476e-03,\n",
       "          7.0791e-04,  3.1686e-02, -1.3471e-02, -9.5604e-03,  3.3309e-02,\n",
       "         -2.8166e-02,  3.7522e-03,  1.3937e-02,  2.9271e-02, -1.3110e-02,\n",
       "         -2.7751e-02, -8.8224e-03, -1.2878e-02,  2.8578e-02, -3.5661e-02,\n",
       "         -3.3235e-02, -1.9332e-02, -2.0199e-02, -2.3387e-02,  2.0122e-02,\n",
       "          1.4426e-02,  1.5483e-02, -3.1944e-02, -2.5797e-02, -1.0442e-02,\n",
       "          3.9808e-03,  3.3778e-02, -2.2063e-02,  1.7894e-02,  3.0188e-02,\n",
       "         -2.3631e-02, -1.0152e-02, -1.6711e-02,  6.6690e-03,  3.0511e-02,\n",
       "         -7.8510e-03,  3.4963e-02,  1.9673e-04,  2.7143e-02,  2.3922e-02,\n",
       "          2.3061e-02, -3.2179e-02,  3.5863e-02,  4.3182e-03, -2.2546e-02,\n",
       "         -5.1112e-03, -4.5592e-03,  3.3356e-02, -2.6851e-02, -2.6368e-02,\n",
       "         -3.4509e-02,  3.6083e-02, -2.8456e-02, -3.0533e-02,  5.0199e-03,\n",
       "         -1.9127e-02,  2.9752e-02,  4.1624e-03, -6.9362e-03, -1.0245e-02,\n",
       "          1.8084e-02,  2.9349e-02,  1.4301e-02, -6.4515e-03, -2.2312e-02,\n",
       "          3.2872e-02,  5.1532e-03, -1.4348e-02, -9.3416e-03, -1.5367e-02,\n",
       "          2.1837e-02, -1.8520e-02,  1.1742e-02,  1.3618e-02,  2.3478e-02,\n",
       "         -1.5516e-02, -2.6912e-02, -1.5502e-02, -1.5314e-02,  2.0801e-02,\n",
       "          1.7005e-02,  1.6361e-03, -2.0818e-02, -1.6914e-02,  1.0416e-02,\n",
       "         -2.8877e-02,  1.5466e-02, -4.2155e-03,  1.2332e-02, -1.0443e-02,\n",
       "         -2.3425e-02,  2.6616e-02, -6.4081e-03, -2.9826e-02, -1.6841e-02,\n",
       "         -2.4343e-02,  1.6315e-03,  2.7704e-02, -3.2513e-02, -3.3244e-02,\n",
       "         -2.6826e-02, -3.2804e-03,  2.3488e-03, -9.2301e-03,  2.1314e-03,\n",
       "         -1.9201e-02, -1.8448e-02, -6.2761e-03, -3.5936e-02, -3.0436e-02,\n",
       "         -2.1211e-02, -2.8152e-02, -2.7396e-02,  1.7529e-02,  8.1542e-03,\n",
       "         -1.6433e-02,  3.2629e-02,  2.9519e-02,  2.7514e-02,  4.6408e-03,\n",
       "          8.1374e-03, -2.4273e-03, -6.1715e-03, -1.6582e-03,  1.6757e-02,\n",
       "          6.4319e-03,  1.1610e-02,  5.7241e-03, -3.4771e-02,  2.3960e-03,\n",
       "         -1.1880e-02, -2.7830e-02, -1.6902e-03, -2.6204e-02,  2.4310e-02,\n",
       "          3.0004e-02, -2.4779e-02,  3.3051e-02,  3.2911e-02,  3.2537e-02,\n",
       "          3.2701e-02,  1.5715e-02,  1.6032e-02, -1.7077e-02,  2.9093e-02,\n",
       "         -1.0187e-02,  1.2331e-02,  8.9493e-03,  3.5440e-02, -1.5592e-02,\n",
       "         -1.4185e-02,  1.0907e-02,  5.5895e-03,  4.0683e-03, -2.5520e-03,\n",
       "         -2.4035e-02, -1.0452e-02, -2.4456e-02, -9.2868e-03,  4.2418e-04,\n",
       "         -2.6148e-02, -1.5777e-02, -8.1257e-03, -3.2501e-03, -1.5248e-02,\n",
       "         -2.5798e-02, -1.9066e-02,  4.0800e-03, -2.5835e-02,  9.9632e-03,\n",
       "         -2.9654e-02, -3.3539e-02, -2.4370e-02, -9.5742e-03,  1.4673e-02,\n",
       "         -4.6579e-03, -2.4513e-02,  6.9268e-03, -1.7067e-02,  2.3447e-02,\n",
       "          3.7365e-03, -3.0962e-02,  1.2173e-02,  2.7734e-02, -3.3466e-02,\n",
       "         -2.9907e-02, -1.6615e-02,  2.6796e-03,  5.3966e-03,  3.1051e-02,\n",
       "          3.0783e-02, -2.1676e-02, -1.1227e-02,  2.0273e-02, -3.2566e-02,\n",
       "         -2.5011e-02, -2.7512e-02,  2.0876e-02,  2.6417e-02,  3.5140e-02,\n",
       "         -2.2263e-03,  1.9504e-02,  2.3231e-02, -1.8356e-03, -4.1545e-03,\n",
       "          2.0000e-02, -3.5670e-02, -2.6997e-03, -1.1349e-02, -9.2359e-03,\n",
       "          7.2796e-03, -5.6432e-03, -6.3156e-03,  1.8599e-02,  2.6397e-02,\n",
       "         -2.7733e-03, -2.7744e-02,  3.6101e-02, -2.5549e-02,  1.2825e-02,\n",
       "         -1.7467e-02,  1.1389e-02,  1.4816e-02,  1.4043e-03, -1.4285e-02,\n",
       "         -1.1017e-02,  2.6422e-02,  3.4326e-02, -5.2949e-03, -4.7256e-03,\n",
       "         -8.9706e-03, -1.0114e-02,  1.9245e-02, -1.4084e-02,  2.2514e-02,\n",
       "         -9.7663e-03, -3.5889e-02,  2.5398e-02,  9.5337e-03, -1.3794e-02,\n",
       "         -1.3650e-03, -5.7459e-03,  1.5442e-02,  1.1297e-02, -1.0152e-03,\n",
       "         -6.2574e-03, -1.4173e-02,  2.7941e-03,  6.2527e-03, -2.7642e-02,\n",
       "         -4.7037e-04, -1.0723e-02,  1.3266e-02,  1.3722e-02, -1.4858e-02,\n",
       "         -2.1665e-02, -1.7462e-02, -2.0966e-02, -3.5653e-02, -1.2988e-02,\n",
       "         -1.5101e-02,  1.7574e-02,  6.0750e-03, -1.6028e-02, -2.4752e-02,\n",
       "          1.7585e-02, -2.3510e-02,  1.2938e-02, -2.5782e-02, -7.3074e-03,\n",
       "         -2.1036e-02, -3.4949e-02,  1.0524e-02, -6.1948e-03, -3.3998e-03,\n",
       "          3.3528e-02,  2.2255e-02,  5.5267e-03,  1.8331e-02,  1.0710e-02,\n",
       "         -2.8317e-02, -3.9319e-03, -3.4249e-02, -3.4042e-02, -1.3228e-03,\n",
       "         -3.2467e-02, -1.9314e-02,  3.3187e-02, -3.4636e-02, -2.9013e-03,\n",
       "         -1.3155e-02,  1.4774e-02, -1.9047e-02,  1.1313e-02, -9.0729e-03,\n",
       "          5.3368e-03,  8.5243e-04, -1.1314e-02, -2.4072e-02, -2.0933e-02,\n",
       "         -8.0364e-04,  3.5424e-02,  3.2216e-02,  1.7941e-02,  2.5943e-02,\n",
       "         -2.4610e-03,  2.8608e-02,  1.4937e-02, -1.0517e-02,  3.3803e-02,\n",
       "         -1.9161e-02, -5.4902e-03,  5.7873e-03, -2.3334e-02,  3.1550e-02,\n",
       "         -1.9428e-02,  4.0985e-03, -5.8857e-03, -8.5034e-03,  1.9697e-02,\n",
       "         -1.1136e-02,  1.1972e-02, -7.2804e-03,  2.1101e-02, -2.2374e-02,\n",
       "          7.4428e-03,  1.1270e-02,  2.5290e-02,  7.5689e-03, -1.4788e-02,\n",
       "          3.7370e-03, -2.2118e-02,  1.9082e-02,  3.3702e-02,  1.2359e-02,\n",
       "          2.2681e-02,  3.5099e-03, -1.1345e-02,  1.4834e-03, -1.8055e-02,\n",
       "         -1.1170e-02, -1.7475e-03, -1.0581e-02, -1.8887e-02,  2.7654e-02,\n",
       "         -1.4997e-02, -1.7530e-02, -1.6496e-02,  2.9328e-03,  1.9419e-02,\n",
       "          1.9813e-02, -3.3217e-03, -1.9014e-02,  5.4742e-03,  2.5474e-02,\n",
       "         -9.3875e-03,  2.9626e-02,  2.8864e-02,  3.5300e-02, -1.6765e-02,\n",
       "          1.1817e-02,  2.2404e-02, -3.1858e-02, -3.1600e-02,  6.9076e-03,\n",
       "          1.6712e-03,  2.2420e-02,  3.4242e-02, -3.0643e-02,  2.5358e-02,\n",
       "          1.5823e-02, -1.5555e-02, -2.3073e-02, -1.2345e-02, -1.0609e-02,\n",
       "          1.0808e-02, -2.7527e-02,  6.4504e-03,  1.7655e-02,  2.5388e-02,\n",
       "         -2.1614e-02,  3.0205e-02, -3.5525e-02,  6.1643e-03,  1.1976e-02,\n",
       "          2.1437e-02,  1.4943e-02,  2.1029e-03,  8.6262e-03,  3.5470e-02,\n",
       "         -5.9251e-03,  5.2818e-03,  5.6083e-04, -2.3082e-02,  4.8785e-03,\n",
       "         -3.2273e-02, -3.2245e-02, -4.0197e-03, -3.2250e-02, -6.5469e-03,\n",
       "         -4.4593e-03, -1.6016e-02,  2.9888e-02, -4.1936e-03,  9.2584e-03,\n",
       "          1.4113e-02, -1.1080e-02,  2.9097e-02,  2.1923e-02,  1.6881e-02,\n",
       "         -1.0438e-02, -3.3976e-02, -1.0051e-02, -3.3835e-02, -2.7009e-03,\n",
       "          3.1676e-02, -4.8868e-03,  2.0656e-02,  1.9575e-03, -6.2321e-03,\n",
       "         -3.5537e-02,  1.6004e-02,  8.2573e-03,  2.5728e-02, -1.9067e-02,\n",
       "          2.6133e-02,  2.7255e-05,  4.7642e-03,  2.7905e-03, -9.3275e-03,\n",
       "         -2.3947e-02,  3.1308e-02,  2.5030e-02, -3.3564e-02, -4.0092e-03,\n",
       "         -1.4926e-02,  3.5675e-02, -5.0990e-03, -4.5677e-03, -1.4800e-02,\n",
       "          1.7124e-03,  1.3738e-03, -7.6950e-03,  1.4607e-03, -2.8364e-02,\n",
       "          2.4793e-02, -1.9643e-02,  1.0727e-03], device='cuda:0'),\n",
       " 'classifier.out_proj.weight': tensor([[-0.0010, -0.0341,  0.0157,  ...,  0.0277, -0.0258, -0.0136],\n",
       "         [ 0.0313, -0.0277, -0.0190,  ..., -0.0073,  0.0265, -0.0225]],\n",
       "        device='cuda:0'),\n",
       " 'classifier.out_proj.bias': tensor([ 0.0002, -0.0170], device='cuda:0')}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lora_state_dict = torch.load('/home/lab/bumjun/lora-training/LoRA/examples/NLU/sst2/lora/2023-09-11_16:37:03lorackpt.bin')\n",
    "lora_state_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(10.9219, device='cuda:0')\n",
      "tensor(9.6851, device='cuda:0')\n",
      "tensor(9.1127, device='cuda:0')\n",
      "tensor(9.2301, device='cuda:0')\n",
      "tensor(9.3997, device='cuda:0')\n",
      "tensor(8.9274, device='cuda:0')\n",
      "tensor(8.9530, device='cuda:0')\n",
      "tensor(9.2583, device='cuda:0')\n",
      "tensor(8.9385, device='cuda:0')\n",
      "tensor(9.1729, device='cuda:0')\n",
      "tensor(8.7749, device='cuda:0')\n",
      "tensor(9.0307, device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "for i in range(12):\n",
    "    lora_state_dict[f'roberta.encoder.layer.{i}.attention.self.query.lora_A']\n",
    "    #print(lora_state_dict[f'roberta.encoder.layer.{i}.attention.self.query.lora_B'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['roberta.encoder.layer.0.attention.self.query.lora_A', 'roberta.encoder.layer.0.attention.self.query.lora_B', 'roberta.encoder.layer.0.attention.self.value.lora_A', 'roberta.encoder.layer.0.attention.self.value.lora_B', 'roberta.encoder.layer.1.attention.self.query.lora_A', 'roberta.encoder.layer.1.attention.self.query.lora_B', 'roberta.encoder.layer.1.attention.self.value.lora_A', 'roberta.encoder.layer.1.attention.self.value.lora_B', 'roberta.encoder.layer.2.attention.self.query.lora_A', 'roberta.encoder.layer.2.attention.self.query.lora_B', 'roberta.encoder.layer.2.attention.self.value.lora_A', 'roberta.encoder.layer.2.attention.self.value.lora_B', 'roberta.encoder.layer.3.attention.self.query.lora_A', 'roberta.encoder.layer.3.attention.self.query.lora_B', 'roberta.encoder.layer.3.attention.self.value.lora_A', 'roberta.encoder.layer.3.attention.self.value.lora_B', 'roberta.encoder.layer.4.attention.self.query.lora_A', 'roberta.encoder.layer.4.attention.self.query.lora_B', 'roberta.encoder.layer.4.attention.self.value.lora_A', 'roberta.encoder.layer.4.attention.self.value.lora_B', 'roberta.encoder.layer.5.attention.self.query.lora_A', 'roberta.encoder.layer.5.attention.self.query.lora_B', 'roberta.encoder.layer.5.attention.self.value.lora_A', 'roberta.encoder.layer.5.attention.self.value.lora_B', 'roberta.encoder.layer.6.attention.self.query.lora_A', 'roberta.encoder.layer.6.attention.self.query.lora_B', 'roberta.encoder.layer.6.attention.self.value.lora_A', 'roberta.encoder.layer.6.attention.self.value.lora_B', 'roberta.encoder.layer.7.attention.self.query.lora_A', 'roberta.encoder.layer.7.attention.self.query.lora_B', 'roberta.encoder.layer.7.attention.self.value.lora_A', 'roberta.encoder.layer.7.attention.self.value.lora_B', 'roberta.encoder.layer.8.attention.self.query.lora_A', 'roberta.encoder.layer.8.attention.self.query.lora_B', 'roberta.encoder.layer.8.attention.self.value.lora_A', 'roberta.encoder.layer.8.attention.self.value.lora_B', 'roberta.encoder.layer.9.attention.self.query.lora_A', 'roberta.encoder.layer.9.attention.self.query.lora_B', 'roberta.encoder.layer.9.attention.self.value.lora_A', 'roberta.encoder.layer.9.attention.self.value.lora_B', 'roberta.encoder.layer.10.attention.self.query.lora_A', 'roberta.encoder.layer.10.attention.self.query.lora_B', 'roberta.encoder.layer.10.attention.self.value.lora_A', 'roberta.encoder.layer.10.attention.self.value.lora_B', 'roberta.encoder.layer.11.attention.self.query.lora_A', 'roberta.encoder.layer.11.attention.self.query.lora_B', 'roberta.encoder.layer.11.attention.self.value.lora_A', 'roberta.encoder.layer.11.attention.self.value.lora_B', 'classifier.dense.weight', 'classifier.dense.bias', 'classifier.out_proj.weight', 'classifier.out_proj.bias'])\n"
     ]
    }
   ],
   "source": [
    "print(lora_state_dict.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.0010, -0.0341,  0.0157,  ...,  0.0277, -0.0258, -0.0136],\n",
       "        [ 0.0313, -0.0277, -0.0190,  ..., -0.0073,  0.0265, -0.0225]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.classifier.out_proj.weight.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AFTER LOAD LORA\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.0322, -0.0359, -0.0232,  ...,  0.0358,  0.0125,  0.0275],\n",
       "        [-0.0214, -0.0352, -0.0192,  ...,  0.0032, -0.0262, -0.0343],\n",
       "        [ 0.0182,  0.0004, -0.0124,  ...,  0.0281,  0.0066, -0.0108],\n",
       "        ...,\n",
       "        [-0.0222, -0.0039,  0.0108,  ...,  0.0196,  0.0040,  0.0186],\n",
       "        [ 0.0353,  0.0337,  0.0345,  ...,  0.0277,  0.0004,  0.0060],\n",
       "        [ 0.0220,  0.0234, -0.0042,  ...,  0.0074,  0.0276, -0.0044]])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"AFTER LOAD LORA\")\n",
    "model.roberta.encoder.layer[0].attention.self.value.weight.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at textattack/roberta-base-SST-2 were not used when initializing RobertaForSequenceClassification: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "- This IS expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "new_model = copy.deepcopy(AutoModelForSequenceClassification.from_pretrained(\n",
    "        'textattack/roberta-base-SST-2'\n",
    "    ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def W_weight_copy(new_model, W_model):\n",
    "    len_of_layers = 12\n",
    "    q_encoder_weight_list = []\n",
    "    v_encoder_weight_list = []\n",
    "    q_encoder_bias_list = []\n",
    "    v_encoder_bias_list = []\n",
    "\n",
    "    for i in range(len_of_layers):\n",
    "        q_encoder_new_weight = W_model.roberta.encoder.layer[i].attention.self.query.weight.data\n",
    "        q_encoder_weight_list.append(q_encoder_new_weight)\n",
    "        q_encoder_new_bias = W_model.roberta.encoder.layer[i].attention.self.query.bias.data\n",
    "        q_encoder_bias_list.append(q_encoder_new_bias)\n",
    "\n",
    "        v_encoder_new_weight = W_model.roberta.encoder.layer[i].attention.self.value.weight.data\n",
    "        v_encoder_weight_list.append(v_encoder_new_weight)\n",
    "        v_encoder_new_bias = W_model.roberta.encoder.layer[i].attention.self.value.bias.data\n",
    "        v_encoder_bias_list.append(v_encoder_new_bias)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for i in range(len_of_layers):\n",
    "            new_model.roberta.encoder.layer[i].attention.self.query.weight.data.copy_(q_encoder_weight_list[i])\n",
    "            new_model.roberta.encoder.layer[i].attention.self.value.weight.data.copy_(v_encoder_weight_list[i])\n",
    "            new_model.roberta.encoder.layer[i].attention.self.query.bias.data.copy_(q_encoder_bias_list[i])\n",
    "            new_model.roberta.encoder.layer[i].attention.self.value.bias.data.copy_(v_encoder_bias_list[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        ...,\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.]])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.roberta.encoder.layer[0].attention.self.query.weight.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.0732, -0.0019, -0.0901,  ...,  0.1035,  0.0895, -0.1039],\n",
       "        [-0.0503,  0.2062,  0.0739,  ...,  0.0655,  0.0638,  0.1283],\n",
       "        [ 0.0873,  0.0705, -0.0510,  ..., -0.0434, -0.0083,  0.1095],\n",
       "        ...,\n",
       "        [-0.1872,  0.0175, -0.0310,  ..., -0.0509,  0.1026, -0.1170],\n",
       "        [-0.2543,  0.0437,  0.0641,  ...,  0.0709, -0.1043,  0.0117],\n",
       "        [-0.0517, -0.0858,  0.1024,  ..., -0.1888,  0.0034, -0.0538]])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "W_weight_copy(model, new_model)\n",
    "model.roberta.encoder.layer[0].attention.self.query.weight.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(78.2082) tensor(78.2082)\n",
      "tensor(57.5268) tensor(57.5268)\n",
      "tensor(52.0564) tensor(52.0564)\n",
      "tensor(55.0221) tensor(55.0221)\n",
      "tensor(56.1601) tensor(56.1601)\n",
      "tensor(52.9273) tensor(52.9273)\n",
      "tensor(52.9121) tensor(52.9121)\n",
      "tensor(56.8583) tensor(56.8583)\n",
      "tensor(51.9982) tensor(51.9982)\n",
      "tensor(50.7544) tensor(50.7544)\n",
      "tensor(51.3512) tensor(51.3512)\n",
      "tensor(52.4352) tensor(52.4352)\n"
     ]
    }
   ],
   "source": [
    "for i in range(12):\n",
    "    print( torch.norm(model.roberta.encoder.layer[i].attention.self.query.weight.data), torch.norm(model.roberta.encoder.layer[i].attention.self.query.weight.data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(77.4265) tensor(77.4265)\n",
      "tensor(56.4624) tensor(56.4624)\n",
      "tensor(51.3908) tensor(51.3908)\n",
      "tensor(53.2840) tensor(53.2840)\n",
      "tensor(54.1298) tensor(54.1298)\n",
      "tensor(51.0863) tensor(51.0863)\n",
      "tensor(51.0968) tensor(51.0968)\n",
      "tensor(55.2711) tensor(55.2711)\n",
      "tensor(50.8302) tensor(50.8302)\n",
      "tensor(49.9693) tensor(49.9693)\n",
      "tensor(49.5151) tensor(49.5151)\n",
      "tensor(51.6066) tensor(51.6066)\n"
     ]
    }
   ],
   "source": [
    "for i in range(12):\n",
    "    print( torch.norm(model.roberta.encoder.layer[i].attention.self.key.weight.data), torch.norm(model.roberta.encoder.layer[i].attention.self.key.weight.data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(2.3070, grad_fn=<CopyBackwards>), tensor(0., grad_fn=<CopyBackwards>))"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "insert_lora(new_model, 768, 16, 16)\n",
    "#lora_state_dict = torch.load('/home/lab/bumjun/lora-training/LoRA/examples/NLU/sst2/r64r64r64/model/checkpoint-13175/pytorch_model.bin')\n",
    "#new_model.load_state_dict(lora_state_dict, strict=False)\n",
    "torch.norm(new_model.roberta.encoder.layer[0].attention.self.query.lora_A),torch.norm(new_model.roberta.encoder.layer[0].attention.self.query.lora_B)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(10.9219, grad_fn=<CopyBackwards>) tensor(10.8647, grad_fn=<CopyBackwards>)\n",
      "tensor(9.6851, grad_fn=<CopyBackwards>) tensor(9.6469, grad_fn=<CopyBackwards>)\n",
      "tensor(9.1127, grad_fn=<CopyBackwards>) tensor(9.0218, grad_fn=<CopyBackwards>)\n",
      "tensor(9.2301, grad_fn=<CopyBackwards>) tensor(9.2332, grad_fn=<CopyBackwards>)\n",
      "tensor(9.3997, grad_fn=<CopyBackwards>) tensor(9.3910, grad_fn=<CopyBackwards>)\n",
      "tensor(8.9274, grad_fn=<CopyBackwards>) tensor(8.9347, grad_fn=<CopyBackwards>)\n",
      "tensor(8.9530, grad_fn=<CopyBackwards>) tensor(8.9259, grad_fn=<CopyBackwards>)\n",
      "tensor(9.2584, grad_fn=<CopyBackwards>) tensor(9.2404, grad_fn=<CopyBackwards>)\n",
      "tensor(8.9385, grad_fn=<CopyBackwards>) tensor(8.9553, grad_fn=<CopyBackwards>)\n",
      "tensor(9.1729, grad_fn=<CopyBackwards>) tensor(9.1983, grad_fn=<CopyBackwards>)\n",
      "tensor(8.7749, grad_fn=<CopyBackwards>) tensor(8.7662, grad_fn=<CopyBackwards>)\n",
      "tensor(9.0308, grad_fn=<CopyBackwards>) tensor(9.0136, grad_fn=<CopyBackwards>)\n"
     ]
    }
   ],
   "source": [
    "for i in range(12):\n",
    "    print( torch.norm(model.roberta.encoder.layer[i].attention.self.query.lora_A), torch.norm(model.roberta.encoder.layer[i].attention.self.query.lora_B))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([16, 768]), torch.Size([128, 768]))"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.roberta.encoder.layer[i].attention.self.query.lora_A.shape, new_model.roberta.encoder.layer[i].attention.self.query.lora_A.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(2.3070, grad_fn=<CopyBackwards>) tensor(0., grad_fn=<CopyBackwards>)\n",
      "tensor(2.2959, grad_fn=<CopyBackwards>) tensor(0., grad_fn=<CopyBackwards>)\n",
      "tensor(2.3106, grad_fn=<CopyBackwards>) tensor(0., grad_fn=<CopyBackwards>)\n",
      "tensor(2.3133, grad_fn=<CopyBackwards>) tensor(0., grad_fn=<CopyBackwards>)\n",
      "tensor(2.3033, grad_fn=<CopyBackwards>) tensor(0., grad_fn=<CopyBackwards>)\n",
      "tensor(2.3186, grad_fn=<CopyBackwards>) tensor(0., grad_fn=<CopyBackwards>)\n",
      "tensor(2.3104, grad_fn=<CopyBackwards>) tensor(0., grad_fn=<CopyBackwards>)\n",
      "tensor(2.2942, grad_fn=<CopyBackwards>) tensor(0., grad_fn=<CopyBackwards>)\n",
      "tensor(2.3172, grad_fn=<CopyBackwards>) tensor(0., grad_fn=<CopyBackwards>)\n",
      "tensor(2.3137, grad_fn=<CopyBackwards>) tensor(0., grad_fn=<CopyBackwards>)\n",
      "tensor(2.2999, grad_fn=<CopyBackwards>) tensor(0., grad_fn=<CopyBackwards>)\n",
      "tensor(2.3121, grad_fn=<CopyBackwards>) tensor(0., grad_fn=<CopyBackwards>)\n"
     ]
    }
   ],
   "source": [
    "for i in range(12):\n",
    "    print( torch.norm(new_model.roberta.encoder.layer[i].attention.self.query.lora_A), torch.norm(new_model.roberta.encoder.layer[i].attention.self.query.lora_B))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter containing:\n",
      "tensor([[ 0.0139,  0.0295, -0.0040,  ..., -0.0151, -0.0048, -0.0237],\n",
      "        [ 0.0140, -0.0060, -0.0127,  ..., -0.0104, -0.0056,  0.0150],\n",
      "        [-0.0277, -0.0122,  0.0181,  ..., -0.0182, -0.0130, -0.0210],\n",
      "        ...,\n",
      "        [-0.0322, -0.0211, -0.0048,  ...,  0.0252, -0.0280, -0.0230],\n",
      "        [ 0.0040, -0.0131,  0.0132,  ..., -0.0281, -0.0081,  0.0275],\n",
      "        [ 0.0028,  0.0217,  0.0232,  ..., -0.0175, -0.0163,  0.0122]],\n",
      "       requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[ 0.0014,  0.0105,  0.0071,  ...,  0.0169,  0.0251,  0.0073],\n",
      "        [ 0.0359,  0.0251, -0.0356,  ..., -0.0108,  0.0021,  0.0284],\n",
      "        [ 0.0264,  0.0078, -0.0033,  ...,  0.0056, -0.0003,  0.0356],\n",
      "        ...,\n",
      "        [ 0.0086,  0.0262, -0.0339,  ..., -0.0129,  0.0065, -0.0028],\n",
      "        [ 0.0032,  0.0008, -0.0006,  ...,  0.0216,  0.0007,  0.0063],\n",
      "        [-0.0142, -0.0030, -0.0137,  ..., -0.0214,  0.0346,  0.0010]],\n",
      "       requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[-0.0354, -0.0112, -0.0100,  ..., -0.0187, -0.0092,  0.0163],\n",
      "        [-0.0218,  0.0198,  0.0272,  ...,  0.0346, -0.0260,  0.0043],\n",
      "        [-0.0359, -0.0164,  0.0055,  ..., -0.0013, -0.0188,  0.0007],\n",
      "        ...,\n",
      "        [-0.0262,  0.0132, -0.0035,  ..., -0.0028,  0.0056, -0.0206],\n",
      "        [ 0.0033, -0.0100, -0.0029,  ...,  0.0086,  0.0249,  0.0060],\n",
      "        [-0.0309,  0.0217, -0.0120,  ...,  0.0185, -0.0115, -0.0255]],\n",
      "       requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[-0.0009,  0.0200, -0.0168,  ..., -0.0181, -0.0199, -0.0036],\n",
      "        [ 0.0233, -0.0075,  0.0109,  ...,  0.0223, -0.0071,  0.0326],\n",
      "        [-0.0271,  0.0032, -0.0274,  ...,  0.0162,  0.0079, -0.0155],\n",
      "        ...,\n",
      "        [-0.0334, -0.0155,  0.0093,  ...,  0.0339, -0.0246, -0.0059],\n",
      "        [ 0.0234,  0.0268, -0.0155,  ...,  0.0247, -0.0032, -0.0343],\n",
      "        [-0.0125, -0.0350,  0.0226,  ...,  0.0023, -0.0070, -0.0197]],\n",
      "       requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[ 0.0094, -0.0121, -0.0345,  ..., -0.0336, -0.0341,  0.0186],\n",
      "        [-0.0167, -0.0206,  0.0353,  ...,  0.0336, -0.0002, -0.0290],\n",
      "        [ 0.0025,  0.0287, -0.0198,  ..., -0.0356,  0.0337,  0.0341],\n",
      "        ...,\n",
      "        [ 0.0066,  0.0213,  0.0228,  ..., -0.0307,  0.0090,  0.0222],\n",
      "        [ 0.0037,  0.0263,  0.0186,  ...,  0.0085, -0.0113, -0.0204],\n",
      "        [ 0.0052,  0.0034,  0.0274,  ..., -0.0326, -0.0203, -0.0252]],\n",
      "       requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[ 0.0259, -0.0227,  0.0103,  ...,  0.0197,  0.0074,  0.0101],\n",
      "        [-0.0202,  0.0266, -0.0149,  ...,  0.0099, -0.0064, -0.0288],\n",
      "        [-0.0280,  0.0156, -0.0303,  ...,  0.0229, -0.0244,  0.0204],\n",
      "        ...,\n",
      "        [-0.0141, -0.0076,  0.0183,  ...,  0.0064,  0.0192,  0.0026],\n",
      "        [-0.0330,  0.0012, -0.0284,  ...,  0.0208,  0.0113,  0.0142],\n",
      "        [-0.0333,  0.0291, -0.0238,  ...,  0.0197, -0.0201,  0.0049]],\n",
      "       requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[ 0.0006,  0.0114,  0.0015,  ...,  0.0099,  0.0278,  0.0304],\n",
      "        [ 0.0301,  0.0127,  0.0053,  ..., -0.0093,  0.0014,  0.0131],\n",
      "        [-0.0044, -0.0050,  0.0281,  ..., -0.0150,  0.0033,  0.0091],\n",
      "        ...,\n",
      "        [ 0.0004, -0.0111,  0.0166,  ..., -0.0011,  0.0300,  0.0343],\n",
      "        [-0.0111, -0.0130, -0.0042,  ...,  0.0008, -0.0297, -0.0103],\n",
      "        [-0.0304, -0.0179, -0.0301,  ..., -0.0128,  0.0039,  0.0145]],\n",
      "       requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[-0.0047, -0.0134, -0.0281,  ..., -0.0182,  0.0327,  0.0007],\n",
      "        [-0.0251,  0.0170, -0.0312,  ...,  0.0246,  0.0305,  0.0061],\n",
      "        [-0.0278,  0.0116,  0.0063,  ...,  0.0358, -0.0273,  0.0173],\n",
      "        ...,\n",
      "        [ 0.0026,  0.0101, -0.0099,  ..., -0.0034, -0.0074, -0.0157],\n",
      "        [-0.0055, -0.0121, -0.0329,  ..., -0.0212,  0.0113, -0.0112],\n",
      "        [ 0.0034, -0.0299,  0.0117,  ..., -0.0022, -0.0013,  0.0141]],\n",
      "       requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[-0.0172,  0.0195,  0.0269,  ..., -0.0203, -0.0198,  0.0180],\n",
      "        [ 0.0122, -0.0309,  0.0115,  ...,  0.0098,  0.0152, -0.0328],\n",
      "        [ 0.0349, -0.0214,  0.0128,  ...,  0.0361, -0.0025, -0.0326],\n",
      "        ...,\n",
      "        [-0.0022, -0.0127,  0.0070,  ..., -0.0172, -0.0011,  0.0269],\n",
      "        [-0.0215,  0.0051,  0.0007,  ...,  0.0048,  0.0070,  0.0217],\n",
      "        [ 0.0018,  0.0188, -0.0134,  ...,  0.0334, -0.0121,  0.0058]],\n",
      "       requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[-0.0230, -0.0360, -0.0122,  ...,  0.0049, -0.0234,  0.0020],\n",
      "        [-0.0202, -0.0251,  0.0089,  ...,  0.0089, -0.0183,  0.0079],\n",
      "        [-0.0290, -0.0213,  0.0231,  ..., -0.0207,  0.0136,  0.0332],\n",
      "        ...,\n",
      "        [-0.0264, -0.0278,  0.0160,  ..., -0.0344, -0.0127,  0.0102],\n",
      "        [-0.0143, -0.0326, -0.0331,  ..., -0.0048,  0.0073, -0.0218],\n",
      "        [ 0.0246,  0.0343,  0.0236,  ..., -0.0118,  0.0346, -0.0327]],\n",
      "       requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[-0.0007,  0.0120, -0.0288,  ..., -0.0245, -0.0269,  0.0139],\n",
      "        [ 0.0086,  0.0065,  0.0228,  ..., -0.0058, -0.0199,  0.0028],\n",
      "        [ 0.0342, -0.0344, -0.0213,  ...,  0.0097, -0.0359, -0.0101],\n",
      "        ...,\n",
      "        [-0.0062, -0.0074, -0.0123,  ..., -0.0009, -0.0127,  0.0144],\n",
      "        [ 0.0072,  0.0143,  0.0150,  ...,  0.0331, -0.0185, -0.0351],\n",
      "        [ 0.0122,  0.0124, -0.0162,  ...,  0.0167,  0.0137,  0.0194]],\n",
      "       requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[ 0.0191,  0.0017,  0.0240,  ...,  0.0099,  0.0219,  0.0287],\n",
      "        [-0.0089, -0.0310,  0.0152,  ...,  0.0213, -0.0275, -0.0162],\n",
      "        [-0.0113, -0.0028, -0.0208,  ...,  0.0232,  0.0330,  0.0186],\n",
      "        ...,\n",
      "        [-0.0305,  0.0250, -0.0276,  ..., -0.0136,  0.0256, -0.0078],\n",
      "        [ 0.0226, -0.0301,  0.0239,  ..., -0.0255,  0.0349,  0.0353],\n",
      "        [ 0.0074, -0.0253, -0.0205,  ...,  0.0311,  0.0056, -0.0037]],\n",
      "       requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "for i in range(12):\n",
    "    print(new_model.roberta.encoder.layer[i].attention.self.value.lora_A)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(7.7123, grad_fn=<CopyBackwards>) tensor(3.4013, grad_fn=<CopyBackwards>)\n",
      "tensor(7.8495, grad_fn=<CopyBackwards>) tensor(3.0643, grad_fn=<CopyBackwards>)\n",
      "tensor(7.6633, grad_fn=<CopyBackwards>) tensor(3.0875, grad_fn=<CopyBackwards>)\n",
      "tensor(7.1175, grad_fn=<CopyBackwards>) tensor(2.5886, grad_fn=<CopyBackwards>)\n",
      "tensor(6.9871, grad_fn=<CopyBackwards>) tensor(2.4708, grad_fn=<CopyBackwards>)\n",
      "tensor(6.8683, grad_fn=<CopyBackwards>) tensor(2.4792, grad_fn=<CopyBackwards>)\n",
      "tensor(6.8484, grad_fn=<CopyBackwards>) tensor(2.4745, grad_fn=<CopyBackwards>)\n",
      "tensor(7.1846, grad_fn=<CopyBackwards>) tensor(2.8878, grad_fn=<CopyBackwards>)\n",
      "tensor(6.9876, grad_fn=<CopyBackwards>) tensor(2.8358, grad_fn=<CopyBackwards>)\n",
      "tensor(6.8469, grad_fn=<CopyBackwards>) tensor(2.7624, grad_fn=<CopyBackwards>)\n",
      "tensor(6.6812, grad_fn=<CopyBackwards>) tensor(2.3723, grad_fn=<CopyBackwards>)\n",
      "tensor(6.5843, grad_fn=<CopyBackwards>) tensor(2.1620, grad_fn=<CopyBackwards>)\n"
     ]
    }
   ],
   "source": [
    "for i in range(12):\n",
    "    print( torch.norm(new_model.roberta.encoder.layer[i].attention.self.value.lora_A), torch.norm(new_model.roberta.encoder.layer[i].attention.self.value.lora_B))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([[-0.0113, -0.0016,  0.0347,  ...,  0.0439, -0.0025,  0.0073],\n",
       "        [ 0.0090,  0.0445, -0.0361,  ...,  0.0181, -0.0119,  0.0049],\n",
       "        [ 0.0282,  0.0265,  0.0351,  ...,  0.0181,  0.0378, -0.0296],\n",
       "        ...,\n",
       "        [ 0.0468,  0.0065, -0.0446,  ..., -0.0098,  0.0433, -0.0173],\n",
       "        [-0.0202,  0.0192,  0.0144,  ...,  0.0267, -0.0055,  0.0240],\n",
       "        [-0.0377,  0.0324, -0.0446,  ..., -0.0368, -0.0095,  0.0393]],\n",
       "       requires_grad=True)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_model.roberta.encoder.layer[0].attention.self.query.lora_A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([[ 0.1517, -0.1326, -0.1234,  ...,  0.0705,  0.1163, -0.0122],\n",
       "        [-0.1000,  0.0818,  0.2082,  ..., -0.1151,  0.0634, -0.0582],\n",
       "        [ 0.2597, -0.0216, -0.0885,  ...,  0.0084, -0.0894, -0.0085],\n",
       "        ...,\n",
       "        [-0.1887,  0.0710,  0.0932,  ...,  0.1906,  0.0301, -0.2001],\n",
       "        [-0.0157,  0.0772, -0.0567,  ..., -0.0360,  0.0985, -0.0041],\n",
       "        [ 0.0767, -0.0417,  0.1543,  ...,  0.0336,  0.0307, -0.0174]],\n",
       "       requires_grad=True)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.roberta.encoder.layer[0].attention.self.query.lora_A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.0423,  0.0066, -0.0447,  ..., -0.0113,  0.0029, -0.1085],\n",
       "        [-0.0053, -0.0050, -0.0031,  ..., -0.0049,  0.0114,  0.0038],\n",
       "        [-0.0326, -0.0065,  0.0312,  ..., -0.0037,  0.0191,  0.0202],\n",
       "        ...,\n",
       "        [-0.0352,  0.0125,  0.0243,  ..., -0.0509,  0.0318, -0.0567],\n",
       "        [-0.0132,  0.0274, -0.0442,  ...,  0.0136, -0.0051, -0.0123],\n",
       "        [-0.0514,  0.0142, -0.0271,  ...,  0.0021,  0.0060,  0.0020]])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_model.roberta.encoder.layer[0].attention.self.query.weight.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.0423,  0.0066, -0.0447,  ..., -0.0113,  0.0029, -0.1085],\n",
       "        [-0.0053, -0.0050, -0.0031,  ..., -0.0049,  0.0114,  0.0038],\n",
       "        [-0.0326, -0.0065,  0.0312,  ..., -0.0037,  0.0191,  0.0202],\n",
       "        ...,\n",
       "        [-0.0352,  0.0125,  0.0243,  ..., -0.0509,  0.0318, -0.0567],\n",
       "        [-0.0132,  0.0274, -0.0442,  ...,  0.0136, -0.0051, -0.0123],\n",
       "        [-0.0514,  0.0142, -0.0271,  ...,  0.0021,  0.0060,  0.0020]])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "W_init_by_loraAB(new_model, model)\n",
    "new_model.roberta.encoder.layer[0].attention.self.query.weight.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.0423, -0.0053, -0.0326,  ..., -0.0352, -0.0132, -0.0514],\n",
       "        [ 0.0066, -0.0050, -0.0065,  ...,  0.0125,  0.0274,  0.0142],\n",
       "        [-0.0447, -0.0031,  0.0312,  ...,  0.0243, -0.0442, -0.0271],\n",
       "        ...,\n",
       "        [-0.0113, -0.0049, -0.0037,  ..., -0.0509,  0.0136,  0.0021],\n",
       "        [ 0.0029,  0.0114,  0.0191,  ...,  0.0318, -0.0051,  0.0060],\n",
       "        [-0.1085,  0.0038,  0.0202,  ..., -0.0567, -0.0123,  0.0020]],\n",
       "       grad_fn=<MmBackward>)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.roberta.encoder.layer[0].attention.self.query.lora_A.T @ model.roberta.encoder.layer[0].attention.self.query.lora_B.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_model = copy.deepcopy(model)\n",
    "insert_lora(model, 768, model_args.lora_r, model_args.lora_alpha)\n",
    "# print(model.roberta.encoder.layer[0].attention.self.query.bias)\n",
    "W_weight_copy(model, new_model)\n",
    "# print(model.roberta.encoder.layer[0].attention.self.query.bias)\n",
    "trainable_params = []\n",
    "# if model_args.apply_lora:\n",
    "#     if model_args.lora_path is not None:\n",
    "#         lora_state_dict = torch.load(model_args.lora_path)\n",
    "#         logger.info(f\"Apply LoRA state dict from {model_args.lora_path}.\")\n",
    "#         logger.info(lora_state_dict.keys())\n",
    "#         model.load_state_dict(lora_state_dict, strict=False)\n",
    "#     model.load_state_dict(torch.load(model_args.lora_path), strict=False)\n",
    "# trainable_params.append(\"lora\")\n",
    "print(\"BEFORE INIT LORA\")\n",
    "print(\n",
    "    model.roberta.encoder.layer[0].attention.self.query.lora_A,\n",
    "    model.roberta.encoder.layer[0].attention.self.query.lora_B,\n",
    ")\n",
    "# dW_init_by_SVD(model, new_model, model_args.lora_r)\n",
    "w_q_encoder_loraA_weights = []\n",
    "w_q_encoder_loraB_weights = []\n",
    "w_v_encoder_loraA_weights = []\n",
    "w_v_encoder_loraB_weights = []\n",
    "len_of_layers = 12  # len(SVD_model.roberta.encoder.layer)\n",
    "with torch.no_grad():\n",
    "    for i in range(len_of_layers):\n",
    "        encoder_q_original_weight = new_model.roberta.encoder.layer[i].attention.self.query.weight.data.T\n",
    "        encoder_v_original_weight = new_model.roberta.encoder.layer[i].attention.self.value.weight.data.T\n",
    "        encoder_q_u, encoder_q_s, encoder_q_v = torch.linalg.svd(encoder_q_original_weight)\n",
    "        encoder_v_u, encoder_v_s, encoder_v_v = torch.linalg.svd(encoder_v_original_weight)\n",
    "        approx_rank = model_args.lora_r\n",
    "        # w_q_encoder\n",
    "        # torch.Size([768, rank])\n",
    "        w_q_encoder_loraA_weights.append(\n",
    "            encoder_q_u[:, :approx_rank] @ torch.diag(encoder_q_s[:approx_rank]).sqrt()\n",
    "        )\n",
    "        # torch.Size([rank, 768])\n",
    "        w_q_encoder_loraB_weights.append(\n",
    "            torch.diag(encoder_q_s[:approx_rank]).sqrt() @ encoder_q_v[:approx_rank, :]\n",
    "        )\n",
    "        # w_v_encoder\n",
    "        w_v_encoder_loraA_weights.append(\n",
    "            encoder_v_u[:, :approx_rank] @ torch.diag(encoder_v_s[:approx_rank]).sqrt()\n",
    "        )\n",
    "        w_v_encoder_loraB_weights.append(\n",
    "            torch.diag(encoder_v_s[:approx_rank]).sqrt() @ encoder_v_v[:approx_rank, :]\n",
    "        )\n",
    "og_weight = new_model.roberta.encoder.layer[0].attention.self.query.weight.data\n",
    "with torch.no_grad():\n",
    "    for i in range(len_of_layers):\n",
    "        model.roberta.encoder.layer[i].attention.self.query.lora_A.copy_(w_q_encoder_loraA_weights[i].T)\n",
    "        model.roberta.encoder.layer[i].attention.self.query.lora_B.copy_(w_q_encoder_loraB_weights[i].T)\n",
    "        model.roberta.encoder.layer[i].attention.self.value.lora_A.copy_(w_v_encoder_loraA_weights[i].T)\n",
    "        model.roberta.encoder.layer[i].attention.self.value.lora_B.copy_(w_v_encoder_loraB_weights[i].T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "InvalidVersion",
     "evalue": "Invalid version: '0.10.1,<0.11'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInvalidVersion\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_2634722/129635456.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mdatasets\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mload_dataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mload_metric\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mtransformers\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m from transformers import (\n\u001b[1;32m     10\u001b[0m     \u001b[0mAutoConfig\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/bumjun/low_rank/examples/NLU/transformers/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     41\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m \u001b[0;31m# Check the dependencies satisfy the minimal versions required.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 43\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdependency_versions_check\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     44\u001b[0m from .file_utils import (\n\u001b[1;32m     45\u001b[0m     \u001b[0m_BaseLazyModule\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/bumjun/low_rank/examples/NLU/transformers/dependency_versions_check.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     39\u001b[0m                 \u001b[0;32mcontinue\u001b[0m  \u001b[0;31m# not required, check version only if installed\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 41\u001b[0;31m         \u001b[0mrequire_version_core\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdeps\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpkg\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     42\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"can't find {pkg} in {deps.keys()}, check dependency_versions_table.py\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/bumjun/low_rank/examples/NLU/transformers/utils/versions.py\u001b[0m in \u001b[0;36mrequire_version_core\u001b[0;34m(requirement)\u001b[0m\n\u001b[1;32m     92\u001b[0m     \u001b[0;34m\"\"\" require_version wrapper which emits a core-specific hint on failure \"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m     \u001b[0mhint\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"Try: pip install transformers -U or pip install -e '.[dev]' if you're working with git master\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 94\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mrequire_version\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequirement\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     95\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     96\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/bumjun/low_rank/examples/NLU/transformers/utils/versions.py\u001b[0m in \u001b[0;36mrequire_version\u001b[0;34m(requirement, hint)\u001b[0m\n\u001b[1;32m     83\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     84\u001b[0m     \u001b[0;31m# check that the right version is installed if version number was provided\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 85\u001b[0;31m     \u001b[0;32mif\u001b[0m \u001b[0mwant_ver\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mop\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mversion\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgot_ver\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mversion\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwant_ver\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     86\u001b[0m         raise pkg_resources.VersionConflict(\n\u001b[1;32m     87\u001b[0m             \u001b[0;34mf\"{requirement} is required for a normal functioning of this module, but found {pkg}=={got_ver}.{hint}\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/NLU_without_transformers/lib/python3.7/site-packages/packaging/version.py\u001b[0m in \u001b[0;36mparse\u001b[0;34m(version)\u001b[0m\n\u001b[1;32m     52\u001b[0m     \u001b[0;34m:\u001b[0m\u001b[0mraises\u001b[0m \u001b[0mInvalidVersion\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mWhen\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mversion\u001b[0m \u001b[0mstring\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0ma\u001b[0m \u001b[0mvalid\u001b[0m \u001b[0mversion\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m     \"\"\"\n\u001b[0;32m---> 54\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mVersion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mversion\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     55\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/NLU_without_transformers/lib/python3.7/site-packages/packaging/version.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, version)\u001b[0m\n\u001b[1;32m    198\u001b[0m         \u001b[0mmatch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_regex\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msearch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mversion\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    199\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mmatch\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 200\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mInvalidVersion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Invalid version: '{version}'\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    201\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    202\u001b[0m         \u001b[0;31m# Store the parsed out pieces of the version\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mInvalidVersion\u001b[0m: Invalid version: '0.10.1,<0.11'"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from dataclasses import dataclass, field\n",
    "from typing import Optional\n",
    "\n",
    "import numpy as np\n",
    "from datasets import load_dataset, load_metric\n",
    "\n",
    "# import transformers\n",
    "# from transformers import (\n",
    "#     AutoConfig,\n",
    "#     AutoModelForSequenceClassification, \n",
    "#     AutoTokenizer,\n",
    "#     DataCollatorWithPadding,\n",
    "#     EvalPrediction,\n",
    "#     HfArgumentParser,\n",
    "#     PretrainedConfig,\n",
    "#     Trainer,\n",
    "#     TrainingArguments,\n",
    "#     default_data_collator,\n",
    "#     set_seed,\n",
    "#     EarlyStoppingCallback,\n",
    "#     integrations,\n",
    "# )\n",
    "# from transformers.trainer_utils import get_last_checkpoint, is_main_process\n",
    "# from transformers.utils import check_min_version\n",
    "\n",
    "import wandb\n",
    "from wandb import AlertLevel\n",
    "import loralib as lora\n",
    "import copy\n",
    "import torch.nn as nn\n",
    "import math\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_lora_to_roberta(model, dim, rank, lora_alpha):\n",
    "    len_of_layers = len(model.roberta.encoder.layer)  # len(model.roberta.encoder)\n",
    "    for i in range(len_of_layers):\n",
    "        model.roberta.encoder.layer[i].attention.self.query = copy.deepcopy(\n",
    "            lora.Linear(dim, dim, r=rank, lora_alpha=lora_alpha, merge_weights=False)\n",
    "        )\n",
    "        model.roberta.encoder.layer[i].attention.self.value = copy.deepcopy(\n",
    "            lora.Linear(dim, dim, r=rank, lora_alpha=lora_alpha, merge_weights=False)\n",
    "        )\n",
    "\n",
    "\n",
    "def copy_weights(new_model, W_model):\n",
    "    \"\"\"\n",
    "    W_model의 W weight를 new_model의 W weight로 복사\n",
    "    \"\"\"\n",
    "    len_of_layers = 12\n",
    "    q_encoder_weight_list = []\n",
    "    v_encoder_weight_list = []\n",
    "    q_encoder_bias_list = []\n",
    "    v_encoder_bias_list = []\n",
    "\n",
    "    for i in range(len_of_layers):\n",
    "        q_encoder_new_weight = W_model.roberta.encoder.layer[i].attention.self.query.weight.data\n",
    "        q_encoder_weight_list.append(q_encoder_new_weight)\n",
    "        q_encoder_new_bias = W_model.roberta.encoder.layer[i].attention.self.query.bias.data\n",
    "        q_encoder_bias_list.append(q_encoder_new_bias)\n",
    "\n",
    "        v_encoder_new_weight = W_model.roberta.encoder.layer[i].attention.self.value.weight.data\n",
    "        v_encoder_weight_list.append(v_encoder_new_weight)\n",
    "        v_encoder_new_bias = W_model.roberta.encoder.layer[i].attention.self.value.bias.data\n",
    "        v_encoder_bias_list.append(v_encoder_new_bias)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for i in range(len_of_layers):\n",
    "            new_model.roberta.encoder.layer[i].attention.self.query.weight.data.copy_(q_encoder_weight_list[i])\n",
    "            new_model.roberta.encoder.layer[i].attention.self.value.weight.data.copy_(v_encoder_weight_list[i])\n",
    "            new_model.roberta.encoder.layer[i].attention.self.query.bias.data.copy_(q_encoder_bias_list[i])\n",
    "            new_model.roberta.encoder.layer[i].attention.self.value.bias.data.copy_(v_encoder_bias_list[i])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = copy.deepcopy(\n",
    "        AutoModelForSequenceClassification.from_pretrained(\n",
    "            \"roberta-base\",\n",
    "        )\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "add_lora_to_roberta(model, 768, 8.16)\n",
    "copy_weights(model, new_model)\n",
    "model.load_state_dict(torch.load(\"/home/lab/bumjun/low_rank/examples/NLU/LoRA_ckpt_from_repo/roberta_base_lora_cola.bin\"), strict=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "NLU",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
