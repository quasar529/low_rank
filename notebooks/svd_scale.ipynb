{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lab/bumjun/qlora/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM, BitsAndBytesConfig\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "import os\n",
    "import random\n",
    "import sys\n",
    "import transformers\n",
    "\n",
    "from transformers import (\n",
    "    AutoTokenizer,\n",
    "    AutoModelForSequenceClassification,\n",
    "    BertTokenizer,\n",
    "    BertForSequenceClassification,\n",
    "    RobertaTokenizer,\n",
    "    RobertaForSequenceClassification,\n",
    "    EvalPrediction,\n",
    "    PretrainedConfig,\n",
    "    Trainer,\n",
    "    TrainingArguments,\n",
    ")\n",
    "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
    "import torch\n",
    "import wandb\n",
    "import copy\n",
    "import torch.nn as nn\n",
    "import math\n",
    "from tqdm import tqdm, trange\n",
    "from sklearn.metrics import f1_score\n",
    "from transformers import EarlyStoppingCallback\n",
    "\n",
    "# import loralib as lora\n",
    "from peft import (\n",
    "    get_peft_config,\n",
    "    get_peft_model,\n",
    "    get_peft_model_state_dict,\n",
    "    set_peft_model_state_dict,\n",
    "    LoraConfig,\n",
    "    PeftType,\n",
    "    PrefixTuningConfig,\n",
    "    PromptEncoderConfig,\n",
    "    prepare_model_for_kbit_training,\n",
    ")\n",
    "from collections import Counter\n",
    "import glob\n",
    "import time\n",
    "import datasets\n",
    "import loralib as lora"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def seed_everything(seed: int = 42):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    os.environ[\"PYTHONHASHSEED\"] = str(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)  # type: ignore\n",
    "    torch.backends.cudnn.deterministic = True  # type: ignore\n",
    "    torch.backends.cudnn.benchmark = False  # type: ignore\n",
    "    torch.use_deterministic_algorithms(True)\n",
    "\n",
    "\n",
    "seed_everything(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_trainable_parameters(model):\n",
    "    \"\"\"\n",
    "    Prints the number of trainable parameters in the model.\n",
    "    \"\"\"\n",
    "    trainable_params = 0\n",
    "    all_param = 0\n",
    "    for _, param in model.named_parameters():\n",
    "        all_param += param.numel()\n",
    "        if param.requires_grad:\n",
    "            trainable_params += param.numel()\n",
    "    print(\n",
    "        f\"trainable params: {trainable_params} || all params: {all_param} || trainable%: {100 * trainable_params / all_param}\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recon_error(original_weight, approx_weight):\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    return torch.linalg.norm(original_weight.to(device) - approx_weight.to(device), \"fro\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DebertaV2ForSequenceClassification were not initialized from the model checkpoint at microsoft/deberta-v2-xxlarge and are newly initialized: ['pooler.dense.bias', 'classifier.weight', 'pooler.dense.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainable params: 1182722 || all params: 1568096260 || trainable%: 0.075424068672927\n"
     ]
    }
   ],
   "source": [
    "model_id = \"microsoft/deberta-v2-xxlarge\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_id, use_fast=False)\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "model = AutoModelForSequenceClassification.from_pretrained(model_id, num_labels=2)\n",
    "config = LoraConfig(r=4, lora_alpha=8, target_modules=[\"query_proj\", \"value_proj\"], task_type=\"SEQ_CLS\")\n",
    "model = get_peft_model(model, config)\n",
    "print_trainable_parameters(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ModuleDict(\n",
       "  (default): Linear(in_features=1536, out_features=4, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.base_model.model.deberta.encoder.layer[0].attention.self.query_proj.lora_A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "lora_A = model.base_model.model.deberta.encoder.layer[0].attention.self.query_proj.lora_A.default"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[-0.0037, -0.0002, -0.0136, -0.0114],\n",
       "         [-0.0118, -0.0211, -0.0214,  0.0007],\n",
       "         [-0.0003, -0.0050, -0.0224,  0.0027],\n",
       "         ...,\n",
       "         [-0.0077, -0.0008, -0.0219, -0.0033],\n",
       "         [-0.0131, -0.0245, -0.0117,  0.0163],\n",
       "         [-0.0070, -0.0254, -0.0136,  0.0109]], grad_fn=<TransposeBackward0>),\n",
       " torch.Size([1536, 4]))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lora_A = model.base_model.model.deberta.encoder.layer[0].attention.self.query_proj.lora_A.default.weight.transpose(0,1)\n",
    "lora_A, lora_A.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1.1551, grad_fn=<LinalgVectorNormBackward0>)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lora_A_norm = torch.norm(lora_A)\n",
    "lora_A_norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Parameter containing:\n",
       " tensor([[0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0.],\n",
       "         ...,\n",
       "         [0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0.]], requires_grad=True),\n",
       " torch.Size([1536, 4]),\n",
       " tensor(0., grad_fn=<LinalgVectorNormBackward0>))"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lora_B = model.base_model.model.deberta.encoder.layer[0].attention.self.query_proj.lora_B.default\n",
    "lora_B.weight, lora_B.weight.shape, torch.norm(lora_B.weight)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### query SVD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[ 0.0712,  0.0211, -0.0921,  ..., -0.0111,  0.0479,  0.0247],\n",
       "         [-0.0326,  0.0605, -0.1219,  ...,  0.0445, -0.0812, -0.0392],\n",
       "         [ 0.0090,  0.0134,  0.0068,  ...,  0.0231, -0.0630,  0.0749],\n",
       "         ...,\n",
       "         [ 0.0343,  0.0161, -0.0853,  ..., -0.0633, -0.0336,  0.0295],\n",
       "         [ 0.1448, -0.0611, -0.0674,  ..., -0.0059,  0.0809, -0.0400],\n",
       "         [-0.0075,  0.0023, -0.0746,  ..., -0.0186, -0.0690, -0.0521]]),\n",
       " torch.Size([1536, 1536]),\n",
       " tensor(88.6837))"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q_original_weight = model.deberta.encoder.layer[0].attention.self.query_proj.weight.data.T\n",
    "q_original_weight, q_original_weight.shape, torch.norm(q_original_weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[ 0.2236, -0.0308,  0.0417,  0.0626],\n",
       "         [ 0.1297, -0.1951,  0.0092,  0.0092],\n",
       "         [ 0.0193,  0.0311, -0.0281, -0.0416],\n",
       "         ...,\n",
       "         [-0.0423,  0.0485, -0.1052, -0.0067],\n",
       "         [ 0.0470, -0.0709, -0.0392,  0.0321],\n",
       "         [-0.0780,  0.0835, -0.0392, -0.0022]]),\n",
       " torch.Size([1536, 4]),\n",
       " tensor(5.8884))"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q_proj_u, q_proj_s, q_proj_v = torch.linalg.svd(q_original_weight)\n",
    "new_lora_A = q_proj_u[:, :4] @ torch.diag(q_proj_s[:4]).sqrt()\n",
    "new_lora_A, new_lora_A.shape, torch.norm(new_lora_A)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.0002, device='cuda:0')"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q_reconstructed = q_proj_u @ torch.diag(q_proj_s) @ q_proj_v\n",
    "recon_error(q_original_weight, q_reconstructed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(86.9137, device='cuda:0')"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q_reconstructed = q_proj_u[:, :4] @ torch.diag(q_proj_s[:4]) @ q_proj_v[:4, :]\n",
    "recon_error(q_original_weight, q_reconstructed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.0683, -0.0099,  0.0151,  0.0244],\n",
       "        [ 0.0396, -0.0627,  0.0033,  0.0036],\n",
       "        [ 0.0059,  0.0100, -0.0102, -0.0162],\n",
       "        ...,\n",
       "        [-0.0129,  0.0156, -0.0380, -0.0026],\n",
       "        [ 0.0144, -0.0228, -0.0142,  0.0125],\n",
       "        [-0.0238,  0.0268, -0.0142, -0.0009]])"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q_proj_u[:, :4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1536, 4])"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q_proj_u[:, :4].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([10.7285,  9.6862,  7.6498,  6.6093])"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q_proj_s[:4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[10.7285,  0.0000,  0.0000,  0.0000],\n",
       "         [ 0.0000,  9.6862,  0.0000,  0.0000],\n",
       "         [ 0.0000,  0.0000,  7.6498,  0.0000],\n",
       "         [ 0.0000,  0.0000,  0.0000,  6.6093]]),\n",
       " torch.Size([4, 4]))"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.diag(q_proj_s[:4]), torch.diag(q_proj_s[:4]).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([ 0.2236,  0.1297,  0.0193,  ..., -0.0423,  0.0470, -0.0780]),\n",
       " torch.Size([1536]),\n",
       " tensor(3.2754))"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_lora_A[:,0],new_lora_A[:,0].shape, torch.norm(new_lora_A[:,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([-0.0037, -0.0118, -0.0003,  ..., -0.0077, -0.0131, -0.0070],\n",
       "        grad_fn=<SelectBackward0>),\n",
       " torch.Size([1536]),\n",
       " tensor(0.5674, grad_fn=<LinalgVectorNormBackward0>))"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lora_A[:, 0], lora_A[:, 0].shape, torch.norm(lora_A[:, 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0th col torch.Size([1536]) tensor(0.5674, grad_fn=<LinalgVectorNormBackward0>)\n",
      "1th col torch.Size([1536]) tensor(0.5873, grad_fn=<LinalgVectorNormBackward0>)\n",
      "2th col torch.Size([1536]) tensor(0.5792, grad_fn=<LinalgVectorNormBackward0>)\n",
      "3th col torch.Size([1536]) tensor(0.5762, grad_fn=<LinalgVectorNormBackward0>)\n"
     ]
    }
   ],
   "source": [
    "for i in range(4):\n",
    "    lora_A = model.base_model.model.deberta.encoder.layer[0].attention.self.query_proj.lora_A.default.weight.T\n",
    "    print(f\"{i}th col\",lora_A[:, i].shape, torch.norm(lora_A[:, i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5, 6, 7, 8, 9]\n"
     ]
    }
   ],
   "source": [
    "x = [0,1,2,3,4]\n",
    "for i in range(5):\n",
    "    new_x = 5+i\n",
    "    x[i]= new_x\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len_of_layers = len(model.deberta.encoder.layer)\n",
    "q_new_lora_A_list = []\n",
    "v_new_lora_A_list = []\n",
    "\n",
    "q_new_lora_B_list = []\n",
    "v_new_lora_B_list = []\n",
    "\n",
    "approx_rank = 4\n",
    "for layer_idx in range(len_of_layers):\n",
    "    q_original_weight = model.deberta.encoder.layer[layer_idx].attention.self.query_proj.weight.data.T\n",
    "    v_original_weight = model.deberta.encoder.layer[layer_idx].attention.self.value_proj.weight.data.T\n",
    "\n",
    "    q_og_lora_A = model.base_model.model.deberta.encoder.layer[\n",
    "        layer_idx\n",
    "    ].attention.self.query_proj.lora_A.default.weight.T\n",
    "    v_og_lora_A = model.base_model.model.deberta.encoder.layer[\n",
    "        layer_idx\n",
    "    ].attention.self.value_proj.lora_A.default.weight.T\n",
    "\n",
    "    q_proj_u, q_proj_s, q_proj_v = torch.linalg.svd(q_original_weight)\n",
    "    q_new_lora_A = q_proj_u[:, :approx_rank] @ torch.diag(q_proj_s[:approx_rank]).sqrt()\n",
    "    q_new_lora_B = torch.diag(q_proj_s[:approx_rank]).sqrt() @ q_proj_v[:approx_rank, :]\n",
    "    \n",
    "    v_proj_u, v_proj_s, v_proj_v = torch.linalg.svd(v_original_weight)\n",
    "    v_new_lora_A = v_proj_u[:, :approx_rank] @ torch.diag(v_proj_s[:approx_rank]).sqrt()\n",
    "    v_new_lora_B = torch.diag(v_proj_s[:approx_rank]).sqrt() @ v_proj_v[:approx_rank, :]\n",
    "    \n",
    "    q_new_lora_B_list.append(q_new_lora_B)\n",
    "    v_new_lora_B_list.append(v_new_lora_B)\n",
    "\n",
    "    for i in range(4):\n",
    "        print(f\"Before Scale, q {i}th col Norm\", torch.norm(q_new_lora_A[:, i]))\n",
    "\n",
    "        q_og_lora_A_icol_norm = torch.norm(q_og_lora_A[:, i])\n",
    "        q_new_lora_A_icol_norm = torch.norm(q_new_lora_A[:, i])\n",
    "\n",
    "        q_scale = q_og_lora_A_icol_norm / q_new_lora_A_icol_norm\n",
    "\n",
    "        q_new_lora_A[:, i] = q_new_lora_A[:, i] * q_scale\n",
    "\n",
    "        print(f\"After Scale, q {i}th col Norm\", torch.norm(q_new_lora_A[:, i]))\n",
    "        print(\"####################\")\n",
    "\n",
    "        print(f\"Before Scale, v {i}th col Norm\", torch.norm(v_new_lora_A[:, i]))\n",
    "\n",
    "        v_og_lora_A_icol_norm = torch.norm(v_og_lora_A[:, i])\n",
    "        v_new_lora_A_icol_norm = torch.norm(v_new_lora_A[:, i])\n",
    "\n",
    "        v_scale = v_og_lora_A_icol_norm / v_new_lora_A_icol_norm\n",
    "\n",
    "        v_new_lora_A[:, i] = v_new_lora_A[:, i] * v_scale\n",
    "\n",
    "        print(f\"After Scale, v {i}th col Norm\", torch.norm(v_new_lora_A[:, i]))\n",
    "        print(\"####################\")\n",
    "\n",
    "    q_new_lora_A_list.append(q_new_lora_A)\n",
    "    v_new_lora_A_list.append(v_new_lora_A)\n",
    "\n",
    "    model.base_model.model.deberta.encoder.layer[layer_idx].attention.self.query_proj.lora_A.default.weight.data = (\n",
    "        q_new_lora_A_list[layer_idx].transpose(0, 1).contiguous()\n",
    "    )\n",
    "    model.base_model.model.deberta.encoder.layer[layer_idx].attention.self.value_proj.lora_A.default.weight.data = (\n",
    "        v_new_lora_A_list[layer_idx].transpose(0, 1).contiguous()\n",
    "    )\n",
    "    \n",
    "    model.base_model.model.deberta.encoder.layer[layer_idx].attention.self.query_proj.lora_B.default.weight.data = (\n",
    "        q_new_lora_B_list[layer_idx].transpose(0, 1).contiguous()\n",
    "    )\n",
    "    model.base_model.model.deberta.encoder.layer[layer_idx].attention.self.value_proj.lora_B.default.weight.data = (\n",
    "        v_new_lora_B_list[layer_idx].transpose(0, 1).contiguous()\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before Scale, q 0th col Norm tensor(3.2754)\n",
      "After Scale, q 0th col Norm tensor(0.5823, grad_fn=<LinalgVectorNormBackward0>)\n",
      "####################\n",
      "Before Scale, v 0th col Norm tensor(2.0830)\n",
      "After Scale, v 0th col Norm tensor(0.5780, grad_fn=<LinalgVectorNormBackward0>)\n",
      "####################\n",
      "Before Scale, q 1th col Norm tensor(3.1123, grad_fn=<LinalgVectorNormBackward0>)\n",
      "After Scale, q 1th col Norm tensor(0.5741, grad_fn=<LinalgVectorNormBackward0>)\n",
      "####################\n",
      "Before Scale, v 1th col Norm tensor(1.9221, grad_fn=<LinalgVectorNormBackward0>)\n",
      "After Scale, v 1th col Norm tensor(0.5697, grad_fn=<LinalgVectorNormBackward0>)\n",
      "####################\n",
      "Before Scale, q 2th col Norm tensor(2.7658, grad_fn=<LinalgVectorNormBackward0>)\n",
      "After Scale, q 2th col Norm tensor(0.5851, grad_fn=<LinalgVectorNormBackward0>)\n",
      "####################\n",
      "Before Scale, v 2th col Norm tensor(1.9160, grad_fn=<LinalgVectorNormBackward0>)\n",
      "After Scale, v 2th col Norm tensor(0.5672, grad_fn=<LinalgVectorNormBackward0>)\n",
      "####################\n",
      "Before Scale, q 3th col Norm tensor(2.5709, grad_fn=<LinalgVectorNormBackward0>)\n",
      "After Scale, q 3th col Norm tensor(0.5755, grad_fn=<LinalgVectorNormBackward0>)\n",
      "####################\n",
      "Before Scale, v 3th col Norm tensor(1.8722, grad_fn=<LinalgVectorNormBackward0>)\n",
      "After Scale, v 3th col Norm tensor(0.5772, grad_fn=<LinalgVectorNormBackward0>)\n",
      "####################\n",
      "Before Scale, q 0th col Norm tensor(2.7274)\n",
      "After Scale, q 0th col Norm tensor(0.5824, grad_fn=<LinalgVectorNormBackward0>)\n",
      "####################\n",
      "Before Scale, v 0th col Norm tensor(2.0011)\n",
      "After Scale, v 0th col Norm tensor(0.5817, grad_fn=<LinalgVectorNormBackward0>)\n",
      "####################\n",
      "Before Scale, q 1th col Norm tensor(2.3932, grad_fn=<LinalgVectorNormBackward0>)\n",
      "After Scale, q 1th col Norm tensor(0.5884, grad_fn=<LinalgVectorNormBackward0>)\n",
      "####################\n",
      "Before Scale, v 1th col Norm tensor(1.9277, grad_fn=<LinalgVectorNormBackward0>)\n",
      "After Scale, v 1th col Norm tensor(0.5723, grad_fn=<LinalgVectorNormBackward0>)\n",
      "####################\n",
      "Before Scale, q 2th col Norm tensor(2.3170, grad_fn=<LinalgVectorNormBackward0>)\n",
      "After Scale, q 2th col Norm tensor(0.5767, grad_fn=<LinalgVectorNormBackward0>)\n",
      "####################\n",
      "Before Scale, v 2th col Norm tensor(1.8841, grad_fn=<LinalgVectorNormBackward0>)\n",
      "After Scale, v 2th col Norm tensor(0.5945, grad_fn=<LinalgVectorNormBackward0>)\n",
      "####################\n",
      "Before Scale, q 3th col Norm tensor(2.2348, grad_fn=<LinalgVectorNormBackward0>)\n",
      "After Scale, q 3th col Norm tensor(0.5835, grad_fn=<LinalgVectorNormBackward0>)\n",
      "####################\n",
      "Before Scale, v 3th col Norm tensor(1.8331, grad_fn=<LinalgVectorNormBackward0>)\n",
      "After Scale, v 3th col Norm tensor(0.5784, grad_fn=<LinalgVectorNormBackward0>)\n",
      "####################\n",
      "Before Scale, q 0th col Norm tensor(2.9403)\n",
      "After Scale, q 0th col Norm tensor(0.5832, grad_fn=<LinalgVectorNormBackward0>)\n",
      "####################\n",
      "Before Scale, v 0th col Norm tensor(2.0408)\n",
      "After Scale, v 0th col Norm tensor(0.5703, grad_fn=<LinalgVectorNormBackward0>)\n",
      "####################\n",
      "Before Scale, q 1th col Norm tensor(2.4288, grad_fn=<LinalgVectorNormBackward0>)\n",
      "After Scale, q 1th col Norm tensor(0.5786, grad_fn=<LinalgVectorNormBackward0>)\n",
      "####################\n",
      "Before Scale, v 1th col Norm tensor(2.0072, grad_fn=<LinalgVectorNormBackward0>)\n",
      "After Scale, v 1th col Norm tensor(0.5734, grad_fn=<LinalgVectorNormBackward0>)\n",
      "####################\n",
      "Before Scale, q 2th col Norm tensor(2.3038, grad_fn=<LinalgVectorNormBackward0>)\n",
      "After Scale, q 2th col Norm tensor(0.5741, grad_fn=<LinalgVectorNormBackward0>)\n",
      "####################\n",
      "Before Scale, v 2th col Norm tensor(1.9679, grad_fn=<LinalgVectorNormBackward0>)\n",
      "After Scale, v 2th col Norm tensor(0.5844, grad_fn=<LinalgVectorNormBackward0>)\n",
      "####################\n",
      "Before Scale, q 3th col Norm tensor(2.2439, grad_fn=<LinalgVectorNormBackward0>)\n",
      "After Scale, q 3th col Norm tensor(0.5794, grad_fn=<LinalgVectorNormBackward0>)\n",
      "####################\n",
      "Before Scale, v 3th col Norm tensor(1.9358, grad_fn=<LinalgVectorNormBackward0>)\n",
      "After Scale, v 3th col Norm tensor(0.5717, grad_fn=<LinalgVectorNormBackward0>)\n",
      "####################\n",
      "Before Scale, q 0th col Norm tensor(3.0741)\n",
      "After Scale, q 0th col Norm tensor(0.5732, grad_fn=<LinalgVectorNormBackward0>)\n",
      "####################\n",
      "Before Scale, v 0th col Norm tensor(2.0850)\n",
      "After Scale, v 0th col Norm tensor(0.5960, grad_fn=<LinalgVectorNormBackward0>)\n",
      "####################\n",
      "Before Scale, q 1th col Norm tensor(2.4699, grad_fn=<LinalgVectorNormBackward0>)\n",
      "After Scale, q 1th col Norm tensor(0.5830, grad_fn=<LinalgVectorNormBackward0>)\n",
      "####################\n",
      "Before Scale, v 1th col Norm tensor(2.0752, grad_fn=<LinalgVectorNormBackward0>)\n",
      "After Scale, v 1th col Norm tensor(0.5847, grad_fn=<LinalgVectorNormBackward0>)\n",
      "####################\n",
      "Before Scale, q 2th col Norm tensor(2.3309, grad_fn=<LinalgVectorNormBackward0>)\n",
      "After Scale, q 2th col Norm tensor(0.5682, grad_fn=<LinalgVectorNormBackward0>)\n",
      "####################\n",
      "Before Scale, v 2th col Norm tensor(2.0130, grad_fn=<LinalgVectorNormBackward0>)\n",
      "After Scale, v 2th col Norm tensor(0.5750, grad_fn=<LinalgVectorNormBackward0>)\n",
      "####################\n",
      "Before Scale, q 3th col Norm tensor(2.3086, grad_fn=<LinalgVectorNormBackward0>)\n",
      "After Scale, q 3th col Norm tensor(0.5776, grad_fn=<LinalgVectorNormBackward0>)\n",
      "####################\n",
      "Before Scale, v 3th col Norm tensor(2.0107, grad_fn=<LinalgVectorNormBackward0>)\n",
      "After Scale, v 3th col Norm tensor(0.5696, grad_fn=<LinalgVectorNormBackward0>)\n",
      "####################\n",
      "Before Scale, q 0th col Norm tensor(2.8918)\n",
      "After Scale, q 0th col Norm tensor(0.5765, grad_fn=<LinalgVectorNormBackward0>)\n",
      "####################\n",
      "Before Scale, v 0th col Norm tensor(1.9788)\n",
      "After Scale, v 0th col Norm tensor(0.5792, grad_fn=<LinalgVectorNormBackward0>)\n",
      "####################\n",
      "Before Scale, q 1th col Norm tensor(2.4810, grad_fn=<LinalgVectorNormBackward0>)\n",
      "After Scale, q 1th col Norm tensor(0.5720, grad_fn=<LinalgVectorNormBackward0>)\n",
      "####################\n",
      "Before Scale, v 1th col Norm tensor(1.9444, grad_fn=<LinalgVectorNormBackward0>)\n",
      "After Scale, v 1th col Norm tensor(0.5749, grad_fn=<LinalgVectorNormBackward0>)\n",
      "####################\n",
      "Before Scale, q 2th col Norm tensor(2.3424, grad_fn=<LinalgVectorNormBackward0>)\n",
      "After Scale, q 2th col Norm tensor(0.5731, grad_fn=<LinalgVectorNormBackward0>)\n",
      "####################\n",
      "Before Scale, v 2th col Norm tensor(1.9122, grad_fn=<LinalgVectorNormBackward0>)\n",
      "After Scale, v 2th col Norm tensor(0.5749, grad_fn=<LinalgVectorNormBackward0>)\n",
      "####################\n",
      "Before Scale, q 3th col Norm tensor(2.3075, grad_fn=<LinalgVectorNormBackward0>)\n",
      "After Scale, q 3th col Norm tensor(0.5948, grad_fn=<LinalgVectorNormBackward0>)\n",
      "####################\n",
      "Before Scale, v 3th col Norm tensor(1.9023, grad_fn=<LinalgVectorNormBackward0>)\n",
      "After Scale, v 3th col Norm tensor(0.5810, grad_fn=<LinalgVectorNormBackward0>)\n",
      "####################\n",
      "Before Scale, q 0th col Norm tensor(3.0407)\n",
      "After Scale, q 0th col Norm tensor(0.5750, grad_fn=<LinalgVectorNormBackward0>)\n",
      "####################\n",
      "Before Scale, v 0th col Norm tensor(2.0163)\n",
      "After Scale, v 0th col Norm tensor(0.5790, grad_fn=<LinalgVectorNormBackward0>)\n",
      "####################\n",
      "Before Scale, q 1th col Norm tensor(2.5450, grad_fn=<LinalgVectorNormBackward0>)\n",
      "After Scale, q 1th col Norm tensor(0.5775, grad_fn=<LinalgVectorNormBackward0>)\n",
      "####################\n",
      "Before Scale, v 1th col Norm tensor(2.0037, grad_fn=<LinalgVectorNormBackward0>)\n",
      "After Scale, v 1th col Norm tensor(0.5806, grad_fn=<LinalgVectorNormBackward0>)\n",
      "####################\n",
      "Before Scale, q 2th col Norm tensor(2.3736, grad_fn=<LinalgVectorNormBackward0>)\n",
      "After Scale, q 2th col Norm tensor(0.5830, grad_fn=<LinalgVectorNormBackward0>)\n",
      "####################\n",
      "Before Scale, v 2th col Norm tensor(1.9756, grad_fn=<LinalgVectorNormBackward0>)\n",
      "After Scale, v 2th col Norm tensor(0.5725, grad_fn=<LinalgVectorNormBackward0>)\n",
      "####################\n",
      "Before Scale, q 3th col Norm tensor(2.3111, grad_fn=<LinalgVectorNormBackward0>)\n",
      "After Scale, q 3th col Norm tensor(0.5994, grad_fn=<LinalgVectorNormBackward0>)\n",
      "####################\n",
      "Before Scale, v 3th col Norm tensor(1.9667, grad_fn=<LinalgVectorNormBackward0>)\n",
      "After Scale, v 3th col Norm tensor(0.5713, grad_fn=<LinalgVectorNormBackward0>)\n",
      "####################\n",
      "Before Scale, q 0th col Norm tensor(2.9064)\n",
      "After Scale, q 0th col Norm tensor(0.5797, grad_fn=<LinalgVectorNormBackward0>)\n",
      "####################\n",
      "Before Scale, v 0th col Norm tensor(1.9741)\n",
      "After Scale, v 0th col Norm tensor(0.5738, grad_fn=<LinalgVectorNormBackward0>)\n",
      "####################\n",
      "Before Scale, q 1th col Norm tensor(2.5365, grad_fn=<LinalgVectorNormBackward0>)\n",
      "After Scale, q 1th col Norm tensor(0.5802, grad_fn=<LinalgVectorNormBackward0>)\n",
      "####################\n",
      "Before Scale, v 1th col Norm tensor(1.9338, grad_fn=<LinalgVectorNormBackward0>)\n",
      "After Scale, v 1th col Norm tensor(0.5720, grad_fn=<LinalgVectorNormBackward0>)\n",
      "####################\n",
      "Before Scale, q 2th col Norm tensor(2.4089, grad_fn=<LinalgVectorNormBackward0>)\n",
      "After Scale, q 2th col Norm tensor(0.5788, grad_fn=<LinalgVectorNormBackward0>)\n",
      "####################\n",
      "Before Scale, v 2th col Norm tensor(1.8988, grad_fn=<LinalgVectorNormBackward0>)\n",
      "After Scale, v 2th col Norm tensor(0.5817, grad_fn=<LinalgVectorNormBackward0>)\n",
      "####################\n",
      "Before Scale, q 3th col Norm tensor(2.2958, grad_fn=<LinalgVectorNormBackward0>)\n",
      "After Scale, q 3th col Norm tensor(0.5764, grad_fn=<LinalgVectorNormBackward0>)\n",
      "####################\n",
      "Before Scale, v 3th col Norm tensor(1.8905, grad_fn=<LinalgVectorNormBackward0>)\n",
      "After Scale, v 3th col Norm tensor(0.5680, grad_fn=<LinalgVectorNormBackward0>)\n",
      "####################\n",
      "Before Scale, q 0th col Norm tensor(3.1607)\n",
      "After Scale, q 0th col Norm tensor(0.5868, grad_fn=<LinalgVectorNormBackward0>)\n",
      "####################\n",
      "Before Scale, v 0th col Norm tensor(1.9488)\n",
      "After Scale, v 0th col Norm tensor(0.5660, grad_fn=<LinalgVectorNormBackward0>)\n",
      "####################\n",
      "Before Scale, q 1th col Norm tensor(2.5938, grad_fn=<LinalgVectorNormBackward0>)\n",
      "After Scale, q 1th col Norm tensor(0.5735, grad_fn=<LinalgVectorNormBackward0>)\n",
      "####################\n",
      "Before Scale, v 1th col Norm tensor(1.9356, grad_fn=<LinalgVectorNormBackward0>)\n",
      "After Scale, v 1th col Norm tensor(0.5660, grad_fn=<LinalgVectorNormBackward0>)\n",
      "####################\n",
      "Before Scale, q 2th col Norm tensor(2.3900, grad_fn=<LinalgVectorNormBackward0>)\n",
      "After Scale, q 2th col Norm tensor(0.5614, grad_fn=<LinalgVectorNormBackward0>)\n",
      "####################\n",
      "Before Scale, v 2th col Norm tensor(1.8861, grad_fn=<LinalgVectorNormBackward0>)\n",
      "After Scale, v 2th col Norm tensor(0.5843, grad_fn=<LinalgVectorNormBackward0>)\n",
      "####################\n",
      "Before Scale, q 3th col Norm tensor(2.3430, grad_fn=<LinalgVectorNormBackward0>)\n",
      "After Scale, q 3th col Norm tensor(0.5780, grad_fn=<LinalgVectorNormBackward0>)\n",
      "####################\n",
      "Before Scale, v 3th col Norm tensor(1.8741, grad_fn=<LinalgVectorNormBackward0>)\n",
      "After Scale, v 3th col Norm tensor(0.5700, grad_fn=<LinalgVectorNormBackward0>)\n",
      "####################\n",
      "Before Scale, q 0th col Norm tensor(3.0960)\n",
      "After Scale, q 0th col Norm tensor(0.5784, grad_fn=<LinalgVectorNormBackward0>)\n",
      "####################\n",
      "Before Scale, v 0th col Norm tensor(1.8925)\n",
      "After Scale, v 0th col Norm tensor(0.5789, grad_fn=<LinalgVectorNormBackward0>)\n",
      "####################\n",
      "Before Scale, q 1th col Norm tensor(2.5855, grad_fn=<LinalgVectorNormBackward0>)\n",
      "After Scale, q 1th col Norm tensor(0.5806, grad_fn=<LinalgVectorNormBackward0>)\n",
      "####################\n",
      "Before Scale, v 1th col Norm tensor(1.8453, grad_fn=<LinalgVectorNormBackward0>)\n",
      "After Scale, v 1th col Norm tensor(0.5646, grad_fn=<LinalgVectorNormBackward0>)\n",
      "####################\n",
      "Before Scale, q 2th col Norm tensor(2.4220, grad_fn=<LinalgVectorNormBackward0>)\n",
      "After Scale, q 2th col Norm tensor(0.5770, grad_fn=<LinalgVectorNormBackward0>)\n",
      "####################\n",
      "Before Scale, v 2th col Norm tensor(1.8297, grad_fn=<LinalgVectorNormBackward0>)\n",
      "After Scale, v 2th col Norm tensor(0.5892, grad_fn=<LinalgVectorNormBackward0>)\n",
      "####################\n",
      "Before Scale, q 3th col Norm tensor(2.3458, grad_fn=<LinalgVectorNormBackward0>)\n",
      "After Scale, q 3th col Norm tensor(0.5706, grad_fn=<LinalgVectorNormBackward0>)\n",
      "####################\n",
      "Before Scale, v 3th col Norm tensor(1.8157, grad_fn=<LinalgVectorNormBackward0>)\n",
      "After Scale, v 3th col Norm tensor(0.5748, grad_fn=<LinalgVectorNormBackward0>)\n",
      "####################\n",
      "Before Scale, q 0th col Norm tensor(3.0624)\n",
      "After Scale, q 0th col Norm tensor(0.5814, grad_fn=<LinalgVectorNormBackward0>)\n",
      "####################\n",
      "Before Scale, v 0th col Norm tensor(1.8364)\n",
      "After Scale, v 0th col Norm tensor(0.5702, grad_fn=<LinalgVectorNormBackward0>)\n",
      "####################\n",
      "Before Scale, q 1th col Norm tensor(2.5112, grad_fn=<LinalgVectorNormBackward0>)\n",
      "After Scale, q 1th col Norm tensor(0.5666, grad_fn=<LinalgVectorNormBackward0>)\n",
      "####################\n",
      "Before Scale, v 1th col Norm tensor(1.7825, grad_fn=<LinalgVectorNormBackward0>)\n",
      "After Scale, v 1th col Norm tensor(0.5757, grad_fn=<LinalgVectorNormBackward0>)\n",
      "####################\n",
      "Before Scale, q 2th col Norm tensor(2.3653, grad_fn=<LinalgVectorNormBackward0>)\n",
      "After Scale, q 2th col Norm tensor(0.5796, grad_fn=<LinalgVectorNormBackward0>)\n",
      "####################\n",
      "Before Scale, v 2th col Norm tensor(1.7542, grad_fn=<LinalgVectorNormBackward0>)\n",
      "After Scale, v 2th col Norm tensor(0.5722, grad_fn=<LinalgVectorNormBackward0>)\n",
      "####################\n",
      "Before Scale, q 3th col Norm tensor(2.3556, grad_fn=<LinalgVectorNormBackward0>)\n",
      "After Scale, q 3th col Norm tensor(0.5827, grad_fn=<LinalgVectorNormBackward0>)\n",
      "####################\n",
      "Before Scale, v 3th col Norm tensor(1.7466, grad_fn=<LinalgVectorNormBackward0>)\n",
      "After Scale, v 3th col Norm tensor(0.5730, grad_fn=<LinalgVectorNormBackward0>)\n",
      "####################\n",
      "Before Scale, q 0th col Norm tensor(3.0136)\n",
      "After Scale, q 0th col Norm tensor(0.5661, grad_fn=<LinalgVectorNormBackward0>)\n",
      "####################\n",
      "Before Scale, v 0th col Norm tensor(1.7608)\n",
      "After Scale, v 0th col Norm tensor(0.5819, grad_fn=<LinalgVectorNormBackward0>)\n",
      "####################\n",
      "Before Scale, q 1th col Norm tensor(2.3976, grad_fn=<LinalgVectorNormBackward0>)\n",
      "After Scale, q 1th col Norm tensor(0.5731, grad_fn=<LinalgVectorNormBackward0>)\n",
      "####################\n",
      "Before Scale, v 1th col Norm tensor(1.7192, grad_fn=<LinalgVectorNormBackward0>)\n",
      "After Scale, v 1th col Norm tensor(0.5705, grad_fn=<LinalgVectorNormBackward0>)\n",
      "####################\n",
      "Before Scale, q 2th col Norm tensor(2.3635, grad_fn=<LinalgVectorNormBackward0>)\n",
      "After Scale, q 2th col Norm tensor(0.5761, grad_fn=<LinalgVectorNormBackward0>)\n",
      "####################\n",
      "Before Scale, v 2th col Norm tensor(1.7014, grad_fn=<LinalgVectorNormBackward0>)\n",
      "After Scale, v 2th col Norm tensor(0.5647, grad_fn=<LinalgVectorNormBackward0>)\n",
      "####################\n",
      "Before Scale, q 3th col Norm tensor(2.2662, grad_fn=<LinalgVectorNormBackward0>)\n",
      "After Scale, q 3th col Norm tensor(0.5775, grad_fn=<LinalgVectorNormBackward0>)\n",
      "####################\n",
      "Before Scale, v 3th col Norm tensor(1.6975, grad_fn=<LinalgVectorNormBackward0>)\n",
      "After Scale, v 3th col Norm tensor(0.5789, grad_fn=<LinalgVectorNormBackward0>)\n",
      "####################\n",
      "Before Scale, q 0th col Norm tensor(2.9946)\n",
      "After Scale, q 0th col Norm tensor(0.5697, grad_fn=<LinalgVectorNormBackward0>)\n",
      "####################\n",
      "Before Scale, v 0th col Norm tensor(1.6533)\n",
      "After Scale, v 0th col Norm tensor(0.5803, grad_fn=<LinalgVectorNormBackward0>)\n",
      "####################\n",
      "Before Scale, q 1th col Norm tensor(2.8534, grad_fn=<LinalgVectorNormBackward0>)\n",
      "After Scale, q 1th col Norm tensor(0.5749, grad_fn=<LinalgVectorNormBackward0>)\n",
      "####################\n",
      "Before Scale, v 1th col Norm tensor(1.6288, grad_fn=<LinalgVectorNormBackward0>)\n",
      "After Scale, v 1th col Norm tensor(0.5710, grad_fn=<LinalgVectorNormBackward0>)\n",
      "####################\n",
      "Before Scale, q 2th col Norm tensor(2.4948, grad_fn=<LinalgVectorNormBackward0>)\n",
      "After Scale, q 2th col Norm tensor(0.5748, grad_fn=<LinalgVectorNormBackward0>)\n",
      "####################\n",
      "Before Scale, v 2th col Norm tensor(1.6197, grad_fn=<LinalgVectorNormBackward0>)\n",
      "After Scale, v 2th col Norm tensor(0.5823, grad_fn=<LinalgVectorNormBackward0>)\n",
      "####################\n",
      "Before Scale, q 3th col Norm tensor(2.4425, grad_fn=<LinalgVectorNormBackward0>)\n",
      "After Scale, q 3th col Norm tensor(0.5818, grad_fn=<LinalgVectorNormBackward0>)\n",
      "####################\n",
      "Before Scale, v 3th col Norm tensor(1.6095, grad_fn=<LinalgVectorNormBackward0>)\n",
      "After Scale, v 3th col Norm tensor(0.5733, grad_fn=<LinalgVectorNormBackward0>)\n",
      "####################\n",
      "Before Scale, q 0th col Norm tensor(3.0471)\n",
      "After Scale, q 0th col Norm tensor(0.5765, grad_fn=<LinalgVectorNormBackward0>)\n",
      "####################\n",
      "Before Scale, v 0th col Norm tensor(2.0520)\n",
      "After Scale, v 0th col Norm tensor(0.5843, grad_fn=<LinalgVectorNormBackward0>)\n",
      "####################\n",
      "Before Scale, q 1th col Norm tensor(2.8709, grad_fn=<LinalgVectorNormBackward0>)\n",
      "After Scale, q 1th col Norm tensor(0.5808, grad_fn=<LinalgVectorNormBackward0>)\n",
      "####################\n",
      "Before Scale, v 1th col Norm tensor(1.7964, grad_fn=<LinalgVectorNormBackward0>)\n",
      "After Scale, v 1th col Norm tensor(0.5748, grad_fn=<LinalgVectorNormBackward0>)\n",
      "####################\n",
      "Before Scale, q 2th col Norm tensor(2.6469, grad_fn=<LinalgVectorNormBackward0>)\n",
      "After Scale, q 2th col Norm tensor(0.5854, grad_fn=<LinalgVectorNormBackward0>)\n",
      "####################\n",
      "Before Scale, v 2th col Norm tensor(1.6738, grad_fn=<LinalgVectorNormBackward0>)\n",
      "After Scale, v 2th col Norm tensor(0.5698, grad_fn=<LinalgVectorNormBackward0>)\n",
      "####################\n",
      "Before Scale, q 3th col Norm tensor(2.3719, grad_fn=<LinalgVectorNormBackward0>)\n",
      "After Scale, q 3th col Norm tensor(0.5675, grad_fn=<LinalgVectorNormBackward0>)\n",
      "####################\n",
      "Before Scale, v 3th col Norm tensor(1.6186, grad_fn=<LinalgVectorNormBackward0>)\n",
      "After Scale, v 3th col Norm tensor(0.5782, grad_fn=<LinalgVectorNormBackward0>)\n",
      "####################\n",
      "Before Scale, q 0th col Norm tensor(2.6912)\n",
      "After Scale, q 0th col Norm tensor(0.5824, grad_fn=<LinalgVectorNormBackward0>)\n",
      "####################\n",
      "Before Scale, v 0th col Norm tensor(1.7994)\n",
      "After Scale, v 0th col Norm tensor(0.5722, grad_fn=<LinalgVectorNormBackward0>)\n",
      "####################\n",
      "Before Scale, q 1th col Norm tensor(2.2055, grad_fn=<LinalgVectorNormBackward0>)\n",
      "After Scale, q 1th col Norm tensor(0.5811, grad_fn=<LinalgVectorNormBackward0>)\n",
      "####################\n",
      "Before Scale, v 1th col Norm tensor(1.7123, grad_fn=<LinalgVectorNormBackward0>)\n",
      "After Scale, v 1th col Norm tensor(0.5857, grad_fn=<LinalgVectorNormBackward0>)\n",
      "####################\n",
      "Before Scale, q 2th col Norm tensor(2.1798, grad_fn=<LinalgVectorNormBackward0>)\n",
      "After Scale, q 2th col Norm tensor(0.5673, grad_fn=<LinalgVectorNormBackward0>)\n",
      "####################\n",
      "Before Scale, v 2th col Norm tensor(1.6797, grad_fn=<LinalgVectorNormBackward0>)\n",
      "After Scale, v 2th col Norm tensor(0.5672, grad_fn=<LinalgVectorNormBackward0>)\n",
      "####################\n",
      "Before Scale, q 3th col Norm tensor(2.0779, grad_fn=<LinalgVectorNormBackward0>)\n",
      "After Scale, q 3th col Norm tensor(0.5718, grad_fn=<LinalgVectorNormBackward0>)\n",
      "####################\n",
      "Before Scale, v 3th col Norm tensor(1.6344, grad_fn=<LinalgVectorNormBackward0>)\n",
      "After Scale, v 3th col Norm tensor(0.5752, grad_fn=<LinalgVectorNormBackward0>)\n",
      "####################\n",
      "Before Scale, q 0th col Norm tensor(3.0725)\n",
      "After Scale, q 0th col Norm tensor(0.5592, grad_fn=<LinalgVectorNormBackward0>)\n",
      "####################\n",
      "Before Scale, v 0th col Norm tensor(1.9530)\n",
      "After Scale, v 0th col Norm tensor(0.5707, grad_fn=<LinalgVectorNormBackward0>)\n",
      "####################\n",
      "Before Scale, q 1th col Norm tensor(2.4894, grad_fn=<LinalgVectorNormBackward0>)\n",
      "After Scale, q 1th col Norm tensor(0.5822, grad_fn=<LinalgVectorNormBackward0>)\n",
      "####################\n",
      "Before Scale, v 1th col Norm tensor(1.8648, grad_fn=<LinalgVectorNormBackward0>)\n",
      "After Scale, v 1th col Norm tensor(0.5776, grad_fn=<LinalgVectorNormBackward0>)\n",
      "####################\n",
      "Before Scale, q 2th col Norm tensor(2.3708, grad_fn=<LinalgVectorNormBackward0>)\n",
      "After Scale, q 2th col Norm tensor(0.5833, grad_fn=<LinalgVectorNormBackward0>)\n",
      "####################\n",
      "Before Scale, v 2th col Norm tensor(1.8356, grad_fn=<LinalgVectorNormBackward0>)\n",
      "After Scale, v 2th col Norm tensor(0.5843, grad_fn=<LinalgVectorNormBackward0>)\n",
      "####################\n",
      "Before Scale, q 3th col Norm tensor(2.2621, grad_fn=<LinalgVectorNormBackward0>)\n",
      "After Scale, q 3th col Norm tensor(0.5740, grad_fn=<LinalgVectorNormBackward0>)\n",
      "####################\n",
      "Before Scale, v 3th col Norm tensor(1.8202, grad_fn=<LinalgVectorNormBackward0>)\n",
      "After Scale, v 3th col Norm tensor(0.5839, grad_fn=<LinalgVectorNormBackward0>)\n",
      "####################\n",
      "Before Scale, q 0th col Norm tensor(3.1196)\n",
      "After Scale, q 0th col Norm tensor(0.5872, grad_fn=<LinalgVectorNormBackward0>)\n",
      "####################\n",
      "Before Scale, v 0th col Norm tensor(1.9776)\n",
      "After Scale, v 0th col Norm tensor(0.5674, grad_fn=<LinalgVectorNormBackward0>)\n",
      "####################\n",
      "Before Scale, q 1th col Norm tensor(2.5201, grad_fn=<LinalgVectorNormBackward0>)\n",
      "After Scale, q 1th col Norm tensor(0.5823, grad_fn=<LinalgVectorNormBackward0>)\n",
      "####################\n",
      "Before Scale, v 1th col Norm tensor(1.9533, grad_fn=<LinalgVectorNormBackward0>)\n",
      "After Scale, v 1th col Norm tensor(0.5666, grad_fn=<LinalgVectorNormBackward0>)\n",
      "####################\n",
      "Before Scale, q 2th col Norm tensor(2.3593, grad_fn=<LinalgVectorNormBackward0>)\n",
      "After Scale, q 2th col Norm tensor(0.5783, grad_fn=<LinalgVectorNormBackward0>)\n",
      "####################\n",
      "Before Scale, v 2th col Norm tensor(1.9400, grad_fn=<LinalgVectorNormBackward0>)\n",
      "After Scale, v 2th col Norm tensor(0.5842, grad_fn=<LinalgVectorNormBackward0>)\n",
      "####################\n",
      "Before Scale, q 3th col Norm tensor(2.3367, grad_fn=<LinalgVectorNormBackward0>)\n",
      "After Scale, q 3th col Norm tensor(0.5703, grad_fn=<LinalgVectorNormBackward0>)\n",
      "####################\n",
      "Before Scale, v 3th col Norm tensor(1.9073, grad_fn=<LinalgVectorNormBackward0>)\n",
      "After Scale, v 3th col Norm tensor(0.5827, grad_fn=<LinalgVectorNormBackward0>)\n",
      "####################\n",
      "Before Scale, q 0th col Norm tensor(2.9832)\n",
      "After Scale, q 0th col Norm tensor(0.5770, grad_fn=<LinalgVectorNormBackward0>)\n",
      "####################\n",
      "Before Scale, v 0th col Norm tensor(1.9328)\n",
      "After Scale, v 0th col Norm tensor(0.5829, grad_fn=<LinalgVectorNormBackward0>)\n",
      "####################\n",
      "Before Scale, q 1th col Norm tensor(2.5012, grad_fn=<LinalgVectorNormBackward0>)\n",
      "After Scale, q 1th col Norm tensor(0.5775, grad_fn=<LinalgVectorNormBackward0>)\n",
      "####################\n",
      "Before Scale, v 1th col Norm tensor(1.8785, grad_fn=<LinalgVectorNormBackward0>)\n",
      "After Scale, v 1th col Norm tensor(0.5769, grad_fn=<LinalgVectorNormBackward0>)\n",
      "####################\n",
      "Before Scale, q 2th col Norm tensor(2.3815, grad_fn=<LinalgVectorNormBackward0>)\n",
      "After Scale, q 2th col Norm tensor(0.5782, grad_fn=<LinalgVectorNormBackward0>)\n",
      "####################\n",
      "Before Scale, v 2th col Norm tensor(1.7824, grad_fn=<LinalgVectorNormBackward0>)\n",
      "After Scale, v 2th col Norm tensor(0.5790, grad_fn=<LinalgVectorNormBackward0>)\n",
      "####################\n",
      "Before Scale, q 3th col Norm tensor(2.3218, grad_fn=<LinalgVectorNormBackward0>)\n",
      "After Scale, q 3th col Norm tensor(0.5745, grad_fn=<LinalgVectorNormBackward0>)\n",
      "####################\n",
      "Before Scale, v 3th col Norm tensor(1.7690, grad_fn=<LinalgVectorNormBackward0>)\n",
      "After Scale, v 3th col Norm tensor(0.5722, grad_fn=<LinalgVectorNormBackward0>)\n",
      "####################\n",
      "Before Scale, q 0th col Norm tensor(3.0535)\n",
      "After Scale, q 0th col Norm tensor(0.5809, grad_fn=<LinalgVectorNormBackward0>)\n",
      "####################\n",
      "Before Scale, v 0th col Norm tensor(1.9506)\n",
      "After Scale, v 0th col Norm tensor(0.5690, grad_fn=<LinalgVectorNormBackward0>)\n",
      "####################\n",
      "Before Scale, q 1th col Norm tensor(2.5685, grad_fn=<LinalgVectorNormBackward0>)\n",
      "After Scale, q 1th col Norm tensor(0.5845, grad_fn=<LinalgVectorNormBackward0>)\n",
      "####################\n",
      "Before Scale, v 1th col Norm tensor(1.9325, grad_fn=<LinalgVectorNormBackward0>)\n",
      "After Scale, v 1th col Norm tensor(0.5723, grad_fn=<LinalgVectorNormBackward0>)\n",
      "####################\n",
      "Before Scale, q 2th col Norm tensor(2.4341, grad_fn=<LinalgVectorNormBackward0>)\n",
      "After Scale, q 2th col Norm tensor(0.5777, grad_fn=<LinalgVectorNormBackward0>)\n",
      "####################\n",
      "Before Scale, v 2th col Norm tensor(1.8835, grad_fn=<LinalgVectorNormBackward0>)\n",
      "After Scale, v 2th col Norm tensor(0.5818, grad_fn=<LinalgVectorNormBackward0>)\n",
      "####################\n",
      "Before Scale, q 3th col Norm tensor(2.3260, grad_fn=<LinalgVectorNormBackward0>)\n",
      "After Scale, q 3th col Norm tensor(0.5809, grad_fn=<LinalgVectorNormBackward0>)\n",
      "####################\n",
      "Before Scale, v 3th col Norm tensor(1.8638, grad_fn=<LinalgVectorNormBackward0>)\n",
      "After Scale, v 3th col Norm tensor(0.5834, grad_fn=<LinalgVectorNormBackward0>)\n",
      "####################\n",
      "Before Scale, q 0th col Norm tensor(2.8972)\n",
      "After Scale, q 0th col Norm tensor(0.5768, grad_fn=<LinalgVectorNormBackward0>)\n",
      "####################\n",
      "Before Scale, v 0th col Norm tensor(1.9289)\n",
      "After Scale, v 0th col Norm tensor(0.5681, grad_fn=<LinalgVectorNormBackward0>)\n",
      "####################\n",
      "Before Scale, q 1th col Norm tensor(2.5271, grad_fn=<LinalgVectorNormBackward0>)\n",
      "After Scale, q 1th col Norm tensor(0.5721, grad_fn=<LinalgVectorNormBackward0>)\n",
      "####################\n",
      "Before Scale, v 1th col Norm tensor(1.8970, grad_fn=<LinalgVectorNormBackward0>)\n",
      "After Scale, v 1th col Norm tensor(0.5770, grad_fn=<LinalgVectorNormBackward0>)\n",
      "####################\n",
      "Before Scale, q 2th col Norm tensor(2.4338, grad_fn=<LinalgVectorNormBackward0>)\n",
      "After Scale, q 2th col Norm tensor(0.5645, grad_fn=<LinalgVectorNormBackward0>)\n",
      "####################\n",
      "Before Scale, v 2th col Norm tensor(1.8773, grad_fn=<LinalgVectorNormBackward0>)\n",
      "After Scale, v 2th col Norm tensor(0.5783, grad_fn=<LinalgVectorNormBackward0>)\n",
      "####################\n",
      "Before Scale, q 3th col Norm tensor(2.2976, grad_fn=<LinalgVectorNormBackward0>)\n",
      "After Scale, q 3th col Norm tensor(0.5753, grad_fn=<LinalgVectorNormBackward0>)\n",
      "####################\n",
      "Before Scale, v 3th col Norm tensor(1.8111, grad_fn=<LinalgVectorNormBackward0>)\n",
      "After Scale, v 3th col Norm tensor(0.5814, grad_fn=<LinalgVectorNormBackward0>)\n",
      "####################\n",
      "Before Scale, q 0th col Norm tensor(3.1522)\n",
      "After Scale, q 0th col Norm tensor(0.5669, grad_fn=<LinalgVectorNormBackward0>)\n",
      "####################\n",
      "Before Scale, v 0th col Norm tensor(1.8965)\n",
      "After Scale, v 0th col Norm tensor(0.5800, grad_fn=<LinalgVectorNormBackward0>)\n",
      "####################\n",
      "Before Scale, q 1th col Norm tensor(2.5873, grad_fn=<LinalgVectorNormBackward0>)\n",
      "After Scale, q 1th col Norm tensor(0.5668, grad_fn=<LinalgVectorNormBackward0>)\n",
      "####################\n",
      "Before Scale, v 1th col Norm tensor(1.8814, grad_fn=<LinalgVectorNormBackward0>)\n",
      "After Scale, v 1th col Norm tensor(0.5798, grad_fn=<LinalgVectorNormBackward0>)\n",
      "####################\n",
      "Before Scale, q 2th col Norm tensor(2.4169, grad_fn=<LinalgVectorNormBackward0>)\n",
      "After Scale, q 2th col Norm tensor(0.5803, grad_fn=<LinalgVectorNormBackward0>)\n",
      "####################\n",
      "Before Scale, v 2th col Norm tensor(1.8267, grad_fn=<LinalgVectorNormBackward0>)\n",
      "After Scale, v 2th col Norm tensor(0.5759, grad_fn=<LinalgVectorNormBackward0>)\n",
      "####################\n",
      "Before Scale, q 3th col Norm tensor(2.3356, grad_fn=<LinalgVectorNormBackward0>)\n",
      "After Scale, q 3th col Norm tensor(0.5775, grad_fn=<LinalgVectorNormBackward0>)\n",
      "####################\n",
      "Before Scale, v 3th col Norm tensor(1.8114, grad_fn=<LinalgVectorNormBackward0>)\n",
      "After Scale, v 3th col Norm tensor(0.5828, grad_fn=<LinalgVectorNormBackward0>)\n",
      "####################\n",
      "Before Scale, q 0th col Norm tensor(3.0936)\n",
      "After Scale, q 0th col Norm tensor(0.5714, grad_fn=<LinalgVectorNormBackward0>)\n",
      "####################\n",
      "Before Scale, v 0th col Norm tensor(1.8215)\n",
      "After Scale, v 0th col Norm tensor(0.5638, grad_fn=<LinalgVectorNormBackward0>)\n",
      "####################\n",
      "Before Scale, q 1th col Norm tensor(2.5840, grad_fn=<LinalgVectorNormBackward0>)\n",
      "After Scale, q 1th col Norm tensor(0.5715, grad_fn=<LinalgVectorNormBackward0>)\n",
      "####################\n",
      "Before Scale, v 1th col Norm tensor(1.7916, grad_fn=<LinalgVectorNormBackward0>)\n",
      "After Scale, v 1th col Norm tensor(0.5833, grad_fn=<LinalgVectorNormBackward0>)\n",
      "####################\n",
      "Before Scale, q 2th col Norm tensor(2.4425, grad_fn=<LinalgVectorNormBackward0>)\n",
      "After Scale, q 2th col Norm tensor(0.5700, grad_fn=<LinalgVectorNormBackward0>)\n",
      "####################\n",
      "Before Scale, v 2th col Norm tensor(1.7815, grad_fn=<LinalgVectorNormBackward0>)\n",
      "After Scale, v 2th col Norm tensor(0.5831, grad_fn=<LinalgVectorNormBackward0>)\n",
      "####################\n",
      "Before Scale, q 3th col Norm tensor(2.3598, grad_fn=<LinalgVectorNormBackward0>)\n",
      "After Scale, q 3th col Norm tensor(0.5734, grad_fn=<LinalgVectorNormBackward0>)\n",
      "####################\n",
      "Before Scale, v 3th col Norm tensor(1.7597, grad_fn=<LinalgVectorNormBackward0>)\n",
      "After Scale, v 3th col Norm tensor(0.5774, grad_fn=<LinalgVectorNormBackward0>)\n",
      "####################\n",
      "Before Scale, q 0th col Norm tensor(3.0776)\n",
      "After Scale, q 0th col Norm tensor(0.5738, grad_fn=<LinalgVectorNormBackward0>)\n",
      "####################\n",
      "Before Scale, v 0th col Norm tensor(1.7862)\n",
      "After Scale, v 0th col Norm tensor(0.5743, grad_fn=<LinalgVectorNormBackward0>)\n",
      "####################\n",
      "Before Scale, q 1th col Norm tensor(2.5212, grad_fn=<LinalgVectorNormBackward0>)\n",
      "After Scale, q 1th col Norm tensor(0.5837, grad_fn=<LinalgVectorNormBackward0>)\n",
      "####################\n",
      "Before Scale, v 1th col Norm tensor(1.7477, grad_fn=<LinalgVectorNormBackward0>)\n",
      "After Scale, v 1th col Norm tensor(0.5730, grad_fn=<LinalgVectorNormBackward0>)\n",
      "####################\n",
      "Before Scale, q 2th col Norm tensor(2.4035, grad_fn=<LinalgVectorNormBackward0>)\n",
      "After Scale, q 2th col Norm tensor(0.5751, grad_fn=<LinalgVectorNormBackward0>)\n",
      "####################\n",
      "Before Scale, v 2th col Norm tensor(1.7289, grad_fn=<LinalgVectorNormBackward0>)\n",
      "After Scale, v 2th col Norm tensor(0.5662, grad_fn=<LinalgVectorNormBackward0>)\n",
      "####################\n",
      "Before Scale, q 3th col Norm tensor(2.3628, grad_fn=<LinalgVectorNormBackward0>)\n",
      "After Scale, q 3th col Norm tensor(0.5677, grad_fn=<LinalgVectorNormBackward0>)\n",
      "####################\n",
      "Before Scale, v 3th col Norm tensor(1.7231, grad_fn=<LinalgVectorNormBackward0>)\n",
      "After Scale, v 3th col Norm tensor(0.5866, grad_fn=<LinalgVectorNormBackward0>)\n",
      "####################\n",
      "Before Scale, q 0th col Norm tensor(3.0492)\n",
      "After Scale, q 0th col Norm tensor(0.5706, grad_fn=<LinalgVectorNormBackward0>)\n",
      "####################\n",
      "Before Scale, v 0th col Norm tensor(1.7733)\n",
      "After Scale, v 0th col Norm tensor(0.5814, grad_fn=<LinalgVectorNormBackward0>)\n",
      "####################\n",
      "Before Scale, q 1th col Norm tensor(2.4176, grad_fn=<LinalgVectorNormBackward0>)\n",
      "After Scale, q 1th col Norm tensor(0.5887, grad_fn=<LinalgVectorNormBackward0>)\n",
      "####################\n",
      "Before Scale, v 1th col Norm tensor(1.7344, grad_fn=<LinalgVectorNormBackward0>)\n",
      "After Scale, v 1th col Norm tensor(0.5803, grad_fn=<LinalgVectorNormBackward0>)\n",
      "####################\n",
      "Before Scale, q 2th col Norm tensor(2.3496, grad_fn=<LinalgVectorNormBackward0>)\n",
      "After Scale, q 2th col Norm tensor(0.5860, grad_fn=<LinalgVectorNormBackward0>)\n",
      "####################\n",
      "Before Scale, v 2th col Norm tensor(1.7015, grad_fn=<LinalgVectorNormBackward0>)\n",
      "After Scale, v 2th col Norm tensor(0.5771, grad_fn=<LinalgVectorNormBackward0>)\n",
      "####################\n",
      "Before Scale, q 3th col Norm tensor(2.2671, grad_fn=<LinalgVectorNormBackward0>)\n",
      "After Scale, q 3th col Norm tensor(0.5805, grad_fn=<LinalgVectorNormBackward0>)\n",
      "####################\n",
      "Before Scale, v 3th col Norm tensor(1.6931, grad_fn=<LinalgVectorNormBackward0>)\n",
      "After Scale, v 3th col Norm tensor(0.5846, grad_fn=<LinalgVectorNormBackward0>)\n",
      "####################\n",
      "Before Scale, q 0th col Norm tensor(2.9450)\n",
      "After Scale, q 0th col Norm tensor(0.5782, grad_fn=<LinalgVectorNormBackward0>)\n",
      "####################\n",
      "Before Scale, v 0th col Norm tensor(1.6534)\n",
      "After Scale, v 0th col Norm tensor(0.5857, grad_fn=<LinalgVectorNormBackward0>)\n",
      "####################\n",
      "Before Scale, q 1th col Norm tensor(2.8392, grad_fn=<LinalgVectorNormBackward0>)\n",
      "After Scale, q 1th col Norm tensor(0.5692, grad_fn=<LinalgVectorNormBackward0>)\n",
      "####################\n",
      "Before Scale, v 1th col Norm tensor(1.6306, grad_fn=<LinalgVectorNormBackward0>)\n",
      "After Scale, v 1th col Norm tensor(0.5759, grad_fn=<LinalgVectorNormBackward0>)\n",
      "####################\n",
      "Before Scale, q 2th col Norm tensor(2.5007, grad_fn=<LinalgVectorNormBackward0>)\n",
      "After Scale, q 2th col Norm tensor(0.5704, grad_fn=<LinalgVectorNormBackward0>)\n",
      "####################\n",
      "Before Scale, v 2th col Norm tensor(1.6205, grad_fn=<LinalgVectorNormBackward0>)\n",
      "After Scale, v 2th col Norm tensor(0.5714, grad_fn=<LinalgVectorNormBackward0>)\n",
      "####################\n",
      "Before Scale, q 3th col Norm tensor(2.4438, grad_fn=<LinalgVectorNormBackward0>)\n",
      "After Scale, q 3th col Norm tensor(0.5821, grad_fn=<LinalgVectorNormBackward0>)\n",
      "####################\n",
      "Before Scale, v 3th col Norm tensor(1.6131, grad_fn=<LinalgVectorNormBackward0>)\n",
      "After Scale, v 3th col Norm tensor(0.5661, grad_fn=<LinalgVectorNormBackward0>)\n",
      "####################\n",
      "Before Scale, q 0th col Norm tensor(3.0412)\n",
      "After Scale, q 0th col Norm tensor(0.5756, grad_fn=<LinalgVectorNormBackward0>)\n",
      "####################\n",
      "Before Scale, v 0th col Norm tensor(2.0354)\n",
      "After Scale, v 0th col Norm tensor(0.5732, grad_fn=<LinalgVectorNormBackward0>)\n",
      "####################\n",
      "Before Scale, q 1th col Norm tensor(2.8576, grad_fn=<LinalgVectorNormBackward0>)\n",
      "After Scale, q 1th col Norm tensor(0.5792, grad_fn=<LinalgVectorNormBackward0>)\n",
      "####################\n",
      "Before Scale, v 1th col Norm tensor(1.7962, grad_fn=<LinalgVectorNormBackward0>)\n",
      "After Scale, v 1th col Norm tensor(0.5754, grad_fn=<LinalgVectorNormBackward0>)\n",
      "####################\n",
      "Before Scale, q 2th col Norm tensor(2.6406, grad_fn=<LinalgVectorNormBackward0>)\n",
      "After Scale, q 2th col Norm tensor(0.5754, grad_fn=<LinalgVectorNormBackward0>)\n",
      "####################\n",
      "Before Scale, v 2th col Norm tensor(1.6704, grad_fn=<LinalgVectorNormBackward0>)\n",
      "After Scale, v 2th col Norm tensor(0.5848, grad_fn=<LinalgVectorNormBackward0>)\n",
      "####################\n",
      "Before Scale, q 3th col Norm tensor(2.3796, grad_fn=<LinalgVectorNormBackward0>)\n",
      "After Scale, q 3th col Norm tensor(0.5797, grad_fn=<LinalgVectorNormBackward0>)\n",
      "####################\n",
      "Before Scale, v 3th col Norm tensor(1.6199, grad_fn=<LinalgVectorNormBackward0>)\n",
      "After Scale, v 3th col Norm tensor(0.5773, grad_fn=<LinalgVectorNormBackward0>)\n",
      "####################\n",
      "Before Scale, q 0th col Norm tensor(2.6832)\n",
      "After Scale, q 0th col Norm tensor(0.5768, grad_fn=<LinalgVectorNormBackward0>)\n",
      "####################\n",
      "Before Scale, v 0th col Norm tensor(1.8011)\n",
      "After Scale, v 0th col Norm tensor(0.5791, grad_fn=<LinalgVectorNormBackward0>)\n",
      "####################\n",
      "Before Scale, q 1th col Norm tensor(2.2135, grad_fn=<LinalgVectorNormBackward0>)\n",
      "After Scale, q 1th col Norm tensor(0.5901, grad_fn=<LinalgVectorNormBackward0>)\n",
      "####################\n",
      "Before Scale, v 1th col Norm tensor(1.6954, grad_fn=<LinalgVectorNormBackward0>)\n",
      "After Scale, v 1th col Norm tensor(0.5864, grad_fn=<LinalgVectorNormBackward0>)\n",
      "####################\n",
      "Before Scale, q 2th col Norm tensor(2.1647, grad_fn=<LinalgVectorNormBackward0>)\n",
      "After Scale, q 2th col Norm tensor(0.5715, grad_fn=<LinalgVectorNormBackward0>)\n",
      "####################\n",
      "Before Scale, v 2th col Norm tensor(1.6724, grad_fn=<LinalgVectorNormBackward0>)\n",
      "After Scale, v 2th col Norm tensor(0.5889, grad_fn=<LinalgVectorNormBackward0>)\n",
      "####################\n",
      "Before Scale, q 3th col Norm tensor(2.0750, grad_fn=<LinalgVectorNormBackward0>)\n",
      "After Scale, q 3th col Norm tensor(0.5733, grad_fn=<LinalgVectorNormBackward0>)\n",
      "####################\n",
      "Before Scale, v 3th col Norm tensor(1.6135, grad_fn=<LinalgVectorNormBackward0>)\n",
      "After Scale, v 3th col Norm tensor(0.5839, grad_fn=<LinalgVectorNormBackward0>)\n",
      "####################\n",
      "Before Scale, q 0th col Norm tensor(3.0625)\n",
      "After Scale, q 0th col Norm tensor(0.5722, grad_fn=<LinalgVectorNormBackward0>)\n",
      "####################\n",
      "Before Scale, v 0th col Norm tensor(1.9794)\n",
      "After Scale, v 0th col Norm tensor(0.5783, grad_fn=<LinalgVectorNormBackward0>)\n",
      "####################\n",
      "Before Scale, q 1th col Norm tensor(2.4885, grad_fn=<LinalgVectorNormBackward0>)\n",
      "After Scale, q 1th col Norm tensor(0.5681, grad_fn=<LinalgVectorNormBackward0>)\n",
      "####################\n",
      "Before Scale, v 1th col Norm tensor(1.8532, grad_fn=<LinalgVectorNormBackward0>)\n",
      "After Scale, v 1th col Norm tensor(0.5643, grad_fn=<LinalgVectorNormBackward0>)\n",
      "####################\n",
      "Before Scale, q 2th col Norm tensor(2.3805, grad_fn=<LinalgVectorNormBackward0>)\n",
      "After Scale, q 2th col Norm tensor(0.5868, grad_fn=<LinalgVectorNormBackward0>)\n",
      "####################\n",
      "Before Scale, v 2th col Norm tensor(1.8356, grad_fn=<LinalgVectorNormBackward0>)\n",
      "After Scale, v 2th col Norm tensor(0.5735, grad_fn=<LinalgVectorNormBackward0>)\n",
      "####################\n",
      "Before Scale, q 3th col Norm tensor(2.2740, grad_fn=<LinalgVectorNormBackward0>)\n",
      "After Scale, q 3th col Norm tensor(0.5719, grad_fn=<LinalgVectorNormBackward0>)\n",
      "####################\n",
      "Before Scale, v 3th col Norm tensor(1.8054, grad_fn=<LinalgVectorNormBackward0>)\n",
      "After Scale, v 3th col Norm tensor(0.5789, grad_fn=<LinalgVectorNormBackward0>)\n",
      "####################\n",
      "Before Scale, q 0th col Norm tensor(3.1114)\n",
      "After Scale, q 0th col Norm tensor(0.5870, grad_fn=<LinalgVectorNormBackward0>)\n",
      "####################\n",
      "Before Scale, v 0th col Norm tensor(1.9700)\n",
      "After Scale, v 0th col Norm tensor(0.5797, grad_fn=<LinalgVectorNormBackward0>)\n",
      "####################\n",
      "Before Scale, q 1th col Norm tensor(2.5203, grad_fn=<LinalgVectorNormBackward0>)\n",
      "After Scale, q 1th col Norm tensor(0.5804, grad_fn=<LinalgVectorNormBackward0>)\n",
      "####################\n",
      "Before Scale, v 1th col Norm tensor(1.9554, grad_fn=<LinalgVectorNormBackward0>)\n",
      "After Scale, v 1th col Norm tensor(0.5746, grad_fn=<LinalgVectorNormBackward0>)\n",
      "####################\n",
      "Before Scale, q 2th col Norm tensor(2.3634, grad_fn=<LinalgVectorNormBackward0>)\n",
      "After Scale, q 2th col Norm tensor(0.5699, grad_fn=<LinalgVectorNormBackward0>)\n",
      "####################\n",
      "Before Scale, v 2th col Norm tensor(1.9134, grad_fn=<LinalgVectorNormBackward0>)\n",
      "After Scale, v 2th col Norm tensor(0.5733, grad_fn=<LinalgVectorNormBackward0>)\n",
      "####################\n",
      "Before Scale, q 3th col Norm tensor(2.3458, grad_fn=<LinalgVectorNormBackward0>)\n",
      "After Scale, q 3th col Norm tensor(0.5835, grad_fn=<LinalgVectorNormBackward0>)\n",
      "####################\n",
      "Before Scale, v 3th col Norm tensor(1.9028, grad_fn=<LinalgVectorNormBackward0>)\n",
      "After Scale, v 3th col Norm tensor(0.5800, grad_fn=<LinalgVectorNormBackward0>)\n",
      "####################\n",
      "Before Scale, q 0th col Norm tensor(2.9791)\n",
      "After Scale, q 0th col Norm tensor(0.5880, grad_fn=<LinalgVectorNormBackward0>)\n",
      "####################\n",
      "Before Scale, v 0th col Norm tensor(1.9373)\n",
      "After Scale, v 0th col Norm tensor(0.5689, grad_fn=<LinalgVectorNormBackward0>)\n",
      "####################\n",
      "Before Scale, q 1th col Norm tensor(2.5037, grad_fn=<LinalgVectorNormBackward0>)\n",
      "After Scale, q 1th col Norm tensor(0.5640, grad_fn=<LinalgVectorNormBackward0>)\n",
      "####################\n",
      "Before Scale, v 1th col Norm tensor(1.8758, grad_fn=<LinalgVectorNormBackward0>)\n",
      "After Scale, v 1th col Norm tensor(0.5810, grad_fn=<LinalgVectorNormBackward0>)\n",
      "####################\n",
      "Before Scale, q 2th col Norm tensor(2.3929, grad_fn=<LinalgVectorNormBackward0>)\n",
      "After Scale, q 2th col Norm tensor(0.5647, grad_fn=<LinalgVectorNormBackward0>)\n",
      "####################\n",
      "Before Scale, v 2th col Norm tensor(1.7668, grad_fn=<LinalgVectorNormBackward0>)\n",
      "After Scale, v 2th col Norm tensor(0.5928, grad_fn=<LinalgVectorNormBackward0>)\n",
      "####################\n",
      "Before Scale, q 3th col Norm tensor(2.3371, grad_fn=<LinalgVectorNormBackward0>)\n",
      "After Scale, q 3th col Norm tensor(0.5895, grad_fn=<LinalgVectorNormBackward0>)\n",
      "####################\n",
      "Before Scale, v 3th col Norm tensor(1.7537, grad_fn=<LinalgVectorNormBackward0>)\n",
      "After Scale, v 3th col Norm tensor(0.5827, grad_fn=<LinalgVectorNormBackward0>)\n",
      "####################\n",
      "Before Scale, q 0th col Norm tensor(3.0429)\n",
      "After Scale, q 0th col Norm tensor(0.5824, grad_fn=<LinalgVectorNormBackward0>)\n",
      "####################\n",
      "Before Scale, v 0th col Norm tensor(1.9463)\n",
      "After Scale, v 0th col Norm tensor(0.5790, grad_fn=<LinalgVectorNormBackward0>)\n",
      "####################\n",
      "Before Scale, q 1th col Norm tensor(2.5609, grad_fn=<LinalgVectorNormBackward0>)\n",
      "After Scale, q 1th col Norm tensor(0.5901, grad_fn=<LinalgVectorNormBackward0>)\n",
      "####################\n",
      "Before Scale, v 1th col Norm tensor(1.9231, grad_fn=<LinalgVectorNormBackward0>)\n",
      "After Scale, v 1th col Norm tensor(0.5824, grad_fn=<LinalgVectorNormBackward0>)\n",
      "####################\n",
      "Before Scale, q 2th col Norm tensor(2.4373, grad_fn=<LinalgVectorNormBackward0>)\n",
      "After Scale, q 2th col Norm tensor(0.5801, grad_fn=<LinalgVectorNormBackward0>)\n",
      "####################\n",
      "Before Scale, v 2th col Norm tensor(1.8741, grad_fn=<LinalgVectorNormBackward0>)\n",
      "After Scale, v 2th col Norm tensor(0.5750, grad_fn=<LinalgVectorNormBackward0>)\n",
      "####################\n",
      "Before Scale, q 3th col Norm tensor(2.3232, grad_fn=<LinalgVectorNormBackward0>)\n",
      "After Scale, q 3th col Norm tensor(0.5807, grad_fn=<LinalgVectorNormBackward0>)\n",
      "####################\n",
      "Before Scale, v 3th col Norm tensor(1.8408, grad_fn=<LinalgVectorNormBackward0>)\n",
      "After Scale, v 3th col Norm tensor(0.5718, grad_fn=<LinalgVectorNormBackward0>)\n",
      "####################\n",
      "Before Scale, q 0th col Norm tensor(2.8912)\n",
      "After Scale, q 0th col Norm tensor(0.5844, grad_fn=<LinalgVectorNormBackward0>)\n",
      "####################\n",
      "Before Scale, v 0th col Norm tensor(1.9274)\n",
      "After Scale, v 0th col Norm tensor(0.5773, grad_fn=<LinalgVectorNormBackward0>)\n",
      "####################\n",
      "Before Scale, q 1th col Norm tensor(2.5192, grad_fn=<LinalgVectorNormBackward0>)\n",
      "After Scale, q 1th col Norm tensor(0.5662, grad_fn=<LinalgVectorNormBackward0>)\n",
      "####################\n",
      "Before Scale, v 1th col Norm tensor(1.9024, grad_fn=<LinalgVectorNormBackward0>)\n",
      "After Scale, v 1th col Norm tensor(0.5772, grad_fn=<LinalgVectorNormBackward0>)\n",
      "####################\n",
      "Before Scale, q 2th col Norm tensor(2.4362, grad_fn=<LinalgVectorNormBackward0>)\n",
      "After Scale, q 2th col Norm tensor(0.5861, grad_fn=<LinalgVectorNormBackward0>)\n",
      "####################\n",
      "Before Scale, v 2th col Norm tensor(1.8775, grad_fn=<LinalgVectorNormBackward0>)\n",
      "After Scale, v 2th col Norm tensor(0.5719, grad_fn=<LinalgVectorNormBackward0>)\n",
      "####################\n",
      "Before Scale, q 3th col Norm tensor(2.3050, grad_fn=<LinalgVectorNormBackward0>)\n",
      "After Scale, q 3th col Norm tensor(0.5794, grad_fn=<LinalgVectorNormBackward0>)\n",
      "####################\n",
      "Before Scale, v 3th col Norm tensor(1.7988, grad_fn=<LinalgVectorNormBackward0>)\n",
      "After Scale, v 3th col Norm tensor(0.5757, grad_fn=<LinalgVectorNormBackward0>)\n",
      "####################\n",
      "Before Scale, q 0th col Norm tensor(3.1349)\n",
      "After Scale, q 0th col Norm tensor(0.5923, grad_fn=<LinalgVectorNormBackward0>)\n",
      "####################\n",
      "Before Scale, v 0th col Norm tensor(1.8989)\n",
      "After Scale, v 0th col Norm tensor(0.5719, grad_fn=<LinalgVectorNormBackward0>)\n",
      "####################\n",
      "Before Scale, q 1th col Norm tensor(2.5776, grad_fn=<LinalgVectorNormBackward0>)\n",
      "After Scale, q 1th col Norm tensor(0.5708, grad_fn=<LinalgVectorNormBackward0>)\n",
      "####################\n",
      "Before Scale, v 1th col Norm tensor(1.8711, grad_fn=<LinalgVectorNormBackward0>)\n",
      "After Scale, v 1th col Norm tensor(0.5708, grad_fn=<LinalgVectorNormBackward0>)\n",
      "####################\n",
      "Before Scale, q 2th col Norm tensor(2.4348, grad_fn=<LinalgVectorNormBackward0>)\n",
      "After Scale, q 2th col Norm tensor(0.5769, grad_fn=<LinalgVectorNormBackward0>)\n",
      "####################\n",
      "Before Scale, v 2th col Norm tensor(1.8139, grad_fn=<LinalgVectorNormBackward0>)\n",
      "After Scale, v 2th col Norm tensor(0.5777, grad_fn=<LinalgVectorNormBackward0>)\n",
      "####################\n",
      "Before Scale, q 3th col Norm tensor(2.3198, grad_fn=<LinalgVectorNormBackward0>)\n",
      "After Scale, q 3th col Norm tensor(0.5851, grad_fn=<LinalgVectorNormBackward0>)\n",
      "####################\n",
      "Before Scale, v 3th col Norm tensor(1.8006, grad_fn=<LinalgVectorNormBackward0>)\n",
      "After Scale, v 3th col Norm tensor(0.5751, grad_fn=<LinalgVectorNormBackward0>)\n",
      "####################\n",
      "Before Scale, q 0th col Norm tensor(3.0654)\n",
      "After Scale, q 0th col Norm tensor(0.5748, grad_fn=<LinalgVectorNormBackward0>)\n",
      "####################\n",
      "Before Scale, v 0th col Norm tensor(1.8168)\n",
      "After Scale, v 0th col Norm tensor(0.5694, grad_fn=<LinalgVectorNormBackward0>)\n",
      "####################\n",
      "Before Scale, q 1th col Norm tensor(2.5702, grad_fn=<LinalgVectorNormBackward0>)\n",
      "After Scale, q 1th col Norm tensor(0.5839, grad_fn=<LinalgVectorNormBackward0>)\n",
      "####################\n",
      "Before Scale, v 1th col Norm tensor(1.7857, grad_fn=<LinalgVectorNormBackward0>)\n",
      "After Scale, v 1th col Norm tensor(0.5819, grad_fn=<LinalgVectorNormBackward0>)\n",
      "####################\n",
      "Before Scale, q 2th col Norm tensor(2.4547, grad_fn=<LinalgVectorNormBackward0>)\n",
      "After Scale, q 2th col Norm tensor(0.5780, grad_fn=<LinalgVectorNormBackward0>)\n",
      "####################\n",
      "Before Scale, v 2th col Norm tensor(1.7677, grad_fn=<LinalgVectorNormBackward0>)\n",
      "After Scale, v 2th col Norm tensor(0.5662, grad_fn=<LinalgVectorNormBackward0>)\n",
      "####################\n",
      "Before Scale, q 3th col Norm tensor(2.3552, grad_fn=<LinalgVectorNormBackward0>)\n",
      "After Scale, q 3th col Norm tensor(0.5670, grad_fn=<LinalgVectorNormBackward0>)\n",
      "####################\n",
      "Before Scale, v 3th col Norm tensor(1.7481, grad_fn=<LinalgVectorNormBackward0>)\n",
      "After Scale, v 3th col Norm tensor(0.5753, grad_fn=<LinalgVectorNormBackward0>)\n",
      "####################\n",
      "Before Scale, q 0th col Norm tensor(3.0342)\n",
      "After Scale, q 0th col Norm tensor(0.5688, grad_fn=<LinalgVectorNormBackward0>)\n",
      "####################\n",
      "Before Scale, v 0th col Norm tensor(1.7632)\n",
      "After Scale, v 0th col Norm tensor(0.5811, grad_fn=<LinalgVectorNormBackward0>)\n",
      "####################\n",
      "Before Scale, q 1th col Norm tensor(2.5090, grad_fn=<LinalgVectorNormBackward0>)\n",
      "After Scale, q 1th col Norm tensor(0.5824, grad_fn=<LinalgVectorNormBackward0>)\n",
      "####################\n",
      "Before Scale, v 1th col Norm tensor(1.7298, grad_fn=<LinalgVectorNormBackward0>)\n",
      "After Scale, v 1th col Norm tensor(0.5779, grad_fn=<LinalgVectorNormBackward0>)\n",
      "####################\n",
      "Before Scale, q 2th col Norm tensor(2.3980, grad_fn=<LinalgVectorNormBackward0>)\n",
      "After Scale, q 2th col Norm tensor(0.5721, grad_fn=<LinalgVectorNormBackward0>)\n",
      "####################\n",
      "Before Scale, v 2th col Norm tensor(1.7152, grad_fn=<LinalgVectorNormBackward0>)\n",
      "After Scale, v 2th col Norm tensor(0.5758, grad_fn=<LinalgVectorNormBackward0>)\n",
      "####################\n",
      "Before Scale, q 3th col Norm tensor(2.3637, grad_fn=<LinalgVectorNormBackward0>)\n",
      "After Scale, q 3th col Norm tensor(0.5823, grad_fn=<LinalgVectorNormBackward0>)\n",
      "####################\n",
      "Before Scale, v 3th col Norm tensor(1.7019, grad_fn=<LinalgVectorNormBackward0>)\n",
      "After Scale, v 3th col Norm tensor(0.5803, grad_fn=<LinalgVectorNormBackward0>)\n",
      "####################\n",
      "Before Scale, q 0th col Norm tensor(3.0312)\n",
      "After Scale, q 0th col Norm tensor(0.5856, grad_fn=<LinalgVectorNormBackward0>)\n",
      "####################\n",
      "Before Scale, v 0th col Norm tensor(1.7371)\n",
      "After Scale, v 0th col Norm tensor(0.5678, grad_fn=<LinalgVectorNormBackward0>)\n",
      "####################\n",
      "Before Scale, q 1th col Norm tensor(2.4257, grad_fn=<LinalgVectorNormBackward0>)\n",
      "After Scale, q 1th col Norm tensor(0.5862, grad_fn=<LinalgVectorNormBackward0>)\n",
      "####################\n",
      "Before Scale, v 1th col Norm tensor(1.7036, grad_fn=<LinalgVectorNormBackward0>)\n",
      "After Scale, v 1th col Norm tensor(0.5907, grad_fn=<LinalgVectorNormBackward0>)\n",
      "####################\n",
      "Before Scale, q 2th col Norm tensor(2.3334, grad_fn=<LinalgVectorNormBackward0>)\n",
      "After Scale, q 2th col Norm tensor(0.5764, grad_fn=<LinalgVectorNormBackward0>)\n",
      "####################\n",
      "Before Scale, v 2th col Norm tensor(1.6830, grad_fn=<LinalgVectorNormBackward0>)\n",
      "After Scale, v 2th col Norm tensor(0.5621, grad_fn=<LinalgVectorNormBackward0>)\n",
      "####################\n",
      "Before Scale, q 3th col Norm tensor(2.2701, grad_fn=<LinalgVectorNormBackward0>)\n",
      "After Scale, q 3th col Norm tensor(0.5818, grad_fn=<LinalgVectorNormBackward0>)\n",
      "####################\n",
      "Before Scale, v 3th col Norm tensor(1.6733, grad_fn=<LinalgVectorNormBackward0>)\n",
      "After Scale, v 3th col Norm tensor(0.5771, grad_fn=<LinalgVectorNormBackward0>)\n",
      "####################\n",
      "Before Scale, q 0th col Norm tensor(2.9505)\n",
      "After Scale, q 0th col Norm tensor(0.5888, grad_fn=<LinalgVectorNormBackward0>)\n",
      "####################\n",
      "Before Scale, v 0th col Norm tensor(1.6393)\n",
      "After Scale, v 0th col Norm tensor(0.5684, grad_fn=<LinalgVectorNormBackward0>)\n",
      "####################\n",
      "Before Scale, q 1th col Norm tensor(2.8367, grad_fn=<LinalgVectorNormBackward0>)\n",
      "After Scale, q 1th col Norm tensor(0.5869, grad_fn=<LinalgVectorNormBackward0>)\n",
      "####################\n",
      "Before Scale, v 1th col Norm tensor(1.6254, grad_fn=<LinalgVectorNormBackward0>)\n",
      "After Scale, v 1th col Norm tensor(0.5859, grad_fn=<LinalgVectorNormBackward0>)\n",
      "####################\n",
      "Before Scale, q 2th col Norm tensor(2.4836, grad_fn=<LinalgVectorNormBackward0>)\n",
      "After Scale, q 2th col Norm tensor(0.5808, grad_fn=<LinalgVectorNormBackward0>)\n",
      "####################\n",
      "Before Scale, v 2th col Norm tensor(1.6168, grad_fn=<LinalgVectorNormBackward0>)\n",
      "After Scale, v 2th col Norm tensor(0.5719, grad_fn=<LinalgVectorNormBackward0>)\n",
      "####################\n",
      "Before Scale, q 3th col Norm tensor(2.4008, grad_fn=<LinalgVectorNormBackward0>)\n",
      "After Scale, q 3th col Norm tensor(0.5790, grad_fn=<LinalgVectorNormBackward0>)\n",
      "####################\n",
      "Before Scale, v 3th col Norm tensor(1.6127, grad_fn=<LinalgVectorNormBackward0>)\n",
      "After Scale, v 3th col Norm tensor(0.5736, grad_fn=<LinalgVectorNormBackward0>)\n",
      "####################\n",
      "Before Scale, q 0th col Norm tensor(3.0318)\n",
      "After Scale, q 0th col Norm tensor(0.5722, grad_fn=<LinalgVectorNormBackward0>)\n",
      "####################\n",
      "Before Scale, v 0th col Norm tensor(2.0485)\n",
      "After Scale, v 0th col Norm tensor(0.5794, grad_fn=<LinalgVectorNormBackward0>)\n",
      "####################\n",
      "Before Scale, q 1th col Norm tensor(2.8401, grad_fn=<LinalgVectorNormBackward0>)\n",
      "After Scale, q 1th col Norm tensor(0.5883, grad_fn=<LinalgVectorNormBackward0>)\n",
      "####################\n",
      "Before Scale, v 1th col Norm tensor(1.7966, grad_fn=<LinalgVectorNormBackward0>)\n",
      "After Scale, v 1th col Norm tensor(0.5731, grad_fn=<LinalgVectorNormBackward0>)\n",
      "####################\n",
      "Before Scale, q 2th col Norm tensor(2.6452, grad_fn=<LinalgVectorNormBackward0>)\n",
      "After Scale, q 2th col Norm tensor(0.5825, grad_fn=<LinalgVectorNormBackward0>)\n",
      "####################\n",
      "Before Scale, v 2th col Norm tensor(1.6702, grad_fn=<LinalgVectorNormBackward0>)\n",
      "After Scale, v 2th col Norm tensor(0.5731, grad_fn=<LinalgVectorNormBackward0>)\n",
      "####################\n",
      "Before Scale, q 3th col Norm tensor(2.3654, grad_fn=<LinalgVectorNormBackward0>)\n",
      "After Scale, q 3th col Norm tensor(0.5763, grad_fn=<LinalgVectorNormBackward0>)\n",
      "####################\n",
      "Before Scale, v 3th col Norm tensor(1.6191, grad_fn=<LinalgVectorNormBackward0>)\n",
      "After Scale, v 3th col Norm tensor(0.5692, grad_fn=<LinalgVectorNormBackward0>)\n",
      "####################\n",
      "Before Scale, q 0th col Norm tensor(2.6869)\n",
      "After Scale, q 0th col Norm tensor(0.5834, grad_fn=<LinalgVectorNormBackward0>)\n",
      "####################\n",
      "Before Scale, v 0th col Norm tensor(1.7746)\n",
      "After Scale, v 0th col Norm tensor(0.5725, grad_fn=<LinalgVectorNormBackward0>)\n",
      "####################\n",
      "Before Scale, q 1th col Norm tensor(2.2029, grad_fn=<LinalgVectorNormBackward0>)\n",
      "After Scale, q 1th col Norm tensor(0.5860, grad_fn=<LinalgVectorNormBackward0>)\n",
      "####################\n",
      "Before Scale, v 1th col Norm tensor(1.6771, grad_fn=<LinalgVectorNormBackward0>)\n",
      "After Scale, v 1th col Norm tensor(0.5877, grad_fn=<LinalgVectorNormBackward0>)\n",
      "####################\n",
      "Before Scale, q 2th col Norm tensor(2.1564, grad_fn=<LinalgVectorNormBackward0>)\n",
      "After Scale, q 2th col Norm tensor(0.5680, grad_fn=<LinalgVectorNormBackward0>)\n",
      "####################\n",
      "Before Scale, v 2th col Norm tensor(1.6479, grad_fn=<LinalgVectorNormBackward0>)\n",
      "After Scale, v 2th col Norm tensor(0.5689, grad_fn=<LinalgVectorNormBackward0>)\n",
      "####################\n",
      "Before Scale, q 3th col Norm tensor(2.0784, grad_fn=<LinalgVectorNormBackward0>)\n",
      "After Scale, q 3th col Norm tensor(0.5810, grad_fn=<LinalgVectorNormBackward0>)\n",
      "####################\n",
      "Before Scale, v 3th col Norm tensor(1.6054, grad_fn=<LinalgVectorNormBackward0>)\n",
      "After Scale, v 3th col Norm tensor(0.5864, grad_fn=<LinalgVectorNormBackward0>)\n",
      "####################\n",
      "Before Scale, q 0th col Norm tensor(3.0530)\n",
      "After Scale, q 0th col Norm tensor(0.5824, grad_fn=<LinalgVectorNormBackward0>)\n",
      "####################\n",
      "Before Scale, v 0th col Norm tensor(1.9356)\n",
      "After Scale, v 0th col Norm tensor(0.5898, grad_fn=<LinalgVectorNormBackward0>)\n",
      "####################\n",
      "Before Scale, q 1th col Norm tensor(2.4767, grad_fn=<LinalgVectorNormBackward0>)\n",
      "After Scale, q 1th col Norm tensor(0.5840, grad_fn=<LinalgVectorNormBackward0>)\n",
      "####################\n",
      "Before Scale, v 1th col Norm tensor(1.8355, grad_fn=<LinalgVectorNormBackward0>)\n",
      "After Scale, v 1th col Norm tensor(0.5755, grad_fn=<LinalgVectorNormBackward0>)\n",
      "####################\n",
      "Before Scale, q 2th col Norm tensor(2.3749, grad_fn=<LinalgVectorNormBackward0>)\n",
      "After Scale, q 2th col Norm tensor(0.5834, grad_fn=<LinalgVectorNormBackward0>)\n",
      "####################\n",
      "Before Scale, v 2th col Norm tensor(1.8131, grad_fn=<LinalgVectorNormBackward0>)\n",
      "After Scale, v 2th col Norm tensor(0.5854, grad_fn=<LinalgVectorNormBackward0>)\n",
      "####################\n",
      "Before Scale, q 3th col Norm tensor(2.2615, grad_fn=<LinalgVectorNormBackward0>)\n",
      "After Scale, q 3th col Norm tensor(0.5732, grad_fn=<LinalgVectorNormBackward0>)\n",
      "####################\n",
      "Before Scale, v 3th col Norm tensor(1.7821, grad_fn=<LinalgVectorNormBackward0>)\n",
      "After Scale, v 3th col Norm tensor(0.5853, grad_fn=<LinalgVectorNormBackward0>)\n",
      "####################\n",
      "Before Scale, q 0th col Norm tensor(3.1329)\n",
      "After Scale, q 0th col Norm tensor(0.5859, grad_fn=<LinalgVectorNormBackward0>)\n",
      "####################\n",
      "Before Scale, v 0th col Norm tensor(1.9430)\n",
      "After Scale, v 0th col Norm tensor(0.5781, grad_fn=<LinalgVectorNormBackward0>)\n",
      "####################\n",
      "Before Scale, q 1th col Norm tensor(2.4833, grad_fn=<LinalgVectorNormBackward0>)\n",
      "After Scale, q 1th col Norm tensor(0.5781, grad_fn=<LinalgVectorNormBackward0>)\n",
      "####################\n",
      "Before Scale, v 1th col Norm tensor(1.9111, grad_fn=<LinalgVectorNormBackward0>)\n",
      "After Scale, v 1th col Norm tensor(0.5726, grad_fn=<LinalgVectorNormBackward0>)\n",
      "####################\n",
      "Before Scale, q 2th col Norm tensor(2.3730, grad_fn=<LinalgVectorNormBackward0>)\n",
      "After Scale, q 2th col Norm tensor(0.5700, grad_fn=<LinalgVectorNormBackward0>)\n",
      "####################\n",
      "Before Scale, v 2th col Norm tensor(1.8811, grad_fn=<LinalgVectorNormBackward0>)\n",
      "After Scale, v 2th col Norm tensor(0.5796, grad_fn=<LinalgVectorNormBackward0>)\n",
      "####################\n",
      "Before Scale, q 3th col Norm tensor(2.3494, grad_fn=<LinalgVectorNormBackward0>)\n",
      "After Scale, q 3th col Norm tensor(0.5723, grad_fn=<LinalgVectorNormBackward0>)\n",
      "####################\n",
      "Before Scale, v 3th col Norm tensor(1.8612, grad_fn=<LinalgVectorNormBackward0>)\n",
      "After Scale, v 3th col Norm tensor(0.5888, grad_fn=<LinalgVectorNormBackward0>)\n",
      "####################\n",
      "Before Scale, q 0th col Norm tensor(2.9930)\n",
      "After Scale, q 0th col Norm tensor(0.5785, grad_fn=<LinalgVectorNormBackward0>)\n",
      "####################\n",
      "Before Scale, v 0th col Norm tensor(1.9023)\n",
      "After Scale, v 0th col Norm tensor(0.5820, grad_fn=<LinalgVectorNormBackward0>)\n",
      "####################\n",
      "Before Scale, q 1th col Norm tensor(2.4474, grad_fn=<LinalgVectorNormBackward0>)\n",
      "After Scale, q 1th col Norm tensor(0.5730, grad_fn=<LinalgVectorNormBackward0>)\n",
      "####################\n",
      "Before Scale, v 1th col Norm tensor(1.8385, grad_fn=<LinalgVectorNormBackward0>)\n",
      "After Scale, v 1th col Norm tensor(0.5791, grad_fn=<LinalgVectorNormBackward0>)\n",
      "####################\n",
      "Before Scale, q 2th col Norm tensor(2.4028, grad_fn=<LinalgVectorNormBackward0>)\n",
      "After Scale, q 2th col Norm tensor(0.5759, grad_fn=<LinalgVectorNormBackward0>)\n",
      "####################\n",
      "Before Scale, v 2th col Norm tensor(1.7388, grad_fn=<LinalgVectorNormBackward0>)\n",
      "After Scale, v 2th col Norm tensor(0.5810, grad_fn=<LinalgVectorNormBackward0>)\n",
      "####################\n",
      "Before Scale, q 3th col Norm tensor(2.3293, grad_fn=<LinalgVectorNormBackward0>)\n",
      "After Scale, q 3th col Norm tensor(0.5728, grad_fn=<LinalgVectorNormBackward0>)\n",
      "####################\n",
      "Before Scale, v 3th col Norm tensor(1.7236, grad_fn=<LinalgVectorNormBackward0>)\n",
      "After Scale, v 3th col Norm tensor(0.5817, grad_fn=<LinalgVectorNormBackward0>)\n",
      "####################\n",
      "Before Scale, q 0th col Norm tensor(3.0552)\n",
      "After Scale, q 0th col Norm tensor(0.5898, grad_fn=<LinalgVectorNormBackward0>)\n",
      "####################\n",
      "Before Scale, v 0th col Norm tensor(1.9132)\n",
      "After Scale, v 0th col Norm tensor(0.5692, grad_fn=<LinalgVectorNormBackward0>)\n",
      "####################\n",
      "Before Scale, q 1th col Norm tensor(2.5419, grad_fn=<LinalgVectorNormBackward0>)\n",
      "After Scale, q 1th col Norm tensor(0.5800, grad_fn=<LinalgVectorNormBackward0>)\n",
      "####################\n",
      "Before Scale, v 1th col Norm tensor(1.8859, grad_fn=<LinalgVectorNormBackward0>)\n",
      "After Scale, v 1th col Norm tensor(0.5724, grad_fn=<LinalgVectorNormBackward0>)\n",
      "####################\n",
      "Before Scale, q 2th col Norm tensor(2.4315, grad_fn=<LinalgVectorNormBackward0>)\n",
      "After Scale, q 2th col Norm tensor(0.5857, grad_fn=<LinalgVectorNormBackward0>)\n",
      "####################\n",
      "Before Scale, v 2th col Norm tensor(1.8534, grad_fn=<LinalgVectorNormBackward0>)\n",
      "After Scale, v 2th col Norm tensor(0.5736, grad_fn=<LinalgVectorNormBackward0>)\n",
      "####################\n",
      "Before Scale, q 3th col Norm tensor(2.3121, grad_fn=<LinalgVectorNormBackward0>)\n",
      "After Scale, q 3th col Norm tensor(0.5810, grad_fn=<LinalgVectorNormBackward0>)\n",
      "####################\n",
      "Before Scale, v 3th col Norm tensor(1.7973, grad_fn=<LinalgVectorNormBackward0>)\n",
      "After Scale, v 3th col Norm tensor(0.5766, grad_fn=<LinalgVectorNormBackward0>)\n",
      "####################\n",
      "Before Scale, q 0th col Norm tensor(2.9097)\n",
      "After Scale, q 0th col Norm tensor(0.5810, grad_fn=<LinalgVectorNormBackward0>)\n",
      "####################\n",
      "Before Scale, v 0th col Norm tensor(1.8794)\n",
      "After Scale, v 0th col Norm tensor(0.5675, grad_fn=<LinalgVectorNormBackward0>)\n",
      "####################\n",
      "Before Scale, q 1th col Norm tensor(2.4727, grad_fn=<LinalgVectorNormBackward0>)\n",
      "After Scale, q 1th col Norm tensor(0.5712, grad_fn=<LinalgVectorNormBackward0>)\n",
      "####################\n",
      "Before Scale, v 1th col Norm tensor(1.8673, grad_fn=<LinalgVectorNormBackward0>)\n",
      "After Scale, v 1th col Norm tensor(0.5675, grad_fn=<LinalgVectorNormBackward0>)\n",
      "####################\n",
      "Before Scale, q 2th col Norm tensor(2.4401, grad_fn=<LinalgVectorNormBackward0>)\n",
      "After Scale, q 2th col Norm tensor(0.5752, grad_fn=<LinalgVectorNormBackward0>)\n",
      "####################\n",
      "Before Scale, v 2th col Norm tensor(1.8493, grad_fn=<LinalgVectorNormBackward0>)\n",
      "After Scale, v 2th col Norm tensor(0.5711, grad_fn=<LinalgVectorNormBackward0>)\n",
      "####################\n",
      "Before Scale, q 3th col Norm tensor(2.2935, grad_fn=<LinalgVectorNormBackward0>)\n",
      "After Scale, q 3th col Norm tensor(0.5808, grad_fn=<LinalgVectorNormBackward0>)\n",
      "####################\n",
      "Before Scale, v 3th col Norm tensor(1.7513, grad_fn=<LinalgVectorNormBackward0>)\n",
      "After Scale, v 3th col Norm tensor(0.5670, grad_fn=<LinalgVectorNormBackward0>)\n",
      "####################\n",
      "Before Scale, q 0th col Norm tensor(3.1697)\n",
      "After Scale, q 0th col Norm tensor(0.5824, grad_fn=<LinalgVectorNormBackward0>)\n",
      "####################\n",
      "Before Scale, v 0th col Norm tensor(1.8566)\n",
      "After Scale, v 0th col Norm tensor(0.5721, grad_fn=<LinalgVectorNormBackward0>)\n",
      "####################\n",
      "Before Scale, q 1th col Norm tensor(2.5808, grad_fn=<LinalgVectorNormBackward0>)\n",
      "After Scale, q 1th col Norm tensor(0.5924, grad_fn=<LinalgVectorNormBackward0>)\n",
      "####################\n",
      "Before Scale, v 1th col Norm tensor(1.8268, grad_fn=<LinalgVectorNormBackward0>)\n",
      "After Scale, v 1th col Norm tensor(0.5757, grad_fn=<LinalgVectorNormBackward0>)\n",
      "####################\n",
      "Before Scale, q 2th col Norm tensor(2.4376, grad_fn=<LinalgVectorNormBackward0>)\n",
      "After Scale, q 2th col Norm tensor(0.5808, grad_fn=<LinalgVectorNormBackward0>)\n",
      "####################\n",
      "Before Scale, v 2th col Norm tensor(1.7820, grad_fn=<LinalgVectorNormBackward0>)\n",
      "After Scale, v 2th col Norm tensor(0.5898, grad_fn=<LinalgVectorNormBackward0>)\n",
      "####################\n",
      "Before Scale, q 3th col Norm tensor(2.3558, grad_fn=<LinalgVectorNormBackward0>)\n",
      "After Scale, q 3th col Norm tensor(0.5907, grad_fn=<LinalgVectorNormBackward0>)\n",
      "####################\n",
      "Before Scale, v 3th col Norm tensor(1.7744, grad_fn=<LinalgVectorNormBackward0>)\n",
      "After Scale, v 3th col Norm tensor(0.5717, grad_fn=<LinalgVectorNormBackward0>)\n",
      "####################\n",
      "Before Scale, q 0th col Norm tensor(3.1089)\n",
      "After Scale, q 0th col Norm tensor(0.5716, grad_fn=<LinalgVectorNormBackward0>)\n",
      "####################\n",
      "Before Scale, v 0th col Norm tensor(1.7797)\n",
      "After Scale, v 0th col Norm tensor(0.5814, grad_fn=<LinalgVectorNormBackward0>)\n",
      "####################\n",
      "Before Scale, q 1th col Norm tensor(2.5728, grad_fn=<LinalgVectorNormBackward0>)\n",
      "After Scale, q 1th col Norm tensor(0.5769, grad_fn=<LinalgVectorNormBackward0>)\n",
      "####################\n",
      "Before Scale, v 1th col Norm tensor(1.7601, grad_fn=<LinalgVectorNormBackward0>)\n",
      "After Scale, v 1th col Norm tensor(0.5815, grad_fn=<LinalgVectorNormBackward0>)\n",
      "####################\n",
      "Before Scale, q 2th col Norm tensor(2.4644, grad_fn=<LinalgVectorNormBackward0>)\n",
      "After Scale, q 2th col Norm tensor(0.5827, grad_fn=<LinalgVectorNormBackward0>)\n",
      "####################\n",
      "Before Scale, v 2th col Norm tensor(1.7522, grad_fn=<LinalgVectorNormBackward0>)\n",
      "After Scale, v 2th col Norm tensor(0.5781, grad_fn=<LinalgVectorNormBackward0>)\n",
      "####################\n",
      "Before Scale, q 3th col Norm tensor(2.4014, grad_fn=<LinalgVectorNormBackward0>)\n",
      "After Scale, q 3th col Norm tensor(0.5764, grad_fn=<LinalgVectorNormBackward0>)\n",
      "####################\n",
      "Before Scale, v 3th col Norm tensor(1.7265, grad_fn=<LinalgVectorNormBackward0>)\n",
      "After Scale, v 3th col Norm tensor(0.5777, grad_fn=<LinalgVectorNormBackward0>)\n",
      "####################\n",
      "Before Scale, q 0th col Norm tensor(3.0483)\n",
      "After Scale, q 0th col Norm tensor(0.5736, grad_fn=<LinalgVectorNormBackward0>)\n",
      "####################\n",
      "Before Scale, v 0th col Norm tensor(1.7499)\n",
      "After Scale, v 0th col Norm tensor(0.5756, grad_fn=<LinalgVectorNormBackward0>)\n",
      "####################\n",
      "Before Scale, q 1th col Norm tensor(2.4992, grad_fn=<LinalgVectorNormBackward0>)\n",
      "After Scale, q 1th col Norm tensor(0.5761, grad_fn=<LinalgVectorNormBackward0>)\n",
      "####################\n",
      "Before Scale, v 1th col Norm tensor(1.7095, grad_fn=<LinalgVectorNormBackward0>)\n",
      "After Scale, v 1th col Norm tensor(0.5788, grad_fn=<LinalgVectorNormBackward0>)\n",
      "####################\n",
      "Before Scale, q 2th col Norm tensor(2.4197, grad_fn=<LinalgVectorNormBackward0>)\n",
      "After Scale, q 2th col Norm tensor(0.5728, grad_fn=<LinalgVectorNormBackward0>)\n",
      "####################\n",
      "Before Scale, v 2th col Norm tensor(1.6887, grad_fn=<LinalgVectorNormBackward0>)\n",
      "After Scale, v 2th col Norm tensor(0.5909, grad_fn=<LinalgVectorNormBackward0>)\n",
      "####################\n",
      "Before Scale, q 3th col Norm tensor(2.3858, grad_fn=<LinalgVectorNormBackward0>)\n",
      "After Scale, q 3th col Norm tensor(0.5707, grad_fn=<LinalgVectorNormBackward0>)\n",
      "####################\n",
      "Before Scale, v 3th col Norm tensor(1.6800, grad_fn=<LinalgVectorNormBackward0>)\n",
      "After Scale, v 3th col Norm tensor(0.5815, grad_fn=<LinalgVectorNormBackward0>)\n",
      "####################\n",
      "Before Scale, q 0th col Norm tensor(3.0182)\n",
      "After Scale, q 0th col Norm tensor(0.5830, grad_fn=<LinalgVectorNormBackward0>)\n",
      "####################\n",
      "Before Scale, v 0th col Norm tensor(1.7719)\n",
      "After Scale, v 0th col Norm tensor(0.5800, grad_fn=<LinalgVectorNormBackward0>)\n",
      "####################\n",
      "Before Scale, q 1th col Norm tensor(2.4593, grad_fn=<LinalgVectorNormBackward0>)\n",
      "After Scale, q 1th col Norm tensor(0.5778, grad_fn=<LinalgVectorNormBackward0>)\n",
      "####################\n",
      "Before Scale, v 1th col Norm tensor(1.7197, grad_fn=<LinalgVectorNormBackward0>)\n",
      "After Scale, v 1th col Norm tensor(0.5736, grad_fn=<LinalgVectorNormBackward0>)\n",
      "####################\n",
      "Before Scale, q 2th col Norm tensor(2.3484, grad_fn=<LinalgVectorNormBackward0>)\n",
      "After Scale, q 2th col Norm tensor(0.5763, grad_fn=<LinalgVectorNormBackward0>)\n",
      "####################\n",
      "Before Scale, v 2th col Norm tensor(1.6854, grad_fn=<LinalgVectorNormBackward0>)\n",
      "After Scale, v 2th col Norm tensor(0.5804, grad_fn=<LinalgVectorNormBackward0>)\n",
      "####################\n",
      "Before Scale, q 3th col Norm tensor(2.2945, grad_fn=<LinalgVectorNormBackward0>)\n",
      "After Scale, q 3th col Norm tensor(0.5757, grad_fn=<LinalgVectorNormBackward0>)\n",
      "####################\n",
      "Before Scale, v 3th col Norm tensor(1.6826, grad_fn=<LinalgVectorNormBackward0>)\n",
      "After Scale, v 3th col Norm tensor(0.5784, grad_fn=<LinalgVectorNormBackward0>)\n",
      "####################\n",
      "Before Scale, q 0th col Norm tensor(4.0768)\n",
      "After Scale, q 0th col Norm tensor(0.5875, grad_fn=<LinalgVectorNormBackward0>)\n",
      "####################\n",
      "Before Scale, v 0th col Norm tensor(1.6519)\n",
      "After Scale, v 0th col Norm tensor(0.5808, grad_fn=<LinalgVectorNormBackward0>)\n",
      "####################\n",
      "Before Scale, q 1th col Norm tensor(2.8870, grad_fn=<LinalgVectorNormBackward0>)\n",
      "After Scale, q 1th col Norm tensor(0.5788, grad_fn=<LinalgVectorNormBackward0>)\n",
      "####################\n",
      "Before Scale, v 1th col Norm tensor(1.6469, grad_fn=<LinalgVectorNormBackward0>)\n",
      "After Scale, v 1th col Norm tensor(0.5868, grad_fn=<LinalgVectorNormBackward0>)\n",
      "####################\n",
      "Before Scale, q 2th col Norm tensor(2.6832, grad_fn=<LinalgVectorNormBackward0>)\n",
      "After Scale, q 2th col Norm tensor(0.5668, grad_fn=<LinalgVectorNormBackward0>)\n",
      "####################\n",
      "Before Scale, v 2th col Norm tensor(1.6427, grad_fn=<LinalgVectorNormBackward0>)\n",
      "After Scale, v 2th col Norm tensor(0.5696, grad_fn=<LinalgVectorNormBackward0>)\n",
      "####################\n",
      "Before Scale, q 3th col Norm tensor(2.4321, grad_fn=<LinalgVectorNormBackward0>)\n",
      "After Scale, q 3th col Norm tensor(0.5815, grad_fn=<LinalgVectorNormBackward0>)\n",
      "####################\n",
      "Before Scale, v 3th col Norm tensor(1.6396, grad_fn=<LinalgVectorNormBackward0>)\n",
      "After Scale, v 3th col Norm tensor(0.5724, grad_fn=<LinalgVectorNormBackward0>)\n",
      "####################\n"
     ]
    }
   ],
   "source": [
    "len_of_layers = len(model.deberta.encoder.layer)\n",
    "q_new_lora_A_list = []\n",
    "v_new_lora_A_list = []\n",
    "\n",
    "for layer_idx in range(len_of_layers):\n",
    "    q_original_weight = model.deberta.encoder.layer[layer_idx].attention.self.query_proj.weight.data.T\n",
    "    v_original_weight = model.deberta.encoder.layer[layer_idx].attention.self.value_proj.weight.data.T\n",
    "\n",
    "    q_og_lora_A = model.base_model.model.deberta.encoder.layer[\n",
    "        layer_idx\n",
    "    ].attention.self.query_proj.lora_A.default.weight.T\n",
    "    v_og_lora_A = model.base_model.model.deberta.encoder.layer[\n",
    "        layer_idx\n",
    "    ].attention.self.value_proj.lora_A.default.weight.T\n",
    "\n",
    "    q_proj_u, q_proj_s, q_proj_v = torch.linalg.svd(q_original_weight)\n",
    "    q_new_lora_A = q_proj_u[:, :4] @ torch.diag(q_proj_s[:4]).sqrt()\n",
    "\n",
    "    v_proj_u, v_proj_s, v_proj_v = torch.linalg.svd(v_original_weight)\n",
    "    v_new_lora_A = v_proj_u[:, :4] @ torch.diag(v_proj_s[:4]).sqrt()\n",
    "\n",
    "    for i in range(4):\n",
    "        print(f\"Before Scale, q {i}th col Norm\", torch.norm(q_new_lora_A[:, i]))\n",
    "\n",
    "        q_og_lora_A_icol_norm = torch.norm(q_og_lora_A[:, i])\n",
    "        q_new_lora_A_icol_norm = torch.norm(q_new_lora_A[:, i])\n",
    "\n",
    "        q_scale = q_og_lora_A_icol_norm / q_new_lora_A_icol_norm\n",
    "\n",
    "        q_new_lora_A[:, i] = q_new_lora_A[:, i] * q_scale\n",
    "\n",
    "        print(f\"After Scale, q {i}th col Norm\", torch.norm(q_new_lora_A[:, i]))\n",
    "        print(\"####################\")\n",
    "\n",
    "        print(f\"Before Scale, v {i}th col Norm\", torch.norm(v_new_lora_A[:, i]))\n",
    "\n",
    "        v_og_lora_A_icol_norm = torch.norm(v_og_lora_A[:, i])\n",
    "        v_new_lora_A_icol_norm = torch.norm(v_new_lora_A[:, i])\n",
    "\n",
    "        v_scale = v_og_lora_A_icol_norm / v_new_lora_A_icol_norm\n",
    "\n",
    "        v_new_lora_A[:, i] = v_new_lora_A[:, i] * v_scale\n",
    "\n",
    "        print(f\"After Scale, v {i}th col Norm\", torch.norm(v_new_lora_A[:, i]))\n",
    "        print(\"####################\")\n",
    "\n",
    "    q_new_lora_A_list.append(q_new_lora_A)\n",
    "    v_new_lora_A_list.append(v_new_lora_A)\n",
    "\n",
    "    model.base_model.model.deberta.encoder.layer[layer_idx].attention.self.query_proj.lora_A.default.weight.data = (\n",
    "        q_new_lora_A_list[layer_idx].transpose(0, 1).contiguous()\n",
    "    )\n",
    "    model.base_model.model.deberta.encoder.layer[layer_idx].attention.self.value_proj.lora_A.default.weight.data = (\n",
    "        v_new_lora_A_list[layer_idx].transpose(0, 1).contiguous()\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([tensor(0.5674, grad_fn=<LinalgVectorNormBackward0>),\n",
       "  tensor(0.5857, grad_fn=<LinalgVectorNormBackward0>),\n",
       "  tensor(0.5796, grad_fn=<LinalgVectorNormBackward0>),\n",
       "  tensor(0.5761, grad_fn=<LinalgVectorNormBackward0>),\n",
       "  tensor(0.5753, grad_fn=<LinalgVectorNormBackward0>),\n",
       "  tensor(0.5796, grad_fn=<LinalgVectorNormBackward0>),\n",
       "  tensor(0.5784, grad_fn=<LinalgVectorNormBackward0>),\n",
       "  tensor(0.5738, grad_fn=<LinalgVectorNormBackward0>),\n",
       "  tensor(0.5734, grad_fn=<LinalgVectorNormBackward0>),\n",
       "  tensor(0.5654, grad_fn=<LinalgVectorNormBackward0>),\n",
       "  tensor(0.5826, grad_fn=<LinalgVectorNormBackward0>),\n",
       "  tensor(0.5692, grad_fn=<LinalgVectorNormBackward0>),\n",
       "  tensor(0.5683, grad_fn=<LinalgVectorNormBackward0>),\n",
       "  tensor(0.5814, grad_fn=<LinalgVectorNormBackward0>),\n",
       "  tensor(0.5670, grad_fn=<LinalgVectorNormBackward0>),\n",
       "  tensor(0.5818, grad_fn=<LinalgVectorNormBackward0>),\n",
       "  tensor(0.5741, grad_fn=<LinalgVectorNormBackward0>),\n",
       "  tensor(0.5749, grad_fn=<LinalgVectorNormBackward0>),\n",
       "  tensor(0.5754, grad_fn=<LinalgVectorNormBackward0>),\n",
       "  tensor(0.5869, grad_fn=<LinalgVectorNormBackward0>),\n",
       "  tensor(0.5786, grad_fn=<LinalgVectorNormBackward0>),\n",
       "  tensor(0.5709, grad_fn=<LinalgVectorNormBackward0>),\n",
       "  tensor(0.5776, grad_fn=<LinalgVectorNormBackward0>),\n",
       "  tensor(0.5739, grad_fn=<LinalgVectorNormBackward0>),\n",
       "  tensor(0.5794, grad_fn=<LinalgVectorNormBackward0>),\n",
       "  tensor(0.5844, grad_fn=<LinalgVectorNormBackward0>),\n",
       "  tensor(0.5689, grad_fn=<LinalgVectorNormBackward0>),\n",
       "  tensor(0.5763, grad_fn=<LinalgVectorNormBackward0>),\n",
       "  tensor(0.5770, grad_fn=<LinalgVectorNormBackward0>),\n",
       "  tensor(0.5744, grad_fn=<LinalgVectorNormBackward0>),\n",
       "  tensor(0.5760, grad_fn=<LinalgVectorNormBackward0>),\n",
       "  tensor(0.5835, grad_fn=<LinalgVectorNormBackward0>),\n",
       "  tensor(0.5823, grad_fn=<LinalgVectorNormBackward0>),\n",
       "  tensor(0.5711, grad_fn=<LinalgVectorNormBackward0>),\n",
       "  tensor(0.5769, grad_fn=<LinalgVectorNormBackward0>),\n",
       "  tensor(0.5761, grad_fn=<LinalgVectorNormBackward0>),\n",
       "  tensor(0.5847, grad_fn=<LinalgVectorNormBackward0>),\n",
       "  tensor(0.5749, grad_fn=<LinalgVectorNormBackward0>),\n",
       "  tensor(0.5732, grad_fn=<LinalgVectorNormBackward0>),\n",
       "  tensor(0.5854, grad_fn=<LinalgVectorNormBackward0>),\n",
       "  tensor(0.5775, grad_fn=<LinalgVectorNormBackward0>),\n",
       "  tensor(0.5685, grad_fn=<LinalgVectorNormBackward0>),\n",
       "  tensor(0.5741, grad_fn=<LinalgVectorNormBackward0>),\n",
       "  tensor(0.5814, grad_fn=<LinalgVectorNormBackward0>),\n",
       "  tensor(0.5759, grad_fn=<LinalgVectorNormBackward0>),\n",
       "  tensor(0.5720, grad_fn=<LinalgVectorNormBackward0>),\n",
       "  tensor(0.5738, grad_fn=<LinalgVectorNormBackward0>),\n",
       "  tensor(0.5704, grad_fn=<LinalgVectorNormBackward0>)],\n",
       " [tensor(3.2754),\n",
       "  tensor(2.7274),\n",
       "  tensor(2.9403),\n",
       "  tensor(3.0741),\n",
       "  tensor(2.8918),\n",
       "  tensor(3.0407),\n",
       "  tensor(2.9064),\n",
       "  tensor(3.1607),\n",
       "  tensor(3.0960),\n",
       "  tensor(3.0624),\n",
       "  tensor(3.0136),\n",
       "  tensor(2.9946),\n",
       "  tensor(3.0471),\n",
       "  tensor(2.6912),\n",
       "  tensor(3.0725),\n",
       "  tensor(3.1196),\n",
       "  tensor(2.9832),\n",
       "  tensor(3.0535),\n",
       "  tensor(2.8972),\n",
       "  tensor(3.1522),\n",
       "  tensor(3.0936),\n",
       "  tensor(3.0776),\n",
       "  tensor(3.0492),\n",
       "  tensor(2.9450),\n",
       "  tensor(3.0412),\n",
       "  tensor(2.6832),\n",
       "  tensor(3.0625),\n",
       "  tensor(3.1114),\n",
       "  tensor(2.9791),\n",
       "  tensor(3.0429),\n",
       "  tensor(2.8912),\n",
       "  tensor(3.1349),\n",
       "  tensor(3.0654),\n",
       "  tensor(3.0342),\n",
       "  tensor(3.0312),\n",
       "  tensor(2.9505),\n",
       "  tensor(3.0318),\n",
       "  tensor(2.6869),\n",
       "  tensor(3.0530),\n",
       "  tensor(3.1329),\n",
       "  tensor(2.9930),\n",
       "  tensor(3.0552),\n",
       "  tensor(2.9097),\n",
       "  tensor(3.1697),\n",
       "  tensor(3.1089),\n",
       "  tensor(3.0483),\n",
       "  tensor(3.0182),\n",
       "  tensor(4.0768)])"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lora_A_norms = []\n",
    "new_lora_A_norms = []\n",
    "for i in range(48):\n",
    "    lora_A = model.base_model.model.deberta.encoder.layer[i].attention.self.query_proj.lora_A.default.weight.T\n",
    "    lora_A_norms.append(torch.norm(lora_A[:, 0]))\n",
    "\n",
    "    q_original_weight = model.deberta.encoder.layer[i].attention.self.query_proj.weight.data.T\n",
    "    q_proj_u, q_proj_s, q_proj_v = torch.linalg.svd(q_original_weight)\n",
    "    new_lora_A = q_proj_u[:, :4] @ torch.diag(q_proj_s[:4]).sqrt()\n",
    "    new_lora_A_norms.append(torch.norm(new_lora_A[:, 0]))\n",
    "\n",
    "lora_A_norms, new_lora_A_norms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(3.2754)"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_lora_A_norms[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(48):\n",
    "    scale = lora_A_norms[i] / new_lora_A_norms[i]\n",
    "    scaled_lora = model.base_model.model.deberta.encoder.layer[i].attention.self.query_proj.lora_A.default.weight.T * scale\n",
    "    scaled_norm = torch.norm(scaled_lora[:, 0])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "qlora",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
